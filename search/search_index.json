{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Personal Notes Collection","text":""},{"location":"#textbook-reference","title":"Textbook Reference","text":"<p>Abstract Algebra: Abstract Algebra, Theory and Applications</p>"},{"location":"todo/","title":"Broken Link","text":"<p>This is an internal-only page, for use when wanting to link to a page that has not been written.</p>"},{"location":"math/abstract-algebra/16-rings/","title":"Chapter 16 - Rings","text":""},{"location":"math/abstract-algebra/16-rings/#section-161-rings","title":"Section 16.1 - Rings","text":"<p>Definition. A nonempty set \\(S\\) is a ring if, with two binary operations called addition and multiplication, the following are satisfied:</p> <ol> <li>Addition is commutative. \\(a + b = b + a\\) for \\(a, b \\in R\\)</li> <li>Addition is associative. \\((a + b) + c = a + (b + c)\\) for \\(a, b, c \\in R\\)</li> <li>There exists a zero-element \\(0_R\\) in \\(R\\) such that \\(a + 0 = a\\) for all $a \\in $</li> <li>Every element \\(a\\) has an additive inverse \\(-a \\in R\\) such that \\(a + (-a) = 0_R\\)</li> <li>Multiplication is associative. That is, \\(a(bc) = (ab)c\\) for \\(a, b, c \\in R\\)</li> <li>The Distributive Property holds. That is, \\(\\forall a, b, c \\in R,\\)</li> </ol> \\[ a(b+c) = ab+bc \\\\ (a+b)c = ac + bc \\] <p>Definition. If there exists some element \\(1_R \\in R\\) such that \\(1a = a1 = a\\) for all \\(a \\in R\\), we say that \\(R\\) is a ring with unity or identity.</p> <p>Note that some books impose the condition that \\(1 \\neq 0\\). If \\(1 = 0\\), we can show the ring only has one element.</p> <p>Definition. If \\(ab = ba\\) for all \\(a, b \\in R\\), the ring is said to be a commutative ring.</p> <p>Definition. If a ring \\(R\\) is commutative, \\(R\\) is an integral domain if and only if for every \\(a, b \\in R\\), \\(ab = 0\\) implies that either \\(a = 0\\) or \\(b = 0\\).</p> <p>Definition. An element \\(a \\in R\\) is called a unit if there exists some \\(a^{-1}\\) such that \\(a a^{-1} = a^{-1} a = 1\\).</p> <p>Definition. A ring \\(R\\) with identity is called a division ring if every nonzero element in \\(R\\) is a unit.</p> <p>Definition. A commutative division ring is called a field. That is, in a field, every element has an inverse.</p> <p>Definition. A subset \\(S\\) of ring \\(R\\) is a subring if given any \\(r, s \\in S\\), then \\(rs \\in S\\) and \\(r - s \\in S\\).</p>"},{"location":"math/abstract-algebra/16-rings/#section-162-integral-domains-and-fields","title":"Section 16.2 - Integral Domains and Fields","text":"<p>Definition. If \\(R\\) is a commutative ring and \\(r \\in R\\), then \\(r\\) is said to be a zero divisor if there is some nonzero \\(s \\in R\\) such that \\(rs = 0\\).</p> <p>Definition. A commutative ring with no zero divisors is called an integral domain.</p> <p>Example. Consider the set \\(\\mathbb{Z}[i] = \\{m + ni | m, n \\in \\mathbb{Z}\\}\\). This ring is called the Gaussian integers. Prove that the Gaussian integers are not a field, and are an integral domain.</p> <p>Example. Proposition 16.15: Cancellation law. Let \\(D\\) be a commutative ring with identity. Then, \\(D\\) is an integral domain if and only if for every nonzero \\(a \\in R\\), \\(ab = ac\\) implies \\(b = c\\).</p> <p>Theorem. 16.16: Every finite integral domain is a field.</p> <p>Definition. For any non-negative integer \\(n \\in \\mathbb{N}\\) and \\(r \\in R\\), we say that \\(nr = r + \\ldots + r \\text{(n times)}\\).</p> <p>Definition. The characteristic of a ring is the least possible \\(n \\in \\mathbb{N}\\) such that \\(nr = 0\\) for all \\(r \\in R\\).</p> <p>Example. For every prime number \\(p\\), \\(\\mathbb{N}_p\\) is a field of characteristic \\(p\\).</p> <p>Lemma. 16.18: Given \\(R\\) is a ring with identity, the characteristic of \\(1\\) is the characteristic of the field.</p> <p>Theorem. 16.19: The characteristic of an integral domain is prime or zero.</p>"},{"location":"math/abstract-algebra/16-rings/#section-163-ring-homomorphisms-and-ideals","title":"Section 16.3 - Ring Homomorphisms and Ideals","text":"<p>Definition Given rings \\(R\\) and \\(S\\), and a mapping \\(\\varphi: R \\rightarrow S\\), we say that \\(\\varphi\\) is a ring homomorphism if the following are satisfied for all elements of \\(R\\):</p> \\[ \\begin{align}     \\varphi(a + b) &amp;= \\varphi(a) + \\varphi(b) \\\\     \\varphi(ab) &amp;= \\varphi(a) \\varphi(b) \\end{align} \\] <p>Definition. If \\(\\varphi\\) is one-to-one and onto, it is an isomorphism.</p> <p>Definition. For any ring homomorphism \\(\\varphi\\), the kernel of \\(\\varphi\\) is the set</p> \\[ \\ker \\varphi = \\{ r \\in R | \\varphi(r) = 0 \\} \\] <p>Definition. Proposition 16.22: Let \\(\\varphi: R \\rightarrow S\\) be a ring homomorphism. Then,</p> <ol> <li>If \\(R\\) is a commutative ring, then \\(\\varphi(R) \\subseteq S\\) is a commutative ring.</li> <li>\\(\\varphi(0_R) = 0_S\\)</li> <li>Let \\(1_R\\) and \\(1_S\\) be the identities in \\(R\\) and \\(S\\). If \\(\\varphi\\) is onto, then \\(\\varphi(1_R) = 1_S\\)</li> <li>If \\(R\\) is a field an \\(\\varphi(R) \\neq \\{0\\}\\), then \\(\\varphi(R) \\subseteq S\\) is a field.</li> </ol> <p>Definition. A subring \\(I \\subseteq R\\) is asn ideal of \\(R\\) if, when given \\(a \\in I, r \\in R\\), then \\(ar\\) and \\(ra\\) are both in \\(I\\). That is, \\(rI \\subseteq I\\) and \\(Ir \\subseteq I\\).</p> <p>Definition. Given a commutative ring \\(R\\) with identity, and \\(r \\in R\\), the set</p> \\[ \\langle a \\rangle = (r)R = \\{ ar : r \\in R \\} \\] <p>is an ideal in \\(R\\). Specifically, \\(\\langle a \\rangle\\) is a principal ideal.</p> <p>Example. Theorem 16.25. Every ideal in \\(\\mathbb{Z}\\) is a principal ideal.</p> <p>Example. With \\(\\varphi: R \\rightarrow S\\), \\(\\ker \\varphi\\) is an ideal of \\(R\\).</p> <p>Remark. 16.28: We are working with two-sided ideals. If rings are not commutative, we may deal with left ideals and right ideals.</p> <p>Theorem. 16.29: Let  \\(I\\) be an ideal of \\(R\\). Then, the factor/quotient ring \\(R/I\\) is a ring with multiplication defined by</p> \\[ (r + I)(s + I) = rs + I \\] <p>Theorem. 16.30: Let \\(I\\) be an ideal of \\(R\\). Then, the map \\(\\varphi: R \\rightarrow R/I\\) defined by \\(\\varphi(r) = r + I\\) is a ring homomorphism of \\(R\\) onto \\(R/I\\) with \\(\\ker \\varphi = I\\).</p> <p>Theorem. 16.31, First Isomorphism Theorem. Let \\(\\psi: R \\rightarrow S\\). Then, \\(\\ker \\psi\\) is an ideal of \\(R\\). Consider the isomorphism \\(\\varphi: R \\rightarrow R/\\ker \\psi\\). There exists an isomorphism \\(\\eta: R / \\ker \\psi \\rightarrow \\psi(R)\\) such that \\(\\psi = \\eta \\varphi\\).</p> <p>Theorem. 16.32, Second Isomorphism Theorem. Let \\(I\\) be a subring of \\(R\\) and \\(J\\) be an ideal of \\(R\\). Then, \\(I \\cap J\\) is an ideal of \\(I\\) and</p> \\[ I/I \\cap J \\cong (I + J) / J \\] <p>Theorem. 16.33, Third Isomorphism Theorem. Let \\(R\\) be a ring and \\(I, J\\) be ideals of J. If \\(J \\subsetneq I\\), then</p> \\[ R/I \\cong \\frac{R/J}{I/J} \\] <p>Theorem. 16.34, Correspondence Theorem. Let \\(I\\) be an ideal of \\(R\\). Then, \\(S \\mapsto S/I\\) is a one-to-one correspondence between the set of subrings \\(S\\) containing \\(I\\) (that is, \\(I \\in S\\)) and the set of subrings of \\(R/I\\). Furthermore, the ideals of \\(R\\) containing \\(I\\) correspond to the ideals of \\(R/I\\).</p>"},{"location":"math/abstract-algebra/16-rings/#section-164-maximal-and-prime-ideals","title":"Section 16.4 - Maximal and Prime Ideals","text":"<p>Definition. Consider ring \\(R\\) and proper ideal \\(M \\subseteq R\\). Then, \\(M\\) is a maximal ideal of \\(R\\) if the ideal \\(M\\) is not a subset of any ideal except \\(R\\) itself. That is, given any ideal \\(I\\) properly containing \\(M\\), \\(I = R\\).</p> <p>Theorem. 16.35: Given a commutative ring with identity \\(R\\), \\(M\\) is a maximal ideal if and only if \\(R/M\\) is a field.</p> <p>Definition. Consider ring \\(R\\) and proper ideal \\(P \\subseteq R\\). Then, \\(P\\) is a prime ideal if given \\(ab \\in P\\), either \\(a \\in P\\) or \\(b \\in P\\).</p> <p>Theorem. 16.38: Let \\(R\\) be a commutative ring with identity \\(1\\). Then, \\(P \\subseteq R\\) is a prime ideal of \\(R\\) if and only if \\(R/P\\) is a field.</p> <p>Let us assume that \\(P\\) is an ideal in \\(R\\) and \\(R/P\\) is an integral domain. Take two elements \\(ab \\in P\\). Now, consider \\(a + P\\) and \\(b + P\\) in \\(R/P\\) such that \\((a+P)(b+P) = 0+P = P\\). As \\(R/P\\) is a field, either \\(a + P = 0 + P = P\\) or \\(b + P = 0 + P = P\\), meaning either \\(a \\in P\\) or \\(b \\in P\\). Thus, \\(P\\) is as prime ideal.</p> <p>Now, assume the opposite. Let \\(P\\) be prime. Now, we want to show that \\(R/P\\) is an integral domain.</p> <p>Consider two elements \\(a + P\\), \\(b + P\\) in \\(R/P\\). We know that</p> \\[ (a + P)(b + P) = ab + P = 0 + P = P \\] <p>Thus, \\(ab \\in P\\). By symnetry, assume \\(a \\notin P\\). Thus, \\(b \\in P\\) by the definition of a prime ideal, so \\(b + P = 0 + P\\), meaning \\(R/P\\) is an integral domain.</p> <p>Theorem. 16.40: In a commutative ring with identity, every maximal ideal is also a prime ideal.</p>"},{"location":"math/abstract-algebra/16-rings/#section-165-applications-to-computer-science","title":"Section 16.5 - Applications to Computer Science","text":"<p>Lemma. Let \\(m, n \\in \\mathbb{B}\\) be given. Then, for any \\(a, b \\in \\mathbb{Z}\\), there exists some \\(x\\) that satisfies</p> \\[ \\begin{align}     x &amp;\\equiv a \\pmod{m} \\\\     x &amp;\\equiv b \\pmod{n} \\end{align} \\] <p>Theorem. Chinese Remainder Theorem. Let \\(n_1, \\ldots, n_k \\in \\mathbb{N}\\) be given such that \\(\\gcd(n_i, n_j) = 1\\). Then, for any integers \\(a_1, \\ldots, a_k\\), the system</p> \\[ \\begin{align}     x &amp;\\equiv a_1 \\pmod{n_1} \\\\     x &amp;\\equiv a_2 \\pmod{n_2} \\\\     \\ldots     x &amp;\\equiv a_k \\pmod{n_k} \\end{align} \\] <p>has a solution. Additionally, all systems are congruent modulo \\(n_1 n_2 \\ldots n_k\\).</p>"},{"location":"math/abstract-algebra/17-polynomial-rings/","title":"Chapter 17 - Polynomial Rings","text":""},{"location":"math/abstract-algebra/17-polynomial-rings/#section-171-polynomial-rings","title":"Section 17.1 - Polynomial Rings","text":"<p>Throughout this chapter, we will assume that \\(R\\) is a commutative ring with identity.</p> <p>Definition. Any expression of the form</p> \\[ f(x) = \\sum_{i=0}^n a_i x^i = a_0 + a_1x + a_2x^2 + \\ldots + a_n x^n \\] <p>where \\(a_i \\in R\\) and \\(a_n \\neq 0\\) is called a polynomial over \\(R\\) with indeterminate \\(x\\). The elements \\(a_0, a_1, \\ldots, a_n\\) are the coefficients of \\(f\\). The coefficient \\(a_n\\) is the leading coefficient.</p> <p>Definition. A polynomial is known as monic if the leading coefficient is equal to \\(1\\).</p> <p>Definition. The degree of \\(f\\) is the largest nonnegative number such that \\(a_n \\neq 0\\), written as \\(\\deg f(x) = n\\). If no such number exists, that is, \\(f(x) = 0\\), we say the degree of \\(f\\) is $-\\infty%.</p> <p>Definition. We denote the set of all polynomials with coefficients in \\(R\\) as \\(R[x]\\).</p> <p>Two polynomials are equal if and only if their corresponding coefficients are equal. When combined with standard addition and multiplication, \\(R[x]\\) forms a ring.</p> <p>Theorem. If \\(R\\) is commutative and has identity, so does \\(R[x]\\).</p> <p>Definition. The ring of polynomials with \\(n\\) indeterminates and coefficients in \\(R\\) is defined as \\(R[x_1][x_2][\\ldots][x_n] = R[x_1, x_2, \\ldots, x_n]\\).</p> <p>Definition. The evaluation homomorphism is the homomorphism \\(\\varphi: R[x] \\rightarrow R\\) defined as \\(\\varphi(p(x)) = p(\\alpha)\\) for some \\(\\alpha \\in R\\).</p>"},{"location":"math/abstract-algebra/17-polynomial-rings/#section-172-the-division-algorithm","title":"Section 17.2 - The Division Algorithm","text":"<p>Theorem. Given \\(f(x), g(x) \\in F[x]\\), where \\(F\\) is a field and \\(g(x) \\neq 0\\), there exist unique polynomials \\(q(x), r(x) \\in F[x]\\) such that</p> \\[ f(x) = g(x)q(x) + r(x) \\] <p>where either \\(\\deg r(x) &lt; \\deg g(x)\\) or \\(r(x)\\) is the zero polynomial.</p> <p>Corollary. Let \\(F\\) be a field. Then, an element \\(\\alpha \\in F\\) is a zero of \\(p(x) \\ in F[x]\\) if and only if \\((x-\\alpha)\\) is a factor of \\(p(x)\\).</p> <p>Corollary. Let \\(F\\) be a field. Then, a nonzero polynomial \\(p(x) \\in F[x]\\) with degree \\(n\\) can have at most \\(n\\) distinct zeros in \\(F\\).</p> <p>Definition. A monic polynomial \\(d(x)\\) is the greatest common divisor of polynomials \\(p(x), q(x) \\in F[x]\\) if \\(d(x)\\) evenly divides both \\(p(x)\\) and \\(q(x)\\). We write \\(\\gcd(p(x), q(x)) = d(x)\\). This polynomial is unique.</p> <p>Definition. Two polynomials are relatively prime if their greatest common divisor is \\(1\\).</p>"},{"location":"math/abstract-algebra/17-polynomial-rings/#section-173-irreducible-polynomials","title":"Section 17.3 Irreducible Polynomials","text":"<p>Definition A non-constant polynomial \\(f(x) \\ in F[x]\\) is irreducible over a field \\(F\\) if it cannot be expressed as the product of two non-identity polynomials \\(g(x)\\) and \\(h(x)\\) in \\(F[x]\\), with the degree of both polynomials strictly less than the  degree of \\(f(x)\\).</p> <p>Lemma. Let \\(p(x) \\in \\mathbb{Q}[x]\\). Then, with \\(r, s \\in \\mathbb{Z}, a(x) \\in \\mathbb{N}[x]\\), we can write \\(p(x) = \\frac{r}{s} a(x)\\).</p> <p>Lemma. Gauss's Lemma. Let \\(p(x) \\in \\mathbb{Z}[x]\\) be monic such that \\(p(x)\\) factors into two polynomials \\(\\alpha(x), \\beta{x} \\in \\mathbb{Q}[x]\\), with the degrees of both strictly less than the degree of \\(p(x)\\). Then, there exists two polynomials \\(a(x), b(x) \\in \\mathbb{Z}[x]\\) such that \\(p(x) = a(x)b(x)\\), and \\(\\deg \\alpha(x) = \\deg a(x)\\) and \\(\\deg \\beta(x) = \\deg b(x)\\).</p> <p>Corollary. Let \\(p(x) \\in \\mathbb{Z}[x]\\) be monic with constant term \\(a_0\\). Then, if \\(p(x)\\) has a zero in \\(\\mathbb{Q}\\), then it also has a zero \\(\\alpha\\) in \\(\\mathbb[Z]\\). Furthermore, \\(\\alpha\\) divides \\(a_0\\).</p> <p>Theorem. Eisenstein's Criterion. Let \\(p\\) be prime, and suppose that</p> \\[ f(x) = a_n x^n + \\ldots + a_0 \\in \\mathbb{Z}[x] \\] <p>Then, if \\(p | a_i\\) for \\(0 \\leq i &lt; n\\), but \\(p \\nmid a_n\\) and \\(p^2 \\nmid a_0\\), then \\(f(x)\\) is irreducible over \\(\\mathbb{Q}[x]\\).</p> <p>Theorem. If \\(F\\) is a field, then every ideal in \\(F[x]\\) is a principal ideal.</p> <p>Theorem. Let \\(F\\) be a field, and suppose \\(p(x) \\in F[x]\\). Then, the ideal \\(&lt;p(x)&gt;\\) is maximal if and only if \\(p(x)\\) is irreducible.</p>"},{"location":"math/abstract-algebra/18-integral-domains/","title":"Chapter 18 - Integral Domains","text":""},{"location":"math/abstract-algebra/18-integral-domains/#section-181-fields-of-fractions","title":"Section 18.1 - Fields of Fractions","text":"<p>Definition. Given an integral domain \\(D\\), we can construct a field \\(F\\) containing \\(D\\) by stating that any \\(p/q \\in F\\), and that any two elements \\(a/b = c/d\\) if and only if \\(ad = bc\\). We can consider this akin o a set of ordered pairs</p> \\[ S = \\{(a, b) : a, b \\in D \\text{ and } b \\neq 0 \\} \\] <p>Lemma. 18.1: The relation \\((a, b) ~ (c, d) \\text{ if } ad = bc\\) is an equivalence relation.</p> <p>Lemma. 18.2: The operations of addition and multiplication on \\(F\\) are well-defined.</p> <p>Lemma. 18.3: The set of equivalence classes of \\(S, F\\) under \\(~\\) form a field.</p> <p>Theorem. 18.4: Let \\(D\\) be an integral domain. Then, \\(D\\) can be embedded in a field of fractions \\(F_D\\) where any element in \\(F_D\\) can be expressed as the quotient of two elements in \\(D\\).</p> <p>Additionally, \\(F_D\\) is unique. That is, given field \\(E\\) such that \\(E \\supset D\\), there exists a map \\(\\psi: F_D \\rightarrow D\\) giving an isomorphism such that \\(\\psi(a) = a\\) for all \\(a \\in D\\).</p> <p>Corollary. 18.6: Let \\(F\\) be a field of characteristic \\(0\\). Then, \\(F\\) contains a subfield isomorphic to \\(\\mathbb{Q}\\).</p> <p>Corollary. 18.6: Let \\(F\\) be a field of characteristic \\(p\\). Then, \\(F\\) contains a subfield isomorphic to \\(\\mathbb{Z}_p\\).</p>"},{"location":"math/abstract-algebra/18-integral-domains/#section-182-factorization-in-integral-domains","title":"Section 18.2 - Factorization in Integral Domains","text":"<p>Definition. Let \\(R\\) be a commutative ring with identity, and \\(a, b \\in R\\). We say that \\(a\\) divides \\(b\\), that is, \\(a | b\\), if there exists some \\(c \\in R\\) such that \\(b = ac\\).</p> <p>Definition. A unit element is any element that has a multiplicative inverse.</p> <p>Definition. Two elements \\(a, b \\in R\\) are said to be associates if there exists some unit \\(u \\in R\\) such that \\(a = ub\\).</p> <p>Definition. Let \\(D\\) be an integral domain. A nonzero element \\(p \\in D\\) is said to be irreducible if when given \\(p = ab\\), either \\(a\\) or \\(b\\) is a unit.</p> <p>Definition. Let \\(D\\) be an integral domain. A nonzero element \\(p\\) is prime if when given \\(p = ab\\), either \\(p | a\\) or \\(p | b\\).</p> <p>Definition. Given integral domain \\(D\\), we say that \\(D\\) is a Unique Factorization Domain (UFD) if it satisfies the following criteria:</p> <ol> <li>Given \\(a \\in D, a \\neq 0\\), and \\(a\\) is not a unit, \\(a\\) can be written as a product of irreducible elements in \\(D\\).</li> <li>Let \\(a = p_1 \\ldots p_r = q_1 \\ldots q_s\\), where \\(p_i\\) and \\(q_i\\) are all irreducible. Then, \\(r = s\\), and there exists some function \\(\\pi \\in S_r\\) such that \\(p_i\\) and \\(q_{\\pi(j)}\\) are associates for \\(j = 1, \\ldots, r\\).</li> </ol> <p>Definition. A ring \\(R\\) is a principal ideal domain (PID) if every ideal of \\(R\\) is principal.</p> <p>Lemma. 18.11: Let \\(D\\) be an integral domain and \\(a, b \\in D\\). Then,</p> <ol> <li>\\(a | b\\) if and only if \\(\\langle b \\rangle \\subseteq \\langle a \\rangle\\)</li> <li>\\(a\\) and \\(b\\) are associates if and only if \\(\\langle b \\rangle = \\langle a \\rangle\\)</li> <li>\\(a\\) is a unit in \\(D\\) if and only if \\(\\langle a \\rangle = D\\).</li> </ol> <p>Theorem. 18.12: Let \\(D\\) be a PID, and let \\(\\langle p \\rangle\\) be a nonzero ideal in \\(D\\). Thus, \\(\\langle p \\rangle\\) is a maximal ideal if and only if \\(p\\) is irreducible.</p> <p>Corollary. 18.13: Let \\(D\\) be a PID. For any \\(p \\in D\\), if \\(p\\) is irreducible, then \\(p\\) is prime.</p> <p>Lemma. 18.14: Let \\(D\\) be a PID. Let \\(I_1 \\subseteq I_2 \\subseteq \\ldots\\). Then, there exists some integer \\(N\\) such that \\(I_n = I_N\\) for all \\(n &gt; N\\). That is, any chain of ideals converges.</p> <p>Definition. Any commutative ring that satisfies the above condition (the ascending chain condition), even if it's not a PID, is called a Noetherian ring.</p> <p>Theorem. 18.15: Every PID is a UFD. Note that the converse is not true.</p> <p>Corollary 18.16: Let \\(F\\) be a field. Then, \\(F[x]\\) is a UFD.</p> <p>Definition. Any integral domain \\(D\\) is a Euclidean domain with a Euclidean function \\(nu: D \\\\ \\{0\\} \\rightarrow \\mathbb{N}\\) that satisfies the following:</p> <ol> <li>Given \\(a, b \\neq 0\\), then \\(\\nu(a) \\leq \\nu(ab)\\).</li> <li>Given, \\(a, b \\in D\\) and \\(b \\neq 0\\), there exists some \\(q, r \\in D\\) such that \\(a = bq + r\\) and either \\(r = 0\\) or \\(\\nu(r) &lt; \\nu(b)\\).</li> </ol> <p>Example. Absolute value on \\(\\mathbb{Z}\\) is a Euclidean validation.</p> <p>Example. Degree on \\(F[x]\\) is a Euclidean validation.</p> <p>Example. \\(\\nu(a + bi) = a^2 + b^2\\) is a Euclidean validation over \\(\\mathbb{Z}[i]\\).</p> <p>Theorem. 18.21: Every Euclidean domain is a PID.</p> <p>Corollary. Every Euclidean domain is a UFD.</p> <p>Definition. Given a polynomial \\(p(x) \\in D\\), with \\(D\\) being an integer domain, we say that the content of \\(p(x)\\) is the greatest common divisor of its coefficients. Additionally, if the content is \\(1\\), we say that \\(p(x)\\) is primitive.</p> <p>Theorem. 18.24: Let \\(D\\) be a UFD, and \\(f(x), g(x) \\in D[x]\\) be primitive. Then, \\(f(x)g(x)\\) is primitive.</p> <p>Lemma. 18.25: Given \\(D\\) is a UFD, and \\(p(x), q(x) \\in D[x]\\), the content of \\(p(x)q(x)\\) is equal to the product of the contents of the individual polynomials</p> <p>Lemma. 18.26: Let \\(D\\) be a UFD and \\(F = F_D\\) be its field of fractions. Given \\(p(x) \\in D[x]\\), and \\(p(x) = f(x)g(x)\\) with \\(f(x), g(x) \\in F_D\\), we can say that \\(p(x) = f_1(x)g_1(x)\\) with \\(f_1(x), g_1(x) \\in D\\). Additionally, \\(\\deg f_1(x) = \\deg f(x)\\) and \\(\\deg g_1(x) = \\deg g(x)\\).</p> <p>As a direct consequence, we see the following.</p> <p>Corollary. Let \\(D\\) be a UFD, and \\(F = F_D\\). Then, a primitive polynomial \\(p(x) \\in D[x]\\) is irreducible in \\(D[x]\\) if and only if it is irreducible in \\(F[x]\\).</p> <p>Corollary. Let \\(D\\) be a UDF, and \\(F = F_D\\). Then, if a monic polynomial \\(p(x) \\ in D[x]\\) can be written as \\(p(x) = f(x)g(x)\\) with \\(f(x), g(x) \\in F_D[x]\\), then \\(p(x)\\) can be written as \\(p(x) = f_1(x)g_1(x)\\), where \\(f_1(x), g_1(x) \\in D[x]\\).</p> <p>Theorem. If \\(D\\) is as UFD, then \\(D[x]\\) is a UFD.</p> <p>Corollary. This theorem has several corollaries:</p> <ol> <li>Given a field \\(F\\), since \\(F\\) is a PID, it is also a UFD. Thus, \\(F[x]\\) is a UFD.</li> <li>The ring of polynomials over integers, \\(\\mathbb{Z}[x]\\) is a UFD.</li> <li>Given \\(D\\) is a UFD, \\(D[x]\\) is a UFD. Thus, \\(D[x_1, x_2]\\) is a UFD, and by induction, \\(D[x_1, \\ldots, x_n]\\) is a UFD.</li> </ol>"},{"location":"math/abstract-algebra/DF-10-modules/","title":"Dummit &amp; Foote Chapter 10 - Modules","text":""},{"location":"math/abstract-algebra/DF-10-modules/#section-101-basic-definitions-and-examples","title":"Section 10.1 - Basic Definitions and Examples","text":"<p>Definition. Let \\(R\\) be a ring. A left \\(R\\)-module or a left module over \\(R\\) is a nonempty set \\(M\\) together with</p> <ol> <li>A binary operation \\(+\\) on \\(M\\) under which \\(M\\) is an abelian group</li> <li>An action \\(\\times\\) of \\(R\\) on \\(M\\), that is, a map or function \\(R \\times M \\rightarrow M\\), denoted \\(rm\\), that for all \\(r, s \\in R, m, n \\in M\\) satisfies<ul> <li>\\((r + s)m = rm + sm\\)</li> <li>\\((rs)m = r(sm)\\)</li> <li>\\(r(m + n) = rm + rn\\)</li> <li>If \\(R\\) has identity \\(1\\), then \\(1m = m\\)</li> </ul> </li> </ol> <p>Theorem. If \\(R\\) is commutative, any left-module is also a right-module.</p> <p>Remark. Modules over a field \\(F\\) and vector spaces over \\(F\\) are identical.</p> <p>Definition An R-submodule is a subset\\(N \\subseteq M\\) which is closed under the action taken forall \\(r \\in R\\). That is, given \\(r \\in R, n \\in N\\), then \\(rn \\in N\\). Every module has at least two submodules: itself and the trivial (empty) submodule.</p> <p>Remark. If \\(F\\) is a field, submodules are equivalent to subspaces.</p> <p>Example. Let \\(F\\) be a field and \\(F[x]\\) a polynomial ring. Then, let \\(V\\) be a vector space of \\(F\\), and \\(T\\) be a linear transformation from \\(V\\) to itself. That is, \\(V: T \\rightarrow T\\). We know that \\(V\\) is an \\(F\\)-module. We will want to show that \\(V\\) can be written as an \\(F[x]\\)-module for some choice of \\(T\\). That is, we want an action \\(F[x] \\times V \\rightarrow V\\).</p> <p>Now, for a given linear transformation \\(T\\), consider some polynomial \\(p(x) = a_n x^n + \\ldots + a_0\\) and some \\(v \\in V\\). We define \\(p(x) \\times v\\) by$</p> \\[ p(x) \\times v = a_n T^n(v) + a_{n-1} T^{n-1}(v) + \\ldots + a_0 v \\] <p>with \\(T^n\\) being defined as applying \\(T\\) a total of \\(n\\) times.</p> <p>Proposition. Let \\(R\\) be a ring and \\(M\\) an \\(R\\)-module. Then, a subset \\(N\\) of \\(M\\) is a submodule of \\(M\\) if and only if</p> <ol> <li>\\(N \\neq \\emptyset\\)</li> <li>For all \\(r \\in R\\), \\(x, y \\in N\\), then \\(rx - y \\in N\\)</li> </ol> <p>Definition. Let \\(R\\) be a commutative ring with identity. An \\(R\\)-algebra is a ring \\(A\\) together with a ring homomorphism \\(f: R \\rightarrow A\\) such that \\(\\varphi(1_R) = 1_A\\). Thus, the subring \\(f(R) \\subseteq A\\) is contained in the center of \\(A\\).</p> <p>Recall. The center of a ring \\(A\\) is the subring \\(A'\\) such that for all \\(x, y \\in R'\\), then \\(xy = yx\\). In other words, it is the commutative subring of \\(A\\).</p> <p>Definition. Given two \\(R\\)-algebras \\(A, B\\), an *\\(R\\)-algebra homomorphism$ is a ring homomorphism \\(\\varphi: A \\rightarrow B\\) that maps \\(1_A \\rightarrow 1_B\\) such that \\(\\varphi(ra) = r\\varphi(a)\\).</p>"},{"location":"math/abstract-algebra/DF-10-modules/#section-102-quotient-modules-and-module-homomorphisms","title":"Section 10.2 - Quotient Modules and Module Homomorphisms","text":"<p>Definition. Let \\(R\\) be a ring and \\(M, N\\) be \\(R\\)-modules. then a ring homomorphism \\(\\varphi: M \\rightarrow N\\) is an \\(R\\)-module homomorphism if for all \\(r \\in R\\), \\(\\varphi(rx) = r\\varphi(x)\\).</p> <p>Theorem. An \\(R\\)-module homomorphism is an isomorphism if it is 1-1 and onto, and said modules are isomorphic.</p> <p>Definition. Let \\(M, N\\) be \\(R\\)-modules. The set \\(\\text{Hom}_R(M, N)\\) is the set of all homomorphisms from \\(M\\) to \\(N\\).</p> <p>Proposition. Let \\(M\\), \\(N\\), and \\(L\\) be \\(R\\)-modules. Then,</p> <ol> <li>A function \\(\\varphi: M \\rightarrow N\\) is an \\(R\\)-module homomorphism if and only if \\(\\varphi(rx + y) = r\\varphi(x) + \\varphi(y)\\) for all \\(x, y \\in M\\) and \\(r \\in R\\).</li> <li>Let \\(\\varphi, \\psi \\in \\text{Hom}_R(M, N)\\). Then, define \\(\\varphi + \\psi\\) as</li> </ol> \\[ (\\varphi + \\psi)(m) = \\varphi(m) + \\psi(m) \\] <p>Then, \\(\\varphi + \\psi \\in \\text{Hom}_R(M, N)\\). Additionally, if \\(R\\) is commutative, with \\((r\\varphi)(m) = r(\\varphi(m))\\), then \\(r\\varphi \\in \\text{Hom}_R(M,N)\\) 3. If \\(\\varphi \\in \\text{Hom}_R(L, M)\\) and \\(\\psi \\in \\text{Hom}_R(M, N)\\), then \\(\\psi \\circ \\varphi \\in \\text{Hom}_R(L, N)\\) 4. \\(\\text{Hom}_R(M, M)\\) is a ring with identity. With \\(R\\) being commutative, \\(\\text{Hom}_R(M, M)\\) is an \\(R\\)-algebra.</p> <p>Proposition. Let \\(R\\) be a ring, \\(M\\) an \\(R\\)-module, and \\(N \\subseteq M\\) an \\(R\\)-submodule. then, \\(M/N\\) can be made into an \\(R\\)-module by defining addition. With \\(r \\in R\\) and \\(x + N \\in M/N\\),</p> \\[ r(x + N) = (rx) + N \\] <p>That is,</p> \\[ r \\overline{x} = \\overline{rx} \\] <p>Definition. Let \\(A, B\\) be submodules  of the \\(R\\)-module \\(M\\). Then, the sum of \\(A\\) and \\(B\\) is defined as</p> \\[ A + B = {a + b | a \\in A, b \\in B} \\] <p>This is the smallest submodule that contains both \\(A\\) and \\(B\\).</p> <p>Theorem. First Isomorphism Theorem. Let \\(M, N\\) be \\(R\\)-modules, and \\(\\varphi: M \\rightarrow N\\) be an \\(R\\)-module homomorphism. Then, \\(\\ker \\varphi\\) is a submodule of \\(M\\), and \\(M / \\ker \\varphi \\cong \\varphi(M)\\).</p> <p>Theorem. Second Isomorphism Theorem. Let \\(A, B\\) be submodules of the \\(R\\)-module \\(M\\). Then, \\((A + B)/B \\cong A/(A \\cap B)\\).</p> <p>Theorem. Third Isomorphism Theorem. Let \\(M\\) be an \\(R\\)-module, and \\(A \\subseteq B\\) be submodules of \\(M\\). Then, \\(\\frac{M/A}{B/A} \\cong M/B\\).</p> <p>Theorem. Lattice Isomorphism Theorem. Let \\(N\\) be a submodule of the \\(R\\)-module \\(M\\). Then, there is a bijection between submodules of \\(M\\) containing \\(N\\) and submodules of \\(M/N\\). This is given by \\(A \\leftrightarrow A/N\\), for \\(A \\supseteq N\\).</p>"},{"location":"math/abstract-algebra/DF-10-modules/#section-103-generation-of-modules-direct-sums-and-free-modules","title":"Section 10.3 - Generation of Modules, Direct Sums, and Free Modules","text":"<p>Definition. Let \\(M\\) be an \\(R\\)-module and \\(N_1, \\ldots, N_n\\) be submodules of \\(M\\).</p> <ol> <li>The sum of \\(N_1, \\ldots, N_n\\) is the set of all finite sums of elements from the sets \\(N_i\\). That is, \\(N_1, \\ldots, N_n := \\{a_1 + a_2 + \\ldots + a_n | a_i \\in N_i\\}\\)</li> <li>For any subset \\(A\\) of \\(M\\), let \\(RA = \\{r_1 a_1 + r_2 a_2 + \\ldots + r_m a_m | r_i \\in R, a_i \\in A\\}\\). If \\(N\\) is a submodule of \\(M\\) such that \\(N = RA\\), then \\(A\\) is called the generating set for \\(N\\).</li> <li>A submodule \\(N\\) of \\(M\\) is finitely generated if there is some finite subset \\(A\\) of \\(M\\) such that \\(N = RA\\). That is, \\(N\\) is generated by some finite subset.</li> <li>A submodule of \\(M\\) (up to equality) is \\(cyclic\\) if there exists some element \\(a \\in M\\) such that \\(N = Ra = \\{ra | r \\in R\\}\\).</li> </ol> <p>Definition. Let \\(M_1, \\ldots, M_k\\) be a collection of \\(R\\)-modules. Then, the direct product is defined as</p> \\[ M_1 \\otimes \\ldots M_k = (m_1, \\ldots, m_k), m_i \\in M_i \\] <p>This direct product is in itself an \\(R\\)-module.</p> <p>Proposition. Let \\(N_1, \\ldots, N_n\\) be submodules of the \\(R\\)-module \\(M\\). Then, the following are equivalent:</p> <ol> <li>The map \\(\\pi: N_1 \\otimes \\ldots \\otimes N_k \\rightarrow N_1 + \\ldots + N_k\\) defined by \\(\\pi(a_1, \\ldots, a_n) = a_1 + \\ldots + a_n\\) is an isomorphism</li> <li>\\(N_j \\cup (N+1 + \\ldots + N_{j-1} + N{j+1} + \\ldots + N_n) = 0\\) for all \\(j \\in \\{1, 2, \\ldots, k\\}\\)</li> <li>Every \\(x \\in N_1 + \\ldots + N_n\\) can be written uniquely in the form \\(a_1 + \\ldots + a_n\\), with \\(a_i \\in N_i\\)</li> </ol> <p>Definition. An \\(R\\)-module \\(F\\) is said to be free on the subset \\(A\\) of \\(F\\) if for every nonzero \\(x \\in F\\), there exists nonzero elements \\(r_1, \\ldots, r_n\\) of \\(R\\) and unique \\(a_1, \\ldots, a_n\\) such that \\(x = r_1 a_1 + \\ldots + r_n a_n\\) for some \\(n \\in \\mathbb{Z}^+\\). That is, \\(A\\) is a basis or set of free generators of \\(F\\).</p> <p>Theorem. For any set \\(A\\), there is a free \\(R\\)-module \\(F(A)\\) on \\(A\\) such that \\(F(A)\\) satisfies the universal property: if \\(M\\) is any \\(R\\)-module, and \\(\\varphi: A \\rightarrow M\\) is a map of sets, there exists a unique \\(R\\)-module homomorphism: \\(\\Phi: F(A) \\rightarrow M\\) such that \\(\\Phi(a) = \\varphi(a)\\) for all \\(a \\in A\\).</p> <p>Corollary. If \\(F_1\\) and \\(F_2\\) are free modules on \\(A\\), then there is a unique isomorphism between \\(F_1\\) and \\(F_2\\), which is the identity map on A.</p> <p>Corollary. If \\(F\\) is a free \\(R\\)-module with basis \\(A\\), then \\(F \\cong F(A)\\).</p> <p>Definition For a free module \\(F\\) with basis \\(A\\), if \\(R\\) is commutative, then the rank of \\(F\\) is the cardinality of \\(A\\).</p>"},{"location":"math/abstract-algebra/DF-10-modules/#section-104-tensor-products-of-modules","title":"Section 10.4 - Tensor Products of Modules","text":"<p>Skipped</p>"},{"location":"math/abstract-algebra/DF-10-modules/#section-105-exact-sequences-projective-injective-and-flat-modules","title":"Section 10.5 - Exact Sequences - Projective, Injective, and Flat Modules","text":"<p>Skipped</p>"},{"location":"math/abstract-algebra/DF-12-modules-pids/","title":"Dummit &amp; Foote Chapter 12 - Modules over Principal Ideal Domains","text":""},{"location":"math/abstract-algebra/DF-12-modules-pids/#section-121-the-basic-theory","title":"Section 12.1 The Basic Theory","text":"<p>Definition. The left \\(R\\)-module \\(M\\) is said to be a Noetherian \\(R\\)-module if there are no infinitely increasing chains of submodules. That is, given</p> \\[ M_1 \\subseteq M_2 \\subseteq \\ldots \\] <p>there exists some \\(k \\in \\mathbb{N}\\) such that given any \\(n \\in \\mathbb{N}\\) with \\(n \\geq k\\), then \\(M_n = M_k\\).</p> <p>Definition. A ring \\(R\\) is Noetherian if it is Noetherian when viewed as a left \\(R\\)-module over itself.</p> <p>Theorem. Let \\(R\\) be a ring and \\(M\\) a left \\(R\\)-module. Then, the following are equivalent:</p> <ol> <li>\\(M\\) is Noetherian</li> <li>Every nonempty set of submodules of \\(M\\) contains a maximal element under inclusion</li> <li>Every submodule of \\(M\\) is finitely-generated</li> </ol> <p>Corollary. If \\(R\\) is a principal ideal domain (PID), then all nonempty set of ideals of \\(R\\) has a maximal element. Additionally, \\(R\\) is as Noetherian ring.</p> <p>Proposition. Let \\(R\\) be an integral domain, and \\(M\\) be a free \\(R\\)-module of rank \\(n &lt; \\infty\\). Then, given \\(S\\) is subset \\(M\\) with \\(|S| &gt; n\\), the elements of \\(S\\) are \\(R\\)-linearly dependent.</p> <p>Definition. Given \\(R\\) an integral domain and \\(M\\) an \\(R\\)-module,</p> \\[ \\text{Tor}(M) = \\{ x \\in M | rx = 0 \\text{ for any } r \\neq 0 \\} \\] <p>This is the torsion submodule of \\(M\\). If \\(\\text{Tor}(M)\\) is empty, then \\(M\\) is torsion-free.</p> <p>Definition Let \\(R\\) be an integral domain and \\(M\\) be an \\(R\\)-module. Then, given a submodule \\(N\\),</p> \\[ \\text{Ann}_R(N) = \\{r \\in R | rn = 0 \\text{ for all } n \\in N \\} \\] <p>This ideal of \\(R\\) is the annihilator of \\(N\\). That is, \\(\\text{Ann}(N)\\) is the set of elements of \\(R\\) such that \\((r)N = \\{ 0 \\}\\).</p> <p>Note that if \\(N\\) is not a torsion submodule of \\(M\\), then \\(\\text{Ann}(N) = (0)R\\). Additionally, given \\(N, L\\) are submodules of \\(M\\) with \\(N \\subseteq L\\), then \\(\\text{Ann}(N) \\subseteq \\text{Ann}(L)\\).</p> <p>Additionally, if \\(R\\) is a PID, as \\(\\text{Ann}_R(N)\\) is an ideal, \\(\\text{Ann}(N) = (n)R\\) and \\(\\text{Ann}(L) = (l)R\\) for some \\(n, l \\in R\\) such that \\(n | l\\).</p> <p>Definition. Given any integral domain \\(R\\), the rank of an \\(R\\)-module \\(M\\) is the maximum number of \\(R\\)-linearly independent elements of M.</p> <p>Corollary. The rank of a free module is the number of generating elements.</p> <p>Theorem. Let \\(R\\) be a principal ideal domain, and \\(M\\) be a free \\(R\\)-module of finite rank \\(m\\), and \\(N\\) be a submodule of \\(M\\). Then,</p> <ol> <li>\\(N\\) is a free submodule with rank \\(n \\leq m\\).</li> <li>There exists a basis \\(y_1, y_2, \\ldots, y_m\\) of \\(M\\) so that \\(r_1 y_1, r_2 y_2, \\ldots, r_m y_n\\) is a basis of \\(N\\) for some \\(r_i \\in R\\) and \\(r_1 | r_2 | \\ldots | r_n\\)</li> </ol> <p>Theorem. Fundamental Theorem, Existence: Invariant Form. Let \\(R\\) be a PID and \\(M\\) be a finitely generated \\(R\\)-module. THen,</p> <ul> <li>\\(M\\) is isomorphic for some \\(r \\in \\mathbb{N}\\cup{0}\\), \\(a_1, \\ldots, \\a_m \\neq 0 \\in R\\) such that \\(a_1 | a_2 | \\ldots | a_m\\), with</li> </ul> \\[ M \\cong R^{\\oplus r} \\oplus \\frac{R}{(a_1)R} \\oplus \\frac{R}{(a_2)R} \\oplus \\ldots \\oplus \\frac{R}{(a_m)R} \\] <ul> <li> <p>\\(M\\) is torsion-free if and only if \\(M\\) is free</p> </li> <li> <p>Note that</p> </li> </ul> \\[ \\text{Tor}{M} \\cong \\frac{R}{(a_1)R} \\oplus \\frac{R}{(a_2)R} \\oplus \\ldots \\oplus \\frac{R}{(a_m)R} \\] <p>As a consequence, \\(M\\) is a torsion module if and only if \\(r = 0\\).</p> <p>Definition. In the above, \\(r\\) is the free rank of \\(M\\), and \\(a_1, \\ldots, a_m\\) are the invariant factors of \\(M\\).</p> <p>Theorem. Fundamental Theorem, Existence: Elementary Divisor Form. The sum above can be written as</p> \\[ M \\cong R^{\\oplus r} \\oplus \\frac{R}{(p_1^{\\alpha_1})R} \\oplus \\frac{R}{(p_2^{\\alpha_2})R} \\oplus \\ldots \\oplus \\frac{R}{(p_t^{\\alpha_t})R} \\] <p>with \\(p_t\\) non-unique primes and \\(\\alpha_t\\) non-unique, but with \\((p_t^{\\alpha_t})\\) unique. These are called the elementary divisors of \\(M\\).</p> <p>TODO: Incomplete for Now</p>"},{"location":"math/abstract-algebra/DF-13-fields/","title":"Dummit &amp; Foote Chapter 13 - Field Theory","text":""},{"location":"math/abstract-algebra/DF-13-fields/#section-131-basic-theory-of-field-extensions","title":"Section 13.1 Basic Theory of Field Extensions","text":"<p>Definition. The characteristic of a field \\(F\\) is the smallest positive integer \\(p\\) such that \\(1_F * p = 0\\). It follows that \\(p\\) is \\(0\\) or prime, and \\(p \\alpha = 0\\) for any \\(\\alpha \\in F\\).</p> <p>Definition. If \\(K, F\\) are fields such that \\(F \\subseteq K\\), then \\(K\\) is an extension field or extension of \\(F\\), denoted \\(K / F\\).</p> <p>Definition. The degree (or relative degree or index) of \\(K/F\\), denoted \\([K:F]\\), is the dimension of \\(K\\) as a \\(F\\)-vector space.</p> <p>Theorem. Let \\(F\\) be a field, \\(p(x) \\in F[x]\\). Then, there exists a \\(K\\) such that \\(p(x)\\) has a root in \\(K\\).</p> <p>Theorem. Let \\(F\\) be a field, \\(p(x) \\in F[x]\\). Then, \\(K = \\frac{F[x]}{(p(x))}\\) and \\(\\theta = x \\amod{p(x)}\\), \\(K\\) has a basis of \\(1, \\theta, \\ldots, \\theta^{n-1}\\) where \\(n = \\deg(p)\\).</p> <p>Theorem. Let \\(K/F\\) and \\(\\alpha, \\beta, \\ldots \\in K\\). Then, the smallest subfield of \\(K\\) containing \\(F\\) and \\(\\alpha, \\beta, \\ldots\\) is \\(F(\\alpha, \\beta, \\ldots)\\), which is the field generated by \\(\\alpha, \\beta, \\ldots\\) over \\(F\\).</p> <p>Definition. If \\(K\\) is generated by \\(F(\\alpha)\\), then \\(K\\) is a simple extension of \\(F\\).</p> <p>Theorem. Let \\(F\\) be a field, \\(p(x) \\in F[x]\\) be irreducible. Then, if \\(\\alpha\\) is a root of \\(p(x)\\) and \\(K\\) is an extension of \\(F\\) containing \\(\\alpha\\), then \\(F(\\alpha) \\cong \\frac{F[x]}{(p(x))}\\).</p> <p>TODO</p>"},{"location":"math/diffeq/1-intro/","title":"Section 1 - Basic Concepts","text":""},{"location":"math/diffeq/1-intro/#section-11-definitions","title":"Section 1.1 - Definitions","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Definition. A differential equation is an equation that describes a function in terms of its derivatives. Examples of differential equations include Newton's Laws, among others.</p> <p>Definition. The order of a differential equation is the largest derivative present in the equation with a non-zero constant.</p> <p>Definition. A differential equation that only involves derivatives with respect to one variable is called an ordinary differential equation (ODE).</p> <p>Definition. A differential equation that describes a function in terms of derivatives with respect to more than one linearly-independent variable is called a partial equation.</p> <p>Definition. A linear differential equation is any differential equation that cn be written in the following form:</p> \\[ a_n(t)y^{(n)}(t) + a_{n-1}(t)+y^{n-1}(t) + \\ldots + a_1(t)y'(t) + a_0(t)y(t) = g(t) \\] <p>Note that \\(a_n(t)\\) does not depend on any derivative of \\(y\\), so the presence of terms such as \\(e^y\\) or \\(\\sqrt{y'}\\) signal that the equation is nonlinear.</p> <p>Definition. The solution(s) to a differential equation over an interval \\(\\alpha &lt; t &lt; \\beta\\) are any function(s) \\(y(t)\\) that satisfy the differential equation.</p> <p>Definition. The initial conditions are a condition or set of conditions that constrain the possible solution sets.</p> <p>Definition. An Initial Value Problem is a differential equation along with the appropriate boundary or initial conditions.</p> <p>Definition. The integral of validity for a solution to a differential equation is the largest possible interval containing the initial conditions for which the solution is valid.</p> <p>Definition. The general solution to a differential equation is the most general form a solution to a differential equation can take without requiring the initial conditions.</p> <p>Definition. The actual solution to a differential equation is the specific solution that satisfies the differential equation and the boundary conditions.</p> <p>Definition. A solution is said to be explicit if it can be written in the form \\(y = y(t)\\). Otherwise, it is said to be implicit.</p>"},{"location":"math/diffeq/1-intro/#section-12-directional-fields","title":"Section 1.2 - Directional Fields","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Definition. A directional field is the graph of a \\(t\\) vs. \\(y(t)\\), with vectors drawn at each point with a slope corresponding to \\(y'(t)\\). Notably, each arrow will be pointed right (towards increasing \\(t\\)).</p>"},{"location":"math/diffeq/2-1st-order/","title":"Section 2 - First Order Differential Equations","text":""},{"location":"math/diffeq/2-1st-order/#section-21-linear-differential-equations","title":"Section 2.1 - Linear Differential Equations","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Let the following first-order linear differential equation be given, with \\(p(t)\\) and \\(g(t)\\) continuos.</p> \\[ \\frac{dy}{dt} + p(t)y = g(t) \\]"},{"location":"math/diffeq/2-1st-order/#deriving-the-solution","title":"Deriving the Solution","text":"<p>Next, we let \\(\\mu(t)\\) be our integrating factor. Multiply both sides of the equation through by \\(\\mu(t)\\).</p> \\[ \\mu(t)\\frac{dy}{dt} + \\mu(t)p(t)y = \\mu(t)g(t) \\] <p>Now, define \\(\\mu(t)\\) so that \\(\\mu(t)p(t) = \\mu'(t)\\). Thus, we can state the following:</p> \\[ \\mu(t)\\frac{dy}{dt} + \\mu'(t)y = \\mu(t)g(t) \\] <p>The left of the preceding equation is simply the product rule, so we can write \\((\\mu(t)y(t))' = \\mu(t)g(t)\\). Take the integral of both sides.</p> \\[\\begin{align}     \\int (\\mu(t)y(t))' dt &amp;= \\int \\mu(t)g(t) \\\\     \\mu(t)y(t) + C &amp;= \\int \\mu(t)g(t) dt \\\\     y(t) &amp;= \\frac{\\int \\mu(t)g(t) dt - C}{\\mu(t)} \\end{align}\\] <p>Let \\(C\\) absorb the negative sig, and we see the following.</p> \\[ y(t) = \\frac{\\int \\mu(t)g(t) dt + C}{\\mu(t)} \\] <p>This is the general solution to the differential equation. However, it is incomplete, as we do not know \\(\\mu(t)\\)</p> <p>To derive the function, recall that we defined \\(\\mu(t)p(t) = \\mu'(t)\\). Thus, we can rewrite this equation.</p> \\[\\begin{align}     \\frac{\\mu'(t)}{\\mu(t)} &amp;= p(t) \\\\     (\\ln \\mu(t))' &amp;= p(t) \\\\ \\end{align}\\] <p>Integrate both sides.</p> \\[\\begin{align}     \\ln \\mu(t) + k = \\int p(t) dt \\\\     \\mu(t) &amp;= e^{\\int p(t) dt + k} \\\\     &amp;= e^k e^{\\int p(t) dt} \\end{align}\\] <p>As \\(k\\) is an unknown constant, rewrite this as \\(\\mu(t) = k \\exp(\\int p(t) dt)\\).</p>"},{"location":"math/diffeq/2-1st-order/#summary","title":"Summary","text":"<p>The following differential equation is given.</p> \\[ \\frac{dy}{dt} + p(t)y = g(t) \\] <p>To find a solution to this differential equation, construct the integrating factor \\(\\mu(t)\\).</p> \\[\\mu(t) = k \\exp(\\int p(t) dt)\\] <p>Thus, the solution to the differential equation can be written as the following.</p> \\[ y(t) = \\frac{\\int \\mu(t)g(t) dt + C}{\\mu(t)} \\]"},{"location":"math/diffeq/2-1st-order/#section-22-separable-differential-equations","title":"Section 2.2 - Separable Differential Equations","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Let the following differential equation of the following forms be given.</p> <p>\\begin{align}     N(y) \\frac{dy}{dx} &amp;= M(x)     \\frac{dy}{dx} &amp;= \\frac{M(x)}{N(y)} \\     \\frac{dy}{dx} &amp;= \\frac{N(y)}{M(x)} \\     \\frac{dy}{dx} &amp;= N(y)M(x) \\ \\end{align}.</p> <p>For the sake of simplicity, select the following form:</p> \\[ N(y) \\frac{dy}{dx} = M(x) \\] <p>Thus, integrate both sides with respect to \\(x\\).</p> \\[ \\int N(y) \\frac{dy}{dx} dx = \\int M(x) dx \\] <p>Since \\(y\\) is really \\(y(x)\\), we can make the following substitution:</p> \\[ u = y(x) \\text{ and } du = y'(x)dx = \\frac{dy}{dx} dx \\] <p>This reduces the integral to the following:</p> \\[ \\int N(u) du = \\int M(x) dx \\] <p>This is solvable from here.</p>"},{"location":"math/diffeq/2-1st-order/#section-24-bernoulli-equations","title":"Section 2.4 - Bernoulli Equations","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Let a differential equation of the following form be given, with \\(n \\in \\mathbb{N}; n \\geq 2\\)</p> \\[ y' + p(x)y = q(x)y^n \\] <p>This is a Bernoulli equation.</p> <p>Divide by \\(y^n\\).</p> \\[ y^{-n}y' + p(x)y^{1-n} = q(x) \\] <p>Now, make the substitution \\(v = y^{1-n}\\). Thus, the derivative is as follows.</p> \\[ v' = (1-n)y^{-n}y' \\] <p>Substituting into the first equation yields the following.</p> \\[ \\frac{1}{1-n}v' + p(x)v = q(x) \\] <p>After solving, be sure to rewrite in terms of \\(y\\).</p>"},{"location":"math/diffeq/3-2nd-order/","title":"Section 3 - Second Order Differential Equations","text":""},{"location":"math/diffeq/3-2nd-order/#section-31-basic-concepts","title":"Section 3.1 - Basic Concepts","text":"<p>This section is from Paul's Online Math Notes.</p> <p>All second-order differential equations can be written in the following form:</p> \\[ p(t) y'' + q(t) y' + r(t) y = g(t) \\] <p>In the case where \\(p(t)\\), \\(q(t)\\), and \\(r(t)\\) are constants, we write the equation as the following:</p> \\[ ay'' + by' + cy = g(t) \\] <p>This is a second-order differential equation with constant coefficients.</p> <p>Definition. In the event that \\(g(t) = 0\\), we say the equation is homogenous. Otherwise, the equation is nonhomogeneous.</p> <p>Definition. Principal of Superposition. Let \\(y_1(t)\\) and \\(y_2(t)\\) be solutions to a linear, homogenous differential equation. Then, any linear combination of said solutions is also a solution to the differential equation. In other words, with \\(c_1, c_2 \\in \\mathbb{R}\\), the following is a solution to a differential equation.</p> \\[ y(t) = c_1 y_1(t) + c_2 y_2(t) \\] <p>Given a second-order homogenous differential equation with constant coefficients, we assume solutions of the following form:</p> \\[ y(t) = e^{rt} \\] <p>Substituting this equation into the differential equation, we see the following:</p> \\[ e^{rt}(ar^2 + br + c) = 0 \\] <p>Thus, we allow the characteristic equation of the differential equation to be as follows:</p> \\[ ar^2 + br + c = 0 \\]"},{"location":"math/diffeq/3-2nd-order/#section-32-real-distinct-roots","title":"Section 3.2 - Real &amp; Distinct Roots","text":"<p>This section is from Paul's Online Math Notes.</p> <p>When the two roots to the characteristic equation are discrete roots in the real numbers, we see the following solutions.</p> \\[ y_1(t) = e^{r_1 t} \\] \\[ y_2(t) = e^{r_2 t} \\] <p>Thus,</p> \\[ y(t) = c_1 e^{r_1 t} + c_2 e^{r_2 t} \\]"},{"location":"math/diffeq/3-2nd-order/#section-33-complex-roots","title":"Section 3.3 - Complex Roots","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Let the solutions to the characteristic equation be of the following form:</p> \\[ r_{1,2} = \\lambda \\pm \\mu i \\] <p>Thus, our two solutions are</p> \\[ y_1(t) = e^{(\\lambda + \\mu i)t} \\] \\[ y_2(t) = e^{(\\lambda - \\mu i)t} \\] <p>Recall Euler's Formula:</p> \\[ e^{i \\theta} = \\cos \\theta + i \\sin \\theta \\] <p>A corollary of Euler's formula is the following:</p> \\[ e^{-i \\theta} = \\cos(-\\theta) + i \\sin(-\\theta) = \\cos \\theta - i \\sin \\theta \\] <p>Thus, we can write our solutions as the following:</p> \\[\\begin{align}     y_1(t) &amp;= e^{(\\lambda + \\mu i)t} &amp;= e^{\\lambda t} e^{i \\mu t} &amp;= e^{\\lambda t}(\\cos(\\mu t) + i \\sin(\\mu t)) \\\\     y_2(t) &amp;= e^{(\\lambda - \\mu i)t} &amp;= e^{\\lambda t} e^{-i \\mu t} &amp;= e^{\\lambda t}(\\cos(\\mu t) - i \\sin(\\mu t)) \\end{align}\\] <p>A linear combination of the two solutions can be written as the following:</p> \\[ y(t) = c_1 e^{\\lambda t} \\cos(\\mu t) + c_2 e^{\\lambda t} \\sin(\\mu t) \\]"},{"location":"math/diffeq/3-2nd-order/#section-34-repeated-roots","title":"Section 3.4 - Repeated Roots","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Assume the solutions to the characteristic equations are \\(r = r_1 = r_2\\). Thus, the two equations \\(y_t(t)\\) and \\(y_2(t)\\) are not linearly independent.</p> <p>After a lot of algebra, we see that</p> \\[y_1(t) = e^{rt}\\] \\[y_2(t) = t e^{rt}\\]"},{"location":"math/diffeq/3-2nd-order/#section-35-reduction-of-order","title":"Section 3.5 - Reduction of Order","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Skipped.</p>"},{"location":"math/diffeq/3-2nd-order/#section-36-fundamental-set-of-solutions-wronskian","title":"Section 3.6 - Fundamental Set of Solutions, Wronskian","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Definition. Given two functions \\(f(t)\\), \\(g(t)\\), the Wronskian is defined as</p> \\[ W(f,g) = \\det \\begin{vmatrix}   f(t) &amp; g(t) \\\\   f'(t) &amp; g'(t) \\end{vmatrix} \\] <p>Definition. If \\(W(f, g) \\neq 0\\), then \\(f(t)\\) and \\(g(t)\\) are said to form a fundamental set of solutions, and can be superimposed to form the general solution.</p>"},{"location":"math/diffeq/3-2nd-order/#section-38-nonhomogeneous-differential-equations","title":"Section 3.8 - Nonhomogeneous Differential Equations","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Assume we have the differential equation as follows:</p> \\[ y'' + p(t) y' + q(t) y = g(t) \\] <p>The equivalent homogenous differential equation is</p> \\[ y'' + p(t) y' + q(t) y = 0 \\] <p>Theorem. Assume \\(Y_1(t)\\), \\(Y_2(t)\\) are solutions to the nonhomogeneous differential equations. Then, \\(Y_1(t) - Y_2(t)\\) is a solution to the homogenous differential equation. This can be proved by substitution.</p> <p>Thus, with \\(y_h(t)\\) the solution to the homogenous problem, and \\(y_p(t)\\) the solution to this particular problem, we can say that the general form of the solution to this differential equation is</p> \\[ y(t) = y_h(t) + y_p(t) \\]"},{"location":"math/diffeq/3-2nd-order/#section-39-undetermined-coefficients","title":"Section 3.9 - Undetermined Coefficients","text":"<p>This section is from Paul's Online Math Notes.</p> <p>We know the following guesses for functions.</p> \\(g(t)\\) \\(y_p\\) guess \\(\\alpha e^{\\beta t}\\) \\(A e^{\\beta t}\\) \\(a \\cos(\\beta t)\\) \\(A \\cos(\\beta t) + B \\sin(\\beta t)\\) \\(b \\sin(\\beta t)\\) \\(A \\cos(\\beta t) + B \\sin(\\beta t)\\) \\(a \\cos(\\beta t) + \\sin(\\beta t)\\) \\(A \\cos(\\beta t) + B \\sin(\\beta t)\\) n-th degree polynomial \\(A_nt^n + A_{n-1}t^{n-1} + A_1 t + A_0\\) <p>Combine this with the following:</p> <p>Theorem. Given \\(y_{p_1}(t)\\) is a solution to \\(y'' + p(t)y' + q(t)y = g_1(t)\\) and \\(y_{p_2}(t)\\) is a solution to \\(y'' + p(t)y' + q(t)y = g_2(t)\\), then the function \\(y_{p_1}(t) + y_{p_2}(t)\\) is a solution to \\(y'' + p(t)y' + q(t)y = g_1(t) + g_2(t)\\)</p>"},{"location":"math/diffeq/3-2nd-order/#section-310-variation-of-parameters","title":"Section 3.10 - Variation of Parameters","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Assume we have the differential equation as follows:</p> \\[ y'' + p(t) y' + q(t) y = g(t) \\] <p>The equivalent homogenous differential equation is</p> \\[ y'' + p(t) y' + q(t) y = 0 \\] <p>For this method, we must have \\(y_1(t)\\) and \\(y_2(t)\\) known. Through a lot of math, we see that</p> \\[ y_p = -y_1 \\int \\frac{y_2(t)g(t)}{W(y_1, y_2)} dt + y_2 \\int \\frac{y_1(t)g(t)}{W(y_1, y_2)} dt \\]"},{"location":"math/diffeq/4-laplace/","title":"Section 4 - Laplace Transformations","text":""},{"location":"math/diffeq/4-laplace/#section-41-definition","title":"Section 4.1 - Definition","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Definition. The Laplace transform of a function is given by the following:</p> \\[ \\mathcal{L} \\{f(t)\\}(s) = F(s) = \\int_0^{\\infty} e^{-st}f(t) dt \\]"},{"location":"math/diffeq/4-laplace/#section-42-properties","title":"Section 4.2 - Properties","text":"<p>This section is from Paul's Online Math Notes.</p> <p>The Laplace Transformation is a linear transformation over functions in \\(\\mathbb{R}[t]\\). That is, given \\(a, b \\in \\mathbb{R}, f(t), g(t) \\in \\mathbb{R}[t]\\), we know that</p> \\[ \\mathcal{L} \\{a f(t)\\ + b g(t) \\}(s) = a F(s) + b G(s) \\]"},{"location":"math/diffeq/4-laplace/#section-43-inverse-laplace-transformation","title":"Section 4.3 - Inverse Laplace Transformation","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Given \\(F(s)\\), we define the Inverse Laplace Transformation as the following;</p> \\[ f(t) = \\mathcal{L}^{-1} \\{F(s)\\} \\]"},{"location":"math/diffeq/4-laplace/#section-44-step-function","title":"Section 4.4 - Step Function","text":"<p>The step/Heaviside function \\(u_c(t)\\) is defined as 0 if \\(t &lt; c\\), and 1 if \\(t &gt; c\\).</p> <p>Alternatively, \\(u(t - c) = H(t - c)\\) is 0 if \\(t &lt; c\\), and 1 if \\(t &gt; c\\).</p> <p>Applying this to the Laplace transform,</p> \\[ \\begin{align}     \\mathcal{L} \\{ u_c(t) f(t-c) \\} &amp;= \\int_0^{\\infty} e^{-st}u_c(t)f(t) dt \\\\     &amp;= \\int_c^{\\infty} e^{-st}f(t) dt \\end{align} \\] <p>If we let \\(u = t - c\\),</p> \\[ \\begin{align}     \\mathcal{L} \\{ u_c(t) f(t-c) \\} &amp;= \\int_0^{\\infty} e^{-s(u+c)}f(u) du \\\\     &amp;= \\int_0^{\\infty} e^{-su}e^{-cs}f(u) du \\\\     &amp;= e^{-cs} \\int_0^{\\infty} e^{-su}f(u) du \\\\     &amp;= e^{-cs} F(s) \\end{align} \\]"},{"location":"math/diffeq/4-laplace/#section-45-laplace-transformation-applied-to-ivps","title":"Section 4.5 - Laplace Transformation applied to IVPs","text":"<p>This section is from Paul's Online Math Notes.</p> <p>Theorem. Given a function \\(f(t)\\) with \\(C^n\\) continuity, then</p> \\[ \\mathcal{L} \\{ f^{(n)} (t) \\} = s^n F(s) - s^{n-1} f(0) - s^{n-2} f'(0) - \\ldots - s f^{(n-2)} (0) - f^{(n-1)} (0) \\] <p>For \\(n=1, 2\\) we see that</p> \\[ \\begin{align}     \\mathcal{L} \\{ y' \\} &amp;= sY(s) - y(0) \\\\     \\mathcal{L} \\{ y'' \\} &amp;= s^2 Y(s) - s y(0) - y'(0) \\end{align} \\] <p>We can take the Laplace transformation of an IVP, solve for \\(Y(s)\\), then take the inverse to find the solution.</p>"},{"location":"math/diffeq/4-laplace/#section-46-non-constant-coefficient-ivps","title":"Section 4.6 - Non-constant Coefficient IVPs","text":"<p>This section is from Paul's Online Math Notes.</p>"},{"location":"math/real-analysis/11-metric-spaces/","title":"Chapter 11 - Metric Spaces","text":""},{"location":"math/real-analysis/11-metric-spaces/#section-114-netric-spaces","title":"Section 11.4 - Netric Spaces","text":"<p>Definition. A metric on set \\(S\\) is a function \\(d: S \\otimes S \\rightarrow \\mathbb{R}\\) that satifies the following properties for all \\(x, y, z \\in S\\),</p> <ul> <li>\\(d(x, y) \\geq 0\\)</li> <li>\\(d(x, y) = 0 \\; \\text{ if and only if } x = y\\)</li> <li>\\(d(x, y) = d(y, x)\\)</li> <li>\\(d(x, y) \\leq d(x, z) + d(z, y)\\)</li> </ul> <p>Definition. A metric space \\((S, d)\\) is a set \\(S\\), with elements called points, together with a metric \\(d\\).</p> <p>Definition. With metric space \\((S, d)\\), if \\(A \\subset S\\), then \\((A, d)\\) is a subspace of \\((S, d)\\).</p> <p>Definition. The discrete metric is provided by</p> \\[ d(x, y) = \\begin{cases}   0 \\; \\text{ if } x = y \\\\   1 \\; \\text{ if } x \\neq y \\end{cases} \\] <p>Definition. Let \\((S, d)\\) be a metric space. Then, for each \\(\\varepsilon &gt; 0\\), the \\(\\varepsilon\\)-neighborhood or \\(\\varepsilon\\)-ball of a point \\(a \\in S\\) is the set</p> \\[ V_\\varepsilon(a) = {x \\in S | d(a, x) &lt; \\varepsilon} \\] <p>Definition. Let \\((S, d)\\) be a metric space. Then, a subset \\(G \\subseteq S\\) is open if for each \\(x \\in G\\), there exists some \\(\\varepsilon &gt; 0\\) so that \\(V_\\varepsilon(x) \\subseteq G\\).</p> <p>Definition. Let \\((S, d)\\) be a metric space. Then, a subset \\(G \\subseteq S\\) is closed if its complement \\(C(G) = S - G = S \\ F\\) is closed.</p> <p>Definition. Let \\((S, d)\\) be a metric space. A point \\(c \\in S\\) is a *cluster point$ of a set \\(A \\subseteq S\\) if every \\(\\varepsilon\\)-neighborhood of \\(c\\) contains some point \\(a \\in A\\) such that \\(a \\neq c\\).</p> <p>Theorem. Every \\(\\varepsilon\\)-neighborhood of a point is an open set.</p> <p>Theorem. The union of an arbitrary collection of open sets is open.</p> <p>Theorem. The intersection of a finite collection of open sets is open.</p> <p>Theorem. The union of finitely many closed sets is closed.</p> <p>Theorem. The intersection of infinitely many closed sets is closed.</p> <p>Theorem. A subset of a metric space is closed if and only if it contains all of its cluster points.</p> <p>Definition. A sequence \\((x_n)\\) in a metric space \\((S, d)\\) converges to a point \\(x \\in S\\) if given any \\(\\varepsilon &gt; 0\\), there exists a \\(K \\in \\mathbb{N}\\) such that given \\(n \\in \\mathbb{N}\\),</p> \\[ n \\geq K \\Rightarrow d(x_n, x) \\leq \\varepsilon \\] <p>Theorem. Let \\((x_n)\\) be a sequence in metric space \\((S, d)\\). Then,</p> <ul> <li>\\((x_n)\\) converges to \\(x\\) if and only if every \\(\\varepsilon\\)-neighborhood of \\(x\\) contains all but finitely many terms of \\((x_n)\\).</li> <li>If \\((x_n) \\rightarrow x\\) and \\((x_n) \\rightarrow x'\\), then \\(x = x'\\).</li> <li>If \\((x_n)\\) converges, then \\((x_n)\\) is bound.</li> </ul> <p>Definition. A sequence \\((x_n)\\) in metric space \\((S, d)\\) is a Cauchy sequence if for every \\(\\varepsilon &gt; 0\\), there exists some \\(H \\in \\mathbb{N}\\) such that for any \\(m, n \\in \\mathbb{N}\\),</p> \\[ m, n \\geq H \\Rightarrow d(x_n, x_m) &lt; \\varepsilon \\] <p>Definition. A metric space in which every Cauchy sequence converges is said to be complete.</p> <p>Remark. \\(\\mathbb{R}\\) is complete, but \\(\\mathbb{Q}\\) is not.</p> <p>Definition. Let \\(A\\) be a subset of metric space \\((S, d)\\). Then, an open cover of \\(A\\) is some collection of subsets \\(\\mathcal{G} = \\{G_\\alpha\\}_{\\alpha \\in I}\\), such that \\(G_\\alpha \\subseteq S\\) and \\(A \\subseteq \\cup_{\\alpha \\in I} G_\\alpha\\). That is, \\(A\\) is contained within the union of all open subsets in \\(\\mathcal{G}\\).</p> <p>Definition. If \\(\\mathcal{G}' \\subseteq \\mathcal{G}\\) is an open cover of \\(A\\), then \\(\\mathcal{G}'\\) is a subcover of \\(\\mathcal{G}\\).</p> <p>Definition. Given \\(K\\) is a subset of metric space \\((S, d)\\), K is compact if every cover of \\(K\\) contains a finite subcover.</p> <p>Theorem. If \\(K\\) is a compact subset of a metric space, then \\(K\\) is closed and bounded.</p> <p>Theorem. Heine-Borel Theorem. In \\(\\mathbb{R}\\), the convese is true. That is, if \\(K \\subseteq \\mathbb{R}\\) is closed and bounded, then it is compact.</p> <p>Theorem. If \\(K\\) is a compact subset of a metric space, then every infinite subset of \\(K\\) has a cluster point.</p> <p>Corollary. Bolzano-Weirstrass Theorem. Every bounded infinite subset of \\(\\mathbb{R}\\) has a cluster point in \\(\\mathbb{R}\\).</p> <p>Definition. Let \\((S, d)\\) be a metric space, and \\(A_1, A_2 \\in S\\) be subsets. Then, \\(A_1, A_2\\) are said to be separated if there exist disjoint open subsets \\(U_1, U_2\\) such that \\(A_1 \\subseteq U_1\\) and \\(A_2 \\subseteq U_2\\).</p> <p>Definition. A subset \\(C\\) of metric space \\((S, d)\\) is said to be connected if it is not the union of nonempty separated subsets.</p> <p>Theorem. A subset of \\(\\mathbb{R}\\) is connected if and only if it is an interval.</p>"},{"location":"math/real-analysis/2-reals/","title":"Chapter 2 - The Real Number Line","text":""},{"location":"math/real-analysis/2-reals/#section-21-the-algebraic-and-order-properties-of-real-numbers","title":"Section 2.1 - The Algebraic and Order Properties of Real Numbers","text":"<p>Proposition. 2.1.1: \\(\\mathbb{R}\\) is a field, with zero element \\(0\\) and identity \\(1\\).</p> <p>Definition. The rational numbers \\(\\mathbb{Q}\\) is the field of fractions of the natural numbers \\(\\mathbb{N}\\).</p> <p>Theorem. 2.1.4: There does not exist a rational number \\(r\\) such that \\(r^2 = 2\\).</p> <p>Definition. An ordered field is a field \\(F\\) together with subset \\(F^+\\) such that</p> <ol> <li>\\(F+\\) is closed under addition and multiplication</li> <li>If \\(a \\in F\\), then exclusively \\(a \\in F^+\\), \\(a = 0\\), or \\(-a \\in F^+\\).</li> </ol> <p>Theorem. In any ordered field \\(F\\), the following hold</p> <ol> <li>\\(1 \\in F^+\\)</li> <li>\\(\\mathbb{N} \\subseteq F^+\\)</li> <li>If \\(a \\in F^+\\), then \\(\\frac{1}{a} \\in F^+\\)</li> </ol> <p>Definition The order relation \\(a &gt; b\\) and \\(b &lt; a\\) is defined by \\(a - b \\in F^+\\).</p> <p>Theorem. If \\(a, b, c \\in F\\), then</p> <ol> <li>One of \\(a &gt; b\\), \\(a = b\\), or \\(a &lt; b\\) hold (trichotomy)</li> <li>If \\(a &gt; b\\) and \\(b &gt; c\\), then \\(a &gt; c\\) (transitivity)</li> <li>If \\(a &gt; b\\), then \\(-a &lt; -b\\)</li> <li>If \\(a &gt; b\\) and \\(c &gt; 0\\), then \\(ac &gt; bc\\)</li> <li>If \\(a &gt; b\\) and \\(c &lt; 0\\), then \\(ac &lt; bc\\)</li> <li>If \\(a &gt; b &gt; 0\\), then \\(\\frac{1}{b} &gt; \\frac{1}{a} &gt; 0\\)</li> </ol> <p>Definition. Let \\(S\\) be a nonempty subset of ordered field \\(F\\). Then, \\(S\\) is bounded above if there exists some \\(u \\in F\\) such that \\(s \\leq u\\) for all \\(s \\in S\\). Then, said element \\(u\\) is an upper bound of \\(S\\).</p> <p>Definition. Let \\(S\\) be a nonempty subset of ordered field \\(F\\). Then, \\(S\\) is bounded below if there exists some \\(u \\in F\\) such that \\(s \\geq u\\) for all \\(s \\in S\\). Then, said element \\(u\\) is a lower bound of \\(S\\).</p> <p>Definition. Let \\(S\\) be a nonempty subset of ordered field \\(F\\). Then, \\(S\\) is bounded if it is bounded both above and below.</p> <p>Definition. Given field \\(F\\) and nonempty subset \\(S \\subseteq F\\), an element \\(u \\in F\\) is a supremum or least upper bound of \\(S\\) if \\(u\\) is an upper bound of \\(S\\), and given any other upper bound \\(v\\), then \\(u &lt; v\\)</p> <p>Definition. Given field \\(F\\) and nonempty subset \\(S \\subseteq F\\), an element \\(u \\in F\\) is an infimum or greatest lower bound of \\(S\\) if \\(u\\) is a lower bound of \\(S\\), and given any other lower bound \\(v\\), then \\(u &gt; v\\)</p> <p>Definition. Given an ordered field \\(F\\), the field has the supremum/infimum property if given any nonempty subset \\(S\\), if \\(S\\) is bounded above/below, \\(S\\) has a supremum/infimum.</p>"},{"location":"math/real-analysis/2-reals/#section-22-absolute-value-and-the-real-line","title":"Section 2.2 - Absolute Value and the Real Line","text":"<p>Definition. Absolute value is defined as normal (piecewise). Multiline function in LaTeX are hard.</p> <p>Theorem. Given any \\(a, b \\in \\mathbb{R}\\), we know that</p> <ol> <li>\\(|a| &gt; 0\\) for \\(a \\neq 0\\)</li> <li>\\(|ab| = |a||b|\\)</li> <li>\\(|a + b| \\leq |a| + |b|\\)</li> </ol> <p>Corollary. Given \\(a, b \\in \\mathbb{R}\\), then \\(||a| - |b|| \\leq |a - b|\\).</p> <p>Remark. Every field has at least one absolute value function.</p> <p>Theorem. In an ordered field \\(F\\), for any \\(r &gt; 0\\), we know that</p> <ol> <li>\\(|x = r\\) if and only if \\(x = r\\) or \\(x = -r\\)</li> <li>\\(|x &lt; r\\) if and only if \\(-r &lt; x &lt; r\\)</li> <li>\\(|x &gt; r\\) if either \\(x &gt; r\\) or \\(x &lt; -r\\)</li> </ol> <p>Definition. The standard distance function or metric on the real numbers \\(\\mathbb{R}\\) given \\(a, b\\) is \\(|a - b|\\).</p> <p>Theorem. For any real numbers \\(a, b, c\\),</p> <ol> <li>\\(|a - b| &gt; 0\\) if and only if \\(a \\neq b\\) and \\(|a - b| = 0\\) if and only if \\(a = b\\)</li> <li>\\(|a - b| = |b - a|\\)</li> <li>\\(|a - c| \\leq |a - b| + |b + c|\\)</li> </ol> <p>Definition A set together with a function satisfying these three properties is known as a metric space.</p> <p>Definition The \\(\\varepsilon\\)-neighborhood of \\(a \\in \\mathbb{R}\\), denoted \\(V_\\varepsilon(a)\\) is the set of all real numbers \\(x \\in \\mathbb{R}\\) such that \\(|x - a| &lt; \\varepsilon\\). That is,</p> \\[ V_\\varepsilon(a) = (a - \\varepsilon, a + \\varepsilon) \\] <p>Decimals. Let \\(x \\in \\mathbb{R}\\) such that \\(x &gt; 0\\). By the archimedean property, there exists some \\(b_0 \\in \\mathbb{N} \\cup {0}\\) such that \\(b_0 &lt; x &lt; b_0 + 1\\). We can repeat this to see</p> \\[ x = b_0 + \\frac{b_1}{10} + \\frac{b_2}{100} + \\ldots + \\frac{b_n}{100^n} + \\ldots \\] <p>Definition. The decimal expansion of \\(x\\) is denoted \\(b_0.b_1 b_2 b_3 \\ldots\\).</p>"},{"location":"math/real-analysis/2-reals/#section-25-intervals","title":"Section 2.5 - Intervals","text":"<p>Definition. A subset \\(I\\) is an interval if and only if, given \\(a, b \\in I\\), then \\([a, b] \\subseteq I\\).</p> <p>Definition. Intervals \\(I_1, I_2, \\ldots, I_n, \\ldots\\) are nested if and only if \\(I_1 \\subseteq I_2 \\subseteq \\ldots \\subseteq I_n \\subseteq \\ldots\\).</p> <p>Theorem. Nested Intervals Property. If \\(I_n = [a_n, b_n]\\) is a set of nested intervals that are closed and bound, then there exists some number \\(z \\in \\mathbb{R}\\) such that \\(z \\in I_n\\) for all \\(n\\).</p> <p>Theorem. If \\(a &lt; b\\), then the interval \\([a, b]\\) is an uncountable set.</p> <p>Corollary. \\(\\mathbb{R}\\) is uncountable.</p>"},{"location":"math/real-analysis/3-sequences-series/","title":"Chapter 3 - Sequences and Series","text":""},{"location":"math/real-analysis/3-sequences-series/#section-31-sequences-and-their-limits","title":"Section 3.1 - Sequences and their Limits","text":"<p>Definition. A sequence in \\(\\mathbb{R}\\) is a function \\(X: \\mathbb{N} \\rightarrow \\mathbb{R}\\), typically notated as \\(X\\) or \\((x_n)\\), with \\(x_n\\) being referred to as the terms of the sequence. The set \\({x_n | n \\in \\mathbb{N}}\\) is the range of this sequence.</p> <p>Definition. The sequence is bounded if its range is a bounded subset of \\(\\mathbb{R}\\).</p> <p>Example. The constant sequence \\(C = (c) = (c, c, c, \\ldots)\\).</p> <p>Example. The harmonic sequence \\(\\frac{1}{n} = (1, \\frac{1}{2}, \\frac{1}{3}, \\ldots)\\)</p> <p>Example. The geometric sequence, given base \\(a \\in \\mathbb{R}\\) and ratio \\(r \\in \\mathbb{R}\\)</p> \\[ (x_n) = (a, ar,  ar^2, ar^3, \\ldots) \\] <p>Example. The arithmetic sequence, given base \\(a \\in \\mathbb{R}\\) and distance \\(d \\in \\mathbb{R}\\),</p> \\[ (x_n) = (a, a + d, a + 2d, a + 3d, \\ldots) \\] <p>Example. Decimal expansions are bounded sequences.</p> <p>Definition. A sequence \\(X = (x_n)\\) is said to converge to a number \\(x \\in \\mathbb{R}\\) if when given any \\(\\varepsilon &gt; 0\\), there exists some \\(K \\in \\mathbb{N}\\) such that for every \\(n \\in \\mathbb{N}\\) with \\(n \\geq K\\),</p> \\[ |x_n - x| &lt; \\varepsilon \\] <p>If this is the case, we say that \\(X\\) converges to  \\(x\\), and \\(x\\) is a limit of X. This can be written as</p> \\[ \\lim X = x \\text{ or } \\text \\lim(x_n) = x \\text{ or }  x_n \\rightarrow x \\] <p>Definition. If a sequence does not have a limit, it is divergent.</p> <p>Theorem. A sequence can have at most one limit. That is, if a limit exists, it is unique.</p> <p>Theorem. If a limit is convergent, then it is bounded.</p>"},{"location":"math/real-analysis/3-sequences-series/#section-32-limit-theorems","title":"Section 3.2 - Limit Theorems","text":"<p>Theorem. Suppose there exists some \\(X\\) such that \\((x_n) \\rightarrow x\\) and \\(Y\\) such that \\((y_n) \\rightarrow y\\). Then,</p> <ol> <li>\\(x_n + y_n \\rightarrow x + y\\)</li> <li>\\(x_n \\cdot y_n \\rightarrow xy\\)</li> <li>If \\(x_n \\neq 0\\) for all \\(n\\), then \\(\\frac{1}{x_n} \\rightarrow \\frac{1}{x}\\)</li> </ol> <p>Theorem. Suppose \\((x_n)\\) and \\((y_n)\\) are convergent sequences and \\(N \\in \\mathbb{N}\\). Then,</p> <ol> <li>If \\(x_n \\leq y_n\\) for all \\(n \\geq N\\), then \\(\\lim(x_n) \\leq \\lim(y_n)\\)</li> <li>If \\(x_n \\leq a\\) for all \\(n \\geq N\\), then \\(\\lim(x_n) \\leq a\\)</li> <li>If \\(x_n \\geq a\\) for all \\(n \\geq N\\), then \\(\\lim(x_n) \\geq a\\)</li> </ol> <p>Theorem. Squeeze Theorem. Suppose \\((x_n), (y_n), (z_n)\\) are all sequences of real numbers, and \\(\\lim(x_n) = \\lim(z_n) = a\\). Then, if for some \\(N in \\mathbb{N}\\),</p> \\[ \\text{If } x_n \\leq y_n \\leq z_n, \\text{ then } \\lim(y_n) = a \\] <p>Theorem. Suppose \\((x_n)\\) is a sequence if real numbers. Then,</p> <ol> <li>If \\(x_n \\rightarrow x\\), then \\(|x_n| \\rightarrow |x|\\)</li> <li>If \\(|x_n| \\rightarrow 0\\), then \\(x_n \\rightarrow 0\\)</li> <li>\\(x_n \\rightarrow x\\) if and only if \\(|x_n - n| \\rightarrow 0\\)</li> </ol> <p>Theorem. Suppose \\((x_n)\\) is a sequence if real numbers, with each \\(x_n \\geq 0\\). Then, given some \\(k \\in \\mathbb{N}\\), if \\(x_n \\rightarrow x\\), then \\(\\sqrt[k]{x_n} \\rightarrow \\sqrt[k]{x}\\).</p>"},{"location":"math/real-analysis/3-sequences-series/#section-33-monotonic-sequences","title":"Section 3.3 - Monotonic Sequences","text":"<p>Definition. A sequence \\((x_n)\\) is monotonically increasing if \\(x_{n+1} \\geq x_n\\) for all \\(n \\in \\mathbb{N}\\).</p> <p>Definition. A sequence \\((x_n)\\) is monotonically decreasing if \\(x_{n+1} \\leq x_n\\) for all \\(n \\in \\mathbb{N}\\).</p> <p>Definition. A sequence is monotonic if it is either monotonically increasing or decreasing.</p> <p>Theorem. A monotonic sequence is converging if and only if it is bound.</p>"},{"location":"math/real-analysis/3-sequences-series/#section-34-subsequences","title":"Section 3.4 - Subsequences","text":"<p>Definition. Let \\(X = (x_n)\\) be a sequence in \\(\\mathbb{R}\\). Then, the sequence</p> \\[ X_{n_k} = (x_{n_1}, x_{n_2}, \\ldots) \\] <p>is a subsequence of \\(X\\),</p> <p>Theorem. If a sequence converges to \\(x\\), then every subsequence also converges to \\(x\\).</p> <p>Theorem. Every sequence of real numbers \\((x_n)\\) contains a monotonic subsequence \\((x_{n_k})\\).</p> <p>Corollary. Bolzano-Weierstrass Theorem. Every bounded sequence of real numbers has a convergent subsequence.</p>"},{"location":"math/real-analysis/3-sequences-series/#section-35-the-cauchy-criterion","title":"Section 3.5 - The Cauchy Criterion","text":"<p>Definition. A sequence \\((x_n)\\) is said to be a Cauchy sequence such that for any given \\(\\varepsilon\\), there exists a natural number \\(H\\) such that all natural numbers \\(m, n \\geq H\\), then</p> \\[|x_m - x_n \\leq \\varepsilon\\] <p>Theorem. If \\((x_n)\\) is a Cauchy sequence, then \\((x_n)\\) is convergent.</p>"},{"location":"math/real-analysis/3-sequences-series/#section-37-series","title":"Section 3.7 - Series","text":"<p>Definition. Let \\((x_n)\\) be a sequence in \\(\\mathbb{R}\\). Then, the infinite series generated by \\(X\\) is the sequence \\(S = (s_n)\\) with terms</p> \\[ s_1 = x_1; \\; s_{n+1} = s_n + x_{n+1} \\] <p>In other words, \\(s_n = \\sum_{i=1}^n x_i\\). We denote this series as \\(\\sum x_n\\).</p> <p>Definition. If this series is convergent to some number \\(s\\), we say that \\(s\\) is the sum of the series.</p> <p>For natural numbers \\(n &gt; m\\), note that</p> \\[ s_n - s_m = \\sum_{i=m + 1}^n x_i \\] <p>In particular, \\(s_n - s_{n - 1} = x^n\\). Thus, the Cauchy criteria takes the form</p> <p>Theorem. Cauchy Criteria for Series. The series \\(\\sum x_n\\) converges if and only if, for a given \\(\\varepsilon\\), there exists some natural number \\(H\\) such that when \\(m &gt; n &gt; H\\),</p> \\[ |s_m - s_n| = |\\sum_{i = m + 1}^n x_i| &lt; \\varepsilon \\] <p>Corollary. \\(n\\)-th Term Test. If \\(\\sum x_n\\) converges, then \\(x_n \\rightarrow 0\\).</p> <p>Corollary. Absolute Convergence Test. If \\(\\sum |x_n|\\) converges, then \\(\\sum x_n\\) converges.</p> <p>Theorem. A series with non-negative terms converges if and only if its sequence of partial sums is bounded.</p> <p>Theorem. \\(e = \\lim_{n \\rightarrow \\infty} (1+\\frac{1}{n})^n = \\sum_{n=0}^\\infty \\frac{1}{n!}\\)</p>"},{"location":"math/real-analysis/4-limits/","title":"Chapter 4 - Limits","text":""},{"location":"math/real-analysis/4-limits/#section-41-limits-of-functions","title":"Section 4.1 - Limits of Functions","text":"<p>Definition. Let \\(A \\subseteq \\mathbb{R}\\). Then, a point \\(c \\in \\mathbb{R}\\) is a cluster point of \\(A\\) if for every \\(\\delta &gt; 0\\), the \\(\\delta\\)-neighborhood of \\(c\\) contains a point \\(a \\in A\\) such that \\(a \\neq c\\). That is, there exists some \\(a\\) such that \\(0 &lt; |a - c| &lt; \\delta\\).</p> <p>Theorem. A real number \\(c\\) is a cluster point for a set \\(A\\) if and only if there exists a sequence \\((a_n)\\) in \\(A\\\\ \\{c\\}\\) such that \\(a_n \\rightarrow c\\)</p> <p>Corollary. A real number \\(c\\) is a cluster point of a set \\(A\\) if and only if every \\(\\delta\\)-neighborhood contains infinitely many points of \\(A\\).</p> <p>Definition. The set of every cluster point of \\(A\\) is called the derived set of \\(A\\), and denoted \\(A'\\).</p> <p>Corollary. A set \\(A\\) is closed if and only if \\(A' \\subseteq A\\).</p> <p>Remark. If \\(A'\\) is the derived set of \\(A\\), then \\(A'' \\subseteq A'\\).</p> <p>Remark. Intervals involving infinity and square brackets for the constant are closed.</p> <p>Definition. Suppose \\(f: A \\rightarrow \\mathbb{R}\\) is a function with domain \\(A \\subseteq \\mathbb{R}\\), and let \\(c \\in A\\) be a cluster point of \\(A\\). then, a real number \\(L\\) is a limit of \\(f\\) at \\(c\\) if given any \\(\\varepsilon &gt; 0\\), there exists some \\(\\delta &gt; 0\\) such that</p> \\[ 0 &lt; |x-c| &lt; \\delta \\Rightarrow |f(x) - L| &lt; \\varepsilon \\] <p>Theorem. For a given function and cluster point, there can be at most one limit at said point.</p> <p>Theorem. Let \\(A \\subseteq \\mathbb{R}\\) and \\(f: A \\rightarrow \\mathbb{R}\\). Then, to show that \\(lim_{x \\rightarrow c} f(x) = L\\), it suffices to show that for every sequence \\((a_n)\\) in \\(A\\\\ \\{c\\}\\), the sequence \\((f(a_n))\\) converges tto \\(L\\).</p> <p>Definition. The extended real numbers are \\(\\hat{\\mathbb{R}} = \\mathbb{R} \\cup \\{ \\infty, -\\infty \\}\\) are a totally-ordered set with supremum and infimum. Note that this set is no longer a field.</p> <p>Definition. At any point \\(c\\), the limit of \\(f\\) at \\(c\\) is infinite if given some \\(\\alpha\\),  there exists some \\(V_\\delta(c)\\) such that for all \\(x \\in V_\\varepsilon(c)\\), then \\(f(x) \\in V_\\alpha(\\infty)\\).</p> <p>Definition. The limit of a function at infinity is defined if for a given \\(\\varepsilon\\), there exists some \\(\\alpha\\) so that there exists some \\(V_\\delta(c)\\) such that for all \\(x \\in A\\),</p> \\[ x &gt; \\alpha \\Rightarrow |f(x) - L| &lt; \\varepsilon \\]"},{"location":"math/real-analysis/4-limits/#section-42-limit-theorems","title":"Section 4.2 - Limit Theorems","text":"<p>Definition. Let \\(A \\subseteq \\mathbb{R}\\) and \\(c \\in \\mathbb{R}\\) be a cluster point of \\(A\\). Then, a function \\(f: A \\rightarrow \\mathbb{R}\\) is bounded on a neighborhood of \\(c\\) if there exists some \\(\\delta\\)-neighborhood \\(V_\\delta(c)\\) of \\(c\\) and some constant \\(M &gt; 0\\) such that for all \\(x \\in A \\cap V_\\delta(c)\\), then \\(|f(x)| \\leq M\\).</p> <p>Theorem. If \\(A \\subseteq \\mathbb{R}\\) and \\(f: A \\rightarrow \\mathbb{R}\\) has a finite limit at \\(c \\in \\mathbb{R}\\), then \\(f\\) is bounded on some neighborhood of \\(c\\).</p> <p>Theorem. With \\(A \\subseteq \\mathbb{R}\\), and \\(f, g: A \\rightarrow \\mathbb{R}\\), with \\(c \\in \\mathbb{R}\\) a cluster point of \\(A\\), then if \\(\\lim_{x \\rightarrow c} f(x) = L\\) and \\(\\lim_{x \\rightarrow c} g(x) = M\\), then:</p> \\[\\lim_{x \\rightarrow c} (f(x) + g(x)) = L + M\\] \\[\\lim_{x \\rightarrow c} (f(x)g(x)) = LM\\] <p>Additionally, if \\(g(x) \\neq 0\\) for all \\(x \\in A\\), and \\(M \\neq 0\\), then</p> \\[ \\lim_{x \\rightarrow c} \\frac{f(x)}{g(x)} = \\frac{L}{M} \\] <p>Corollary. If \\(p, q \\in \\mathbb{R}[x]\\), and \\(q(c) \\neq 0\\) for some \\(c \\in \\mathbb{R}\\), then</p> \\[ \\lim_{x \\rightarrow c} p(x) = p(c) \\] \\[ \\lim_{x \\rightarrow c} \\frac{p(x)}{q(x)} = \\frac{p(c)}{q(c)} \\] <p>Theorem. Squeeze Theorem. Let \\(A \\subseteq \\mathbb{R}\\). Then, if \\(f, g, h: A \\rightarrow \\mathbb{R}\\) and with \\(c \\in \\mathbb{R}\\) being a cluster point of \\(A\\), then if both</p> \\[ \\lim_{x \\rightarrow c} f(x) = \\lim_{x \\rightarrow c} h(x) = L \\] \\[ f(x) \\leq g(x) \\leq h(x) \\; \\text{ for all } x \\in A, x \\neq c \\] <p>Then, \\(\\lim_{x \\rightarrow c} g(x) = L\\).</p>"},{"location":"math/real-analysis/5-continuity/","title":"Chapter 5 - Continuity","text":""},{"location":"math/real-analysis/5-continuity/#section-51-continuous-functions","title":"Section 5.1 - Continuous Functions","text":"<p>Definition. Let \\(A \\subseteq \\mathbb{R}\\), and \\(f: A \\rightarrow \\mathbb{R}\\). Then, if \\(a \\in A\\), \\(f\\) is continuous at \\(a\\) if, given any \\(\\varepsilon &gt; 0\\), there exists some \\(\\delta &gt; 0\\) such that for all \\(x \\in A\\),</p> \\[ |x - a| &lt; \\delta \\Rightarrow |f(x) - f(a)| &lt; \\varepsilon \\] <p>Note that if \\(a\\) is an isolated point of \\(A\\), that is, not a cluster point, then \\(a\\) is automatically continuous.</p> <p>If \\(a\\) is a cluster point of \\(A\\), then this definition collapses to the definition of \\(\\lim_{x \\rightarrow a} f(x) = f(a)\\).</p> <p>Note that a function cannot be continuous at a point outside of its domain, even if the limit exists.</p> <p>Definition. \\(f\\) is continuous on \\(A\\) if it is continuous at every point \\(a \\in A\\).</p> <p>Theorem. \\(f\\) is continuous if and only if for every sequence \\((x_n)\\) in \\(A\\) that converges to \\(a\\), the sequence \\((f(x_n))\\) converges to \\(f(a)\\).</p> <p>Definition. Let \\((S, d_S)\\) and \\((T, d_T)\\) be metric spaces. A function \\(f: S \\rightarrow T\\) is continuous at a point \\(a \\in S\\) if given any \\(\\varepsilon &gt; 0\\), there exists some \\(\\delta &gt; 0\\) such that for all \\(x \\in S\\),</p> \\[ d_S(x, a) &lt; \\delta \\Rightarrow d_T(f(x),  f(a)) &lt; \\varepsilon \\] <p>Theorem. A function \\(f: S \\rightarrow T\\) is continuous at a point \\(a \\in A\\) if and only if given some neighborhood \\(V(f(a)) \\in B\\), there exists some \\(U(a) \\in A\\) such that \\(f(U) \\subseteq V\\).</p>"},{"location":"math/real-analysis/5-continuity/#section-52-combinations-of-continuous-functions","title":"Section 5.2 - Combinations of continuous Functions","text":"<p>Theorem. Let \\(f, g: A \\rightarrow \\mathbb{R}\\) be continuous at \\(a \\in A\\). Then,</p> <ul> <li>\\(f + g\\) and \\(fg\\) are continuous at \\(a\\)</li> <li>If \\(g(x) \\neq 0\\) for all \\(x \\in A\\), then \\(\\frac{f}{g}\\) is continuous at \\(a\\).</li> </ul> <p>As a consequence, every polynomial, rational, and basic trigonometric function are continuous on its domains.</p> <p>Theorem. Lett \\(A, B \\subseteq \\mathbb{R}\\), such that \\(f: A \\rightarrow B\\) and \\(g: B \\rightarrow \\mathbb{R}\\). Then, if \\(c\\) is a cluster point of \\(A\\) such that \\(\\lim_{x \\rightarrow c} f(x) = L \\in B\\) and \\(g\\) is continuous at \\(L\\), then</p> \\[ \\lim_{x \\rightarrow c} g(f(x)) = g(L) = g(\\lim_{x \\rightarrow c} f(x)) \\] <p>Corollary. let \\(A, B \\subseteq  \\mathbb{R}\\), with \\(f: A \\rightarrow B\\) and \\(g: B \\rightarrow \\mathbb{R}\\). If \\(f\\) is continuous at \\(a \\in A\\) and \\(g\\) is continuous at \\(f(a) \\in B\\), then \\(g(f(x))\\) is continuous at \\(a\\).</p>"},{"location":"math/real-analysis/5-continuity/#section-53-continuous-functions-on-intervals","title":"Section 5.3 - continuous functions on Intervals","text":"<p>Theorem. Let \\(S, T\\) be metric spaces with \\(A \\subseteq S\\) and \\(f: A \\rightarrow T\\). If \\(A\\) is a compact subset of \\(S\\), then \\(f(A)\\) is a compact subset of \\(T\\).</p> <p>Corollary. Let \\(f: A \\rightarrow \\mathbb{R}\\) be a continuous function, with \\(A\\) being a compact subset of metric space \\(S\\). Then, \\(f(A)\\) is closed and bounded. Moreover, there exists a \\(p, q \\in A\\) such that \\(f(p)\\) and \\(f(q)\\) are the supremum and infimum of \\(f(A)\\).</p> <p>Corollary. Maximum-Minimum Theorem. If \\(I = [a, b]\\) is a closed and bounded interval and \\(f: I \\rightarrow \\mathbb{R}\\) is continuous on \\(I\\), then \\(f\\) has an absolute minimum and maximum on \\(I\\).</p> <p>Theorem. Let \\(S, T\\) be metric spaces and \\(A \\subseteq S\\). Then, if \\(f: A \\rightarrow T\\) is continuous on \\(A\\), and \\(A\\) is a connected subset of \\(S\\), then \\(f(A)\\) is a connected subset of \\(T\\).</p> <p>Corollary. Suppose that \\(I\\) is an interval. Let \\(f: I \\rightarrow \\mathbb{R}\\) be continuous on \\(I\\). Then, \\(f(I)\\) is an interval.</p> <p>Theorem. (Bolzano's) Intermediate Value Theorem. Suppose \\(f: [a, b] \\rightarrow \\mathbb{R}\\) is continuous on \\([a, b]\\) with \\(a \\neq b\\). Then, given some \\(k\\) such that \\(f(a) &lt; k &lt; f(b)\\), there exists some \\(c \\in (a, b)\\) such that \\(k = f(c)\\).</p> <p>Definition. Let \\(A \\subseteq R\\). Then, a function \\(f: A \\rightarrow \\mathbb{R}\\) is uniformly continuous if given any \\(\\varepsilon &gt; 0\\), there exists some \\(\\delta &gt; 0\\) depending only on \\(\\varepsilon\\) such that for any \\(x, y \\in A\\),</p> \\[ |x - y| &lt; \\delta \\Rightarrow |f(x) - f(y)| &lt; \\varepsilon \\] <p>Note that if \\(f\\) is uniformly continuous, it must be continuous on \\(A\\).</p> <p>Theorem. Let \\(I = [a, b]\\) be a closed and bounded interval. If \\(f: I \\rightarrow \\mathbb{R}\\) is continuous on \\(I\\), then \\(f\\) is uniformly continuous.</p> <p>Remark. If \\(S, T\\) are metric spaces, \\(K\\) is a compact subset of \\(S\\), and \\(f: K \\rightarrow T\\) is continuous on \\(K\\), then \\(f\\) is uniformly continuous.</p> <p>Theorem. Suppose \\(A \\subseteq \\mathbb{R}\\) and \\(f: A \\rightarrow \\mathbb{R}\\) is uniformly continuous. Then, if \\((x_n)\\) is a Cauchy sequence in \\(A\\), \\((f(x_n))\\) is a Cauchy sequence in \\(\\mathbb{R}\\).</p> <p>Remark. Suppose \\(S, T\\) are metric spaces and \\(f: S \\rightarrow T\\) is uniformly continuous. Then, if \\((x_n)\\) is a Cauchy sequence in \\(S\\), \\((f(x_n))\\) is a Cauchy sequence in \\(T\\).</p>"},{"location":"math/real-analysis/6-derivatives/","title":"Chapter 6 - Derivatives","text":""},{"location":"math/real-analysis/6-derivatives/#section-61-the-derivative","title":"Section 6.1 - The Derivative","text":"<p>Definition. Let \\(I \\subseteq \\mathbb{R}\\) be an interval \\(f: I \\rightarrow \\mathbb{R}\\) a function, and \\(c \\in I\\). Then, the derivative of \\(f\\) at \\(c\\) is</p> \\[ f'(c) = \\lim_{x \\rightarrow c} \\frac{f(x)-f(c)}{x-c} \\] <p>provided that the limit exists. Thus, we obtain \\(f'(x)\\), or the derivative of \\(f\\), with a domain of all points \\(c \\in I\\) where the limit exists.</p> <p>Theorem. If \\(f: I \\rightarrow \\mathbb{R}\\) is differentiable at point \\(c\\), it is continuous at point \\(c\\).</p> <p>Theorem. Let \\(f, g: I \\rightarrow \\mathbb{R}\\) be differentiable at \\(c \\in I\\). Then,</p> <ul> <li>\\((f+g)'(c) = f'(c) + g'(c)\\)</li> <li>\\((fg)'(c) = f'(c)g(c) + f(c)g'(c)\\)</li> <li>\\((\\frac{f}{g})'(c) = \\frac{f'(c)g(c) - f(c)g'(c)}{(g(c))^2}\\)</li> </ul> <p>Theorem. Let \\(f: I \\rightarrow \\mathbb{R}\\) and \\(g: J \\rightarrow \\mathbb{R}\\), with \\(f(I) \\subseteq J\\). Then, if \\(f\\) is differentiable at \\(c \\in I\\) and \\(g\\) is differentiable att \\(f(c) \\in J\\), then \\(f \\circ g\\) is differentiable at \\(c\\), and</p> \\[ (g \\circ f)'(c) = g'(f(c))f'(c) \\] <p>Theorem. Suppose \\(f: I \\rightarrow \\mathbb{R}\\) is a one-to-one function on some interval \\(I\\). Then, with \\(J = f(I)\\) and \\(f^{-1}: J \\rightarrow \\mathbb{R}\\), for all \\(x \\in I\\),</p> \\[ f^{-1}(f(x)) = x \\] <p>Lemma. \\(f\\) is continuous on some interval \\(I\\) if and only if it is monotonic on said interval.</p> <p>Theorem. Suppose \\(f: I \\rightarrow \\mathbb{R}\\) is a one-to-one function on some interval \\(I\\). Then, with \\(J = f(I)\\) and \\(f^{-1}: J \\rightarrow \\mathbb{R}\\), if \\(f\\) is continuous on \\(I\\) and \\(I\\) is an interval, then \\(f(I)\\) is an interval, and \\(f^{-1}\\) is continuous on \\(J\\).</p> <p>Theorem. Suppose \\(f: I \\rightarrow \\mathbb{R}\\) is differentiable at some \\(c \\in I\\). Then, with \\(J = f(I)\\) and \\(f^{-1}: J \\rightarrow \\mathbb{R}\\), if \\(f\\) is differentiable at \\(c\\) and \\(f'(c) \\neq 0\\), then \\(f^{-1}\\) is differentiable at \\(d = f(c)\\), and</p> \\[ (f^{-1})(d) = \\frac{1}{f'(c)} \\] <p>Definition. Let \\(I \\subseteq \\mathbb{R}\\) be an interval and let \\(f: I \\rightarrow \\mathbb{R}\\). Then, \\(f\\) has a relative maximum (or local maximum) at some point \\(c \\in I\\) if there exists some \\(\\delta\\)-neighborhood \\(V_\\delta(c)\\) such that for all \\(x \\in V_\\delta(C) \\cup I\\), then \\(f(x) \\leq f(c)\\). Relative minima are defined similarly.</p> <p>Theorem. Let \\(I\\) be an interval and \\(f: I \\rightarrow \\mathbb{R}\\). Then, if \\(f\\) has a relative extremum at an interior point \\(c \\in I\\), and if \\(f'(c)\\) exists, then \\(f'(c) = 0\\).</p> <p>Corollary. Suppose \\(f: [a, b] \\rightarrow \\mathbb{R}\\) and \\(g: [a, b] \\rightarrow \\mathbb{R}\\) are both continuous on \\([a, b]\\) and differentiable on \\((a, b)\\) with \\(a \\neq b\\). Then,</p> <ul> <li>Rolle's Theorem. If \\(f(a) = f(b)\\), then there exists at least one point \\(c \\in (a, b)\\) with \\(f'(c) = 0\\).</li> <li>If \\(f(a) = g(a)\\) and \\(f(b) = g(b)\\), then there exists aat least one point \\(c \\in (a, b)\\) such that \\(f'(c) = g'(c)\\).</li> </ul> <p>Theorem. Mean Value Theorem. Let \\(f\\) be continuous on \\([a, b]\\) and differentiable on \\((a, b)\\), with \\(a \\neq b\\). Then, there exists at least one \\(c \\in (a, b)\\) with</p> \\[ f(b) - f(a) = f'(c)(b - a) \\] <p>Theorem. Suppose \\(f: I \\rightarrow \\mathbb{R}\\) is differentiable on I. Then,</p> <ul> <li>If \\(f'(x) &gt; 0\\) for all $x \\in $I, then \\(f\\) is strictly increasing on \\(I\\).</li> <li>If \\(f'(x) = 0\\) for all $x \\in $I, then \\(f\\) is constant on \\(I\\).</li> <li>If \\(f'(x) &lt;&gt; 0\\) for all $x \\in $I, then \\(f\\) is strictly decreasing on \\(I\\).</li> </ul> <p>Theorem. Cauchy Mean Value Theorem. Let \\(f, g\\) be continuous on \\([a, b]\\) and differentiable on \\((a, b)\\). If \\(g'(x) \\neq 0\\) for all \\(x \\in (a, b)\\), and \\(a \\neq b\\), then there exists  at least one point \\(c \\in (a, b)\\) such that</p> \\[ \\frac{f(b)-f(a)}{g(b)-g(a)} = \\frac{f'(c)}{g'(c)} \\]"},{"location":"physics/electrodynamics/10-electromagnetic-waves/","title":"Chapter 10 - Electromagnetic Waves","text":""},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-101-time-dependent-electromagnetic-fields-in-a-vacuum-satisfy-the-wave-equation","title":"Section 10.1 - Time-Dependent Electromagnetic Fields in a Vacuum Satisfy the Wave Equation","text":"<p>Consider an empty space. Then, it is evident that</p> \\[\\begin{align}     \\nabla \\cdot \\mathbf{E} &amp;= 0 \\\\     \\nabla \\cdot \\mathbf{H} &amp;= 0 \\end{align}\\] \\[\\begin{align} \\nabla \\times \\mathbf{E} + \\frac{\\partial \\mathbf{B}}{\\partial t} &amp;= 0 \\\\ \\nabla \\times \\mathbf{H} - \\frac{\\partial \\mathbf{D}}{\\partial t} &amp;= 0 \\end{align}\\] <p>As \\(\\mathbf{B} = \\mu_0 \\mathbf{H}\\) and \\(\\mathbf{D} = \\varepsilon_0 \\mathbf{E}\\) in a vacuum, the third and fourth equations can be rewritten as</p> \\[\\begin{align} \\nabla \\times \\mathbf{E} + \\mu_0 \\frac{\\partial \\mathbf{H}}{\\partial t} &amp;= 0 \\\\ \\nabla \\times \\mathbf{H} - \\varepsilon_0 \\frac{\\partial \\mathbf{E}}{\\partial t} &amp;= 0 \\end{align}\\] <p>We can take the curl of both equations and then substitute to see that</p> \\[\\begin{align} \\nabla \\times \\nabla \\times \\mathbf{E} + \\mu_0 \\varepsilon_0 \\frac{\\partial^2 \\mathbf{E}}{\\partial t^2} &amp;= 0 \\\\ \\nabla \\times \\nabla \\times \\mathbf{H} + \\mu_0 \\varepsilon_0 \\frac{\\partial^2 \\mathbf{H}}{\\partial t^2} &amp;= 0 \\end{align}\\] <p>We can apply a vector identity to see</p> \\[\\begin{align} -\\nabla^2 \\mathbf{E} + \\mu_0 \\varepsilon_0 \\frac{\\partial^2 \\mathbf{E}}{\\partial t^2} &amp;= 0 \\\\ -\\nabla^2 \\mathbf{H} + \\mu_0 \\varepsilon_0 \\frac{\\partial^2 \\mathbf{H}}{\\partial t^2} &amp;= 0 \\end{align}\\]"},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-1011-the-wave-equation-and-plane-waves","title":"Section 10.1.1 - The Wave Equation and Plane Waves","text":"<p>Definition. The equation \\([\\frac{\\partial^2}{\\partial x^2} - \\frac{1}{v^2} \\frac{\\partial^2}{\\partial t^2}] f(x, t) = 0\\) is well-known to mathematicians (see Differential Equations), and is known as the wave equation. In physics, the speed of the wave is \\(v = c = \\frac{1}{\\sqrt{\\mu_0 \\varepsilon_0}}\\).</p> <p>Consider some function \\(f(s)\\). If \\(s = x - vt\\) or \\(x + vt\\), it is trivial to see that \\(f(x)\\) satisfies the wave equation.</p> <p>Definition. A plane wave is a solution to the Laplacian form of the last two Maxwell equations for empty space that also satisfy the one-dimensional wave equation. However, these solutions may not be valid electromagnetic waves as they are not guaranteed to satisfy the first two Maxwell equations.</p> <p>Notably, the functions for \\(\\mathbf{E} = \\mathbf{E}_0 f(s)\\) and \\(\\mathbf{H} = \\mathbf{H}_0 g(s)\\) do not have to be equal. However, \\(v = c\\).</p> <p>Definition. A plane electromagnetic wave is a plane wave which satisfies the first two Maxwell equations. The divergence equations restrict \\(\\mathbf{E}_0\\) and \\(\\mathbf{H}_0\\) to be in the plane normal to the direction of motion. That is, electomagnetic plane waves are transverse, not longitudinal.</p> <p>Additionally, the curl equations force \\(f(s) = g(s)\\), such that \\(H_0 = E_0 \\sqrt{\\frac{\\varepsilon_0}{\\mu_0}}\\).</p> <p>Definition. The quantity \\(Y_0 = \\sqrt{\\frac{\\varepsilon_0}{\\mu_0}}\\) is the vacuum admittance and its inverse, \\(Z_0 = \\sqrt{\\frac{\\mu_0}{\\varepsilon_0}}\\) is the vacuum impedance.</p> <p>If we assume the direction of propagation can be written as \\(\\hat{\\mathbf{k}}\\), we can write \\(f(s) = f(\\hat{\\mathbf{k}} \\cdot \\mathbf{r} - vt)\\), such that \\(\\mathbf{E}(\\mathbf{r}, t) = \\mathbf{E}_0 f(\\hat{\\mathbf{k}}\\cdot\\mathbf{r} - vt)\\), where \\(\\hat{\\mathbf{k}}\\cdot\\mathbf{E}_0 = 0\\).</p> <p>From this, we can see that \\(\\mathbf{H}(\\mathbf{r}, t) = \\sqrt{\\frac{\\varepsilon_0}{\\mu_0}} \\hat{\\mathbf{k}} \\times \\mathbf{E}_0 f(\\hat{\\mathbf{k}} \\cdot \\mathbf{r} - vt)\\). Similarly, \\(\\hat{\\mathbf{k}} \\cdot \\mathbf{H} = 0\\).</p> <p>Additionally, we can compute \\(\\mathbf{S} = \\mathbf{E} \\times \\mathbf{H} = c \\varepsilon_0 E_0^2 f^2(\\hat{\\mathbf{k}} \\cdot \\mathbf{r} - vt) \\hat{\\mathbf{k}}\\). We can also see that \\(\\varepsilon_0 E^2 = \\mu_0 H^2\\) at any given time.</p>"},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-1012-monochromatic-plane-waves","title":"Section 10.1.2 - Monochromatic Plane Waves","text":"<p>In any simple material, we like to say that \\(\\mathbf{D} = \\varepsilon \\mathbf{E}\\) and \\(\\mathbf{B} = \\mu \\mathbf{H}\\). However, this only holds true at a fixed frequency \\(\\omega\\). For multiple frequencies, we see that \\(\\mathbf{D}(\\omega) = \\varepsilon(\\omega)\\mathbf{E}(\\omega)\\) and \\(\\mathbf{B}(\\omega) = \\mu(\\omega)\\mathbf{H}(\\omega)\\). This causes problems. As such, we will want to consider waves that are only composed of one frequency under Fourier decomposition.</p> <p>Definition. A monochromatic plane wave is a plane wave in which the full Fourier series of \\(f(x)\\) has only one term. That is, \\(f(x)\\) is \\(\\sin(x)\\) or \\(\\cos(x)\\). We furthermore define a wave vector \\(\\mathbf{k}\\) as \\(\\mathbf{k} = k \\hat{\\mathbf{k}}\\), so that \\(\\omega = kc\\). Then,</p> \\[\\begin{align} \\mathbf{E}(\\mathbf{r}, t) &amp;= \\mathbf{E_0} \\cos(\\mathbf{k} \\cdot \\mathbf{r} - \\omega t) \\\\ \\mathbf{H}(\\mathbf{r}, t) &amp;= \\sqrt{\\frac{\\varepsilon_0}{\\mu_0}} \\hat{\\mathbf{k}} \\times \\mathbf{E}_0 \\cos(\\mathbf{k} \\cdot \\mathbf{r} - \\omega t) \\end{align}\\] <p>Notably, the frequency, or number of cycles per second, is \\(f = \\frac{\\omega}{2\\pi}\\), and wavelength \\(\\lambda = \\frac{2\\pi}{k}\\).</p> <p>We can calculate the energy density \\(u\\), energy current density \\(\\mathbf{S}\\), momentum density \\(\\mathbf{g}\\), and momentum current density \\(-\\overleftrightarrow{\\mathbf{T}}\\)</p>"},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-1013-monochromatic-plane-waves-in-a-linear-model","title":"Section 10.1.3 - Monochromatic Plane Waves in a Linear Model","text":"<p>Monochromatic plane waves with frequency \\(\\omega\\) in a simple linear material are similar to monochromatic plane waves in a vacuum, except when in a material, we know that the magnitude of the wave vector \\(k = \\frac{\\omega}{v}\\), and \\(v = \\frac{1}{\\sqrt{\\mu \\varepsilon}}\\).</p>"},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-1014-polarization-of-monochromatic-plane-waves","title":"Section 10.1.4 - Polarization of Monochromatic Plane Waves","text":"<p>Any plane wave described in such a way that \\(\\mathbf{E} = \\mathbf{E}_0 f(\\mathbf{k} \\cdot \\mathbf{r} - ct)\\) is linearly polarized in the direction of \\(\\mathbf{E}_0\\). That is, the direction of polarization is the direction of \\(\\mathbf{E}\\), and if that direction is unchanging, the wave is linearly polarized.</p> <p>Notably, an elliptically polarized wave can be described as follows:</p> \\[\\begin{align} \\mathbf{E}(\\mathbf{r}, t) &amp;= E_{x0} \\hat{\\mathbf{x}} \\cos(kz - \\omega t) + E_{y0} \\hat{\\mathbf{y}} \\sin(kz - \\omega t) \\\\ \\mathbf{H}(\\mathbf{r}, t) &amp;= \\sqrt{\\frac{\\varepsilon}{\\mu}} (E_{x0} \\hat{\\mathbf{y}} \\cos(kz - \\omega t) - E_{y0} \\hat{\\mathbf{x}} \\sin(kz - \\omega t)) \\end{align}\\] <p>If \\(E_{x0} = E_{y0}\\), the wave is said to be circularly polarized.</p>"},{"location":"physics/electrodynamics/10-electromagnetic-waves/#section-102-reflection-and-refraction-of-plane-electromagnetic-waves-at-a-a-planar-interface","title":"Section 10.2 - Reflection and Refraction of Plane Electromagnetic Waves at a a Planar Interface","text":"<p>This section will focus on plane monochromatic waves incident from material 1 onto material 2, where both materials are homogenous insulators and the surface between the two materials is smooth (on the scale of the wavelength).</p> <p>In this case, we must re-consider Maxwell's equations. We know from previous sections that \\(\\nabla \\cdot \\mathbf{E} = \\frac{\\mathbf{\\rho_e}}{\\varepsilon_0}\\) and \\(\\nabla \\cdot \\mathbf{H} = \\frac{\\mathbf{\\rho_m}}{\\mu_0}\\). We also know that \\(\\nabla \\cdot \\mathbf{D} = \\rho_{ef}\\) and \\(\\nabla \\cdot \\mathbf{B} = \\rho_{mf}\\).</p> <p>Consider the boundary between the two materials. If we consider \\(\\nabla \\cdot \\mathbf{D}\\), and take the integral over a Gaussian pillbox on the boundary, we can apply divergence theorem to see that \\(\\int_V \\nabla \\cdot \\mathbf{D} dV = \\int_{SofV} \\mathbf{D} \\cdot \\hat{\\mathbf{n}} dS = \\rho_{efree}\\). If we assume the materials are insulating, we do not expect to find any electrical charge, so \\(\\rho_{efree} = 0\\). Thus, we can say that \\(\\int_{SofV} D \\cdot \\hat{\\mathbf{n}} = 0\\), so \\(\\mathbf{D}_1 \\cdot \\hat{\\mathbf{n}} + \\mathbf{D}_2 \\cdot \\hat{\\mathbf{n}} = \\mathbf{D_1} \\cdot \\hat{\\mathbf{z}} + \\mathbf{D}_1 \\cdot (-\\hat{\\mathbf{n}}) = 0\\). Then, we can say that \\(\\mathbf{D}_1 \\cdot \\hat{\\mathbf{n}} = \\mathbf{D}_2 \\cdot \\hat{\\mathbf{n}}\\), or in simpler terms, \\(\\mathbf{D}_1^\\perp = \\mathbf{D}_2^\\perp\\).</p> <p>Applying the same logic to \\(\\mathbf{B}\\), we see that \\(\\mathbf{B}_1^\\perp = \\mathbf{B}_2^\\perp\\). Note that due to the existence of polarization and magnetization, we cannot say the same regarding \\(\\mathbf{E}\\) or \\(\\mathbf{H}\\).</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/","title":"Chapter 8 - Quasi-static Electrodynamics and Alternating Current Circuits","text":""},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-81-the-quasi-static-regime-of-electrodynamics","title":"Section 8.1 - The Quasi-static Regime of Electrodynamics","text":""},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-811-rc-circuit-time-dependent-circuits-with-resistor-and-capacitor-in-series-transient-currents","title":"Section 8.1.1 - RC Circuit - Time-dependent Circuits with Resistor and Capacitor in Series Transient Currents","text":"<p>Here, we have a DC voltage source followed by a switch, capacitor with capacitance \\(C\\), and a resistor with resistance \\(R\\).</p> <p>By Kirchoff's Voltage Law, we know that \\(V_{cell} = V_{capacitor} + V_{resistor}\\), so \\(V_{cell} = IR + \\frac{Q}{C}\\). As current is simply charge over time,</p> \\[V_{cell} = R\\frac{dQ}{dt} + \\frac{Q}{C}\\] <p>Assuming the capacitor is uncharged at \\(t = 0\\), we obtain the initial condition \\(Q(0) = 0\\). Solving the differential equation, we see that</p> \\[Q(t) = C V_{cell} (1 - e^{-\\frac{t}{RC}})\\] <p>Then, taking the derivative, we see that</p> \\[I = \\frac{dQ}{dt} = \\frac{V_{cell}}{R} e^{-\\frac{t}{RC}}\\] <p>If instead we assume an AC voltage source, we know that \\(V_{cell} = V_0 \\cos \\omega t\\). Then, by KVL,</p> \\[{V_0 \\cos \\omega t = I(t)R + \\frac{Q(t)}{C}}\\] <p>Now, assume that \\(I(t) = I_0 \\cos(\\omega t + \\phi)\\), as the current may be out-of-phase with voltage. Additionally, we assume that charge cannot accumulate outside of the capacitor. Then, with \\(\\frac{d}{dt} Q(t) = I(t)\\), we see that</p> \\[Q(t) = Q_0 + \\frac{I_0}{\\omega} \\sin(\\omega t + \\phi)\\] <p>Substituting into the formula for voltage, we see that</p> \\[V_0 \\cos \\omega t = I_0 (R \\cos (\\omega t + \\phi) + \\frac{1}{\\omega C} \\sin(\\omega t + \\phi)) + \\frac{Q_0}{C}\\] <p>With trigonometric identities, this becomes</p> \\[[V_0 - I_0 \\cos \\phi - \\frac{I_0}{wC} \\sin \\phi]\\cos(\\omega t) + [I_0 R \\sin \\phi - \\frac{I_0}{\\omega C} \\cos \\phi]\\sin(\\omega t) + \\frac{Q_0}{C} = 0\\] <p>Now, assume let the \\(\\frac{Q_0}{C}\\) vanishes, as there is no constant charge on the capacitor (which would imply an additional constant voltage). Then, for this equation to hold true at all times, the coefficients of \\(\\sin \\omega t\\) and \\(\\cos \\omega t\\) must equal zero. This will allow us to see that</p> \\[\\cos \\phi = \\frac{R}{\\sqrt{R^2 + X_C^2}}\\] <p>Definition. Here, the term \\(X_C = (wC)^{-1}\\) is the capacitive reactance of the circuit.</p> <p>Definition. We also can solve for current to see that \\(I_0 = \\frac{V_0}{Z}\\), where \\(Z = \\sqrt{R^2 + X_C^2}\\), where \\(Z\\) is the impedence of the circuit.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-812-quasi-static-error-for-a-parallel-plate-capacitor","title":"Section 8.1.2 - Quasi-Static Error for a Parallel Plate Capacitor","text":"<p>Consider a parallel-plate capacitor. We know that within the capacitor, the electric flux is \\(\\mathbf{D}(t) = \\varepsilon_0 \\mathbf{E}(t)\\). With the charge on a plate given by \\(Q(t)\\), we can say that \\(\\mathbf{D}(t) = \\frac{Q(t)}{\\pi R^2}\\).</p> <p>We also know by Ampere's law that \\(\\nabla \\times \\mathbf{H} = \\frac{\\partial}{\\partial t} \\mathbf{D}\\). From this, given circular platFrom this, applying Stokes to Ampere's Law, we see that</p> \\[\\mathbf{H} = \\frac{\\partial Q}{\\partial t} \\frac{s}{2 \\pi R^2} \\hat{\\mathbf{\\varphi}}\\] <p>This continues on in this manner, however, I've opted to skip most of the math.</p> <p>The correction term \\(\\delta E\\) can be written as \\(\\delta E = (\\frac{\\pi s}{Tc})^2 E_0\\), where \\(T\\) is the period of the sinusoidal current oscillations (that is, \\(\\omega = 2\\pi/T\\), or \\(T = 2\\pi / \\omega\\)). If this is much smaller than the size of the device, the correction can be neglected.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-813-inductance","title":"Section 8.1.3 - Inductance","text":"<p>For an inductor, the voltage drop across an inductor is directly proportional to the change in current. That is,</p> \\[\\Delta V_L = L \\frac{d^2Q}{dt^2} = L\\frac{dI}{dt}\\] <p>Consider a circular current loop with a voltage source in the \\(x-y\\) plane. Then, applying Faraday's law, \\(\\int_{circle} = (\\nabla \\times \\mathbf{E}) \\cdot \\hat{\\mathbf{z}} dS = -\\frac{\\partial}{\\partial t} \\int_{circle} \\mathbf{B} \\cdot \\hat{\\mathbf{z}} dS\\).</p> <p>Apply Stokes' law to the left hand side to see that \\(\\int_{circumference} \\mathbf{E} \\cdot d\\mathbf{l} = -\\frac{\\partial \\Phi_B}{\\partial t}\\).</p> <p>With \\(\\Phi_B = LI\\), we see the \"back EMF\" opposing the increasing current will be \\(\\mathbf{\\mathcal{E}} = -L \\frac{\\partial I}{\\partial t}\\).</p> <p>Consider a circuit with a voltage source, a switch, an inductor, and a resistor in series. Then, by KVL, \\(V_{cell} = L \\frac{dI}{dt} + IR\\).</p> <p>This is a differential equation. Assuming \\(I(0) = 0\\), we can see that</p> \\[I(t) = \\frac{V_{cell}}{R}(1 - e^{-\\frac{R}{L}t})\\] <p>Now, consider an alternating current voltage source. Then, by KVL, \\(V_0 \\cos \\omega t = R I(t) + L \\frac{dI(t)}{dt}\\). If we assume that current is also sinusoidal, we can say that \\(I(t) = I_0 \\cos(\\omega t + \\phi)\\). Substituting into the voltage expression,</p> \\[V_0 \\cos \\omega t = R I_0 \\cos(\\omega t + \\phi) + L \\omega I_0 \\sin(\\omega t + \\phi)\\] <p>After expanding using trigonometric identities and setting coefficients to zero, we see that</p> \\[\\sin \\phi = -\\frac{X_L}{Z}; \\cos \\phi = \\frac{R}{Z}; I_0 = \\frac{V_0}{Z}\\] <p>Definition. Here, \\(X_Z = \\omega L\\) is the impedence of the circuit.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-814-calculation-of-inductance","title":"Section 8.1.4 - Calculation of Inductance","text":"<p>Recall that the back EMF \\(\\mathbf{\\mathcal{E}} = -L \\frac{\\partial I}{\\partial T}\\). We can calculate the work done by this force as follows.</p> \\[\\frac{dW}{dt} = I(\\mathbf{\\mathcal{E}}) = IL \\frac{dI}{dt} = \\frac{1}{2} L \\frac{d}{dt}(I^2)\\] <p>Then, integrating both sides, we see that</p> \\[W = \\frac{1}{2}L\\int_0^{I^2(t)} I^2(t') dt' = \\frac{1}{2}LI^2\\] <p>We also know from Section 3.2 that the work needed to create a magnetic field is as follows.</p> \\[W = \\frac{1}{2} \\mu_0 \\int_V H^2 dV\\] <p>Now, consider a long air-filled solenoid with \\(n\\) turns per unit length and cross-sectional area \\(A\\). Then, we know the flux through a cross-section of the solenoid will be \\(\\Phi = BA = \\mu_0 n I A\\). Then, the back-EMF for one loop of the solenoid can be given by \\(\\mathbf{\\mathcal{E}}_{1 loop} = - \\frac{d\\Phi}{dt} = -\\mu_0 n A \\frac{dI}{dt}\\). Then, the total induced EMF will be \\(\\mathbf{\\mathcal{E}} = nl\\mathbf{\\mathcal{E}}_{1 loop}\\), where \\(l\\) is the length of the solenoid. Thus, by the definition of back-EMF,</p> \\[\\mathbf{\\mathcal{E}} = -nl \\mu_0 nA \\frac{dI}{dt} = -L\\frac{dI}{dt}\\] <p>So, \\(L = \\mu_0 n^2 Al\\)</p> <p>We can also compute thsi by energy. We know that \\(W = \\frac{1}{2} \\mu_0 \\int_V H^2 dV = \\frac{1}{2} \\mu_0 n^2 I^2 Al = \\frac{1}{2}LI^2\\). This simplifies immediately.</p> <p>Now, consider a coaxial cable. That is, consider a solid cylinder of radius \\(a\\) that conducts current in the \\(+z\\) direction. The circuit is completed by a thin cylindical shell outside of the conductor yet still with radius \\(a\\). We also assume that current density is uniform within the cylindrical conductor.</p> <p>Recall that from Ampere's Law, for \\(s \\in (0, a)\\), we have \\(\\mathbf{H}(s) = \\frac{I_enc}{2\\pi s}\\hat{\\mathbf{\\varphi}}\\), with \\(I_enc = \\frac{I\\pi s^2}{\\pi a^2}\\). Thus, \\(\\mathbf{H} = \\frac{Is}{2\\pi a^2}\\hat{\\mathbf{\\varphi}}\\). Then,</p> \\[W = \\frac{1}{2} \\mu_0 \\int_V H^2 dV = \\frac{1}{2} \\mu_0 l \\int_0^a 2\\pi s ds (\\frac{Is}{2\\pi a^2})^2 = \\frac{I^2}{2} \\frac{\\mu_0 l}{2\\pi} \\frac{1}{4}\\] <p>This implies that \\(L = \\frac{\\mu_0 l}{8\\pi}\\).</p> <p>We can also solve this via flux. We know that \\(\\mathbf{B}(s) = \\frac{u_0 Is}{2\\pi a^2}\\hat{\\mathbf{\\varphi}}\\). Then,</p> \\[\\Phi = \\int_0^a \\mathbf{B} \\cdot \\hat{\\mathbf{n}} dS = \\int_0^a \\frac{\\mu_0 Is}{2\\pi a^2} l ds = \\frac{\\mu_0 I l}{2\\pi} \\frac{1}{2}\\] <p>This is off by a factor of \\(2\\). Instead, multiply by a fator of \\(f(s) = \\frac{s^2}{a^2}\\) to see</p> \\[\\Lambda = LI = \\int_0^a \\frac{\\mu_0 I s^3}{2\\pi a^4} l ds = \\frac{\\mu_0 I l}{2\\pi} \\frac{1}{4}\\] <p>Note that due to the Skin Effect, at high frequencies, back EMF must be considered even inside the conductor.</p> <p>This becomes complicated, and is thus omitted.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-815-quasi-static-error-for-a-solenoidal-inductor","title":"Section 8.1.5 - Quasi-static Error for a Solenoidal Inductor","text":"<p>In section 5.2, we learned that in a long solenoid, \\(\\mathbf{H} = nI \\mathbf{z}\\), where \\(I\\) is the current and \\(n\\) the number of turns per uniut length. This, however, was dependent of the current being constant. Now, let current be represented as \\(I(t) = I_0 \\cos (\\omega t + \\phi)\\). Now, \\(\\mathbf{H}(t) = nI(t) \\hat{\\mathbf{z}}\\).</p> <p>This implies magnetic flux with a density of \\(\\mathbf{B} = \\mu_0 n I(t) \\hat{\\mathbf{z}}\\). Given the inductor with radius \\(s\\), this will cause changing flux \\(\\Phi_B(t) = \\mathbf{B} * A = \\mu_0 n I(t) \\pi s^2\\).</p> <p>By Faraday's Law,</p> \\[E_{induced} = -N \\frac{\\partial \\Phi_B}{\\partial{t}}\\] <p>This can be rearranged to see</p> \\[2\\pi s \\mathbf{E}_{induced}(t) = -\\frac{\\partial \\Phi_b(t)}{\\partial t} = -\\mu_0 n \\pi s^2 \\frac{\\partial}{\\partial t} I(t)\\] <p>This can be used to find \\(\\mathbf{E} = -\\mu_0 n \\frac{s}{2} \\frac{\\partial}{\\partial t}I(t) \\hat{\\mathbf{\\varphi}}\\), equivalent to a flux density \\(\\mathbf{D}(t) = -\\varepsilon_0 \\mu_0 n \\frac{s}{2} \\frac{\\partial}{\\partial t}I(t) \\hat{\\mathbf{\\varphi}}\\). We can then apply Ampere's law to see that</p> \\[\\nabla \\times \\mathbf{H} = \\frac{\\partial \\mathbf{D}(t)}{\\partial t} = -\\varepsilon_0 \\mu_0 n \\frac{s}{2} \\frac{\\partial^2}{\\partial t^2}I(t) \\hat{\\mathbf{\\varphi}}\\] <p>We can work backwards to find that \\(\\mathbf{H}(s, t) = (1 - \\frac{\\mu_0 \\varepsilon_0 s^2 \\omega^2}{4}) H_{z0}(t)\\hat{\\mathbf{z}}\\). Then, the same conditions should apply as in 8.1.2. That is, \\(\\omega\\) should be low enough or the d evice small enough that light can easily propagate across the device during one period of oscillation.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-82-circuits-with-resistance-capacitance-and-inductance-and-a-sinusoidal-emf","title":"Section 8.2 - Circuits with Resistance, Capacitance and Inductance and a Sinusoidal EMF","text":""},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-821-rlc-circuits","title":"Section 8.2.1 - RLC Circuits","text":"<p>Consider an AC voltage source, a resistor with resistance \\(R\\), inductor with inductance \\(L\\), and capacitor with capacitance \\(C\\) all in series. Then, by KVL,</p> \\[V(t) = RI(t) + \\frac{Q(t)}{C} + L \\frac{dI}{dt}\\] <p>Then, with \\(I(t) = I_0 \\cos(\\omega t + \\phi)\\), we can see that with inductive reactance \\(X_L = \\omega L\\) and capactive reactance \\(X_C = (\\omega C)^{-1}\\),</p> \\[I_0 = \\frac{V_0}{Z}; \\sin \\phi = \\frac{X_C - X_L}{Z}; \\cos \\phi = \\frac{R}{Z}; Z = \\sqrt{R^2 + (X_C - X_L)^2}\\] <p>Definition. The quantity \\(Z\\) is the impedence of the circuit.</p> <p>Definition. The resonance frequency is the frequency at which \\(X_C = X_L\\). This occurs only at \\(\\omega_0 = 1 / \\sqrt{LC}\\). Notably, the impedence equals the resistance (\\(Z = R\\)) and the current is in-phase with voltage (\\(\\phi = 0\\)).</p> <p>The instantaneous power delivered by the circuit is</p> \\[P(t) = V(t)I(t) = V_0 \\cos(\\omega t) \\frac{V_0}{Z(\\omega)}\\cos(\\omega t + \\phi)\\] <p>Averaged over one cycle (\\(T = 2\\pi / \\omega\\)),</p> \\[\\langle P(t) \\rangle = \\frac{V_0^2}{Z(\\omega)} \\frac{1}{T} \\int_0^T \\cos(\\omega t) [ \\cos(\\omega t)\\cos\\phi - \\sin(\\omega t)\\sin\\phi] dt = \\frac{V_0^2}{2Z(\\omega)}\\cos\\phi\\] <p>Note that \\(\\cos\\phi\\) = \\(R/Z\\), so</p> \\[\\langle P(t) \\rangle = \\frac{1}{2} \\frac{V_0^2R}{Z^2(\\omega)}\\] <p>Recall that the charactaristic times for a capacitor and inductor to charge are \\(T_C = RC\\) and \\(T_L = L/R\\). Then,</p> \\[\\langle P(t) \\rangle = \\frac{1}{2} \\frac{V_0^2}{r} \\frac{1}{1 + (\\omega T_l - (\\omega T_c)^{-1})^2}\\] <p>This has a clear maximum of \\(\\frac{1}{2} \\frac{V_0^2}{R}\\) for the frequency \\(\\omega T_L = \\frac{1}{\\omega T_C}\\), when \\(\\omega_0 = 1/\\sqrt{LC}\\).</p> <p>The width of the resonance, or the range of angular frequencies over which \\(\\frac{R^2}{Z^2(\\omega)}\\) is greater than half its peak value, is given by \\(\\Delta \\omega = \\frac{1}{T_L} = \\frac{L}{R} = \\omega_0^2 T_C\\).</p> <p>Note that all power dissipation happens over the resistor, not the inductor or capacitor.</p> <p>Now, consider a circuit in which the resistor, inductor, and capacitor are all in parallel. By KVL,</p> \\[V_0 \\cos(\\omega t) = RI_R(t) = L \\frac{dI_L(t)}{dt} = \\frac{Q_C(t)}{C}\\] <p>With currents given as \\(I_R(t) = I_{R0} \\cos(\\omega t + \\phi_R)\\), \\(I_L(t) = I_{L0} \\cos(\\omega t + \\phi_L)\\), and \\(I_C(t) = I_{C0} \\cos(\\omega t + \\phi_C)\\), we obtain</p> \\[ \\begin{array}{ccc}     I_{R0} = \\frac{V_0}{R} &amp; I_{L0} = \\frac{V_0}{\\omega L} &amp; I_{C0} = V_0 \\omega C \\\\     \\phi_R = 0 &amp; \\phi_L = -\\pi / 2 &amp; \\phi_C = \\pi/2 \\end{array} \\] <p>The total current them becomes \\(I(t) = \\frac{V_0}{R} \\cos(\\omega t) + V_0(\\frac{1}{X_L} - \\frac{1}{X_C})\\sin(\\omega t)\\). Additionally, \\(\\langle P(t) \\rangle = \\frac{1}{2} \\frac{V_0^2}{R}\\).</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-822-applications","title":"Section 8.2.2 - Applications","text":"<p>The voltage across the capacitor is higher than the voltage across the capacitor for frequencies less than the resonance frequency. The inverse holds for frequencies greater than the resonance frequency. This can be proved by computing \\(V_C / V_0 = R / Z(\\omega)\\) and \\(V_L / V_0 = \\omega L / Z(\\omega)\\).</p> <p>To eliminate high frequencies, take the voltage across the capacitor. Otherwise, take the voltage across the resistor.</p> <p>These circuits can also be used in tuners by taking the voltage across the resistorr.</p>"},{"location":"physics/electrodynamics/8-quasi-static-electrodynamics-ac-circuitts/#section-823-energy-in-inductors-and-capacitors","title":"Section 8.2.3 - Energy in Inductors and Capacitors","text":"<p>We know the energy in an electromagnetic field is</p> \\[u = \\frac{1}{2}(\\varepsilon_0 e^2 + \\mu_u H^2)\\] <p>In a capacitor, we cannot directly state the energy. However, we can state its rate of change:</p> \\[\\frac{du_E}{dt} = \\mathbf{E} \\cdot \\frac{d\\mathbf{D}}{dt}\\] <p>In the case where \\(\\mathbf{D} = \\varepsilon \\mathbf{E}\\), that is, in the presence of a simple dielectric,</p> \\[u_E = \\frac{1}{2} \\varepsilon E^2 = \\frac{1}{2}\\mathbf{E} \\cdot \\mathbf{D}\\] <p>This is mirrored in solenoids / inductors, where</p> \\[\\frac{du_M}{dt} = \\mathbf{H} \\cdot \\frac{d\\mathbf{B}}{dt}\\] <p>In the case where \\(\\mathbf{B} = \\mu \\mathbf{H}\\), that is, in the presence of a simple magnetic material,</p> \\[u_M = \\frac{1}{2}\\mathbf{H} \\cdot \\mathbf{B}\\] <p>Lastly, this continues for electromagnetic fields.</p> \\[\\frac{du_{EM}}{dt} = \\mathbf{E} \\cdot \\frac{d\\mathbf{D}}{dt} + \\mathbf{H} \\cdot \\frac{d\\mathbf{B}}{dt}\\] <p>In simple electromagnetic materials, we see that</p> \\[u_{EM} = \\frac{1}{2}(\\mathbf{E} \\cdot \\mathbf{D} + \\mathbf{H} \\cdot \\mathbf{B}) = \\frac{1}{2}(\\varepsilon E^2 + \\mu H^2)\\]"},{"location":"physics/electrodynamics/9-conservation-laws/","title":"Chapter 9 - Conservation Laws","text":""},{"location":"physics/electrodynamics/9-conservation-laws/#section-91-continuity-equation-as-a-model-conservation-law","title":"Section 9.1 - Continuity Equation as a Model Conservation Law","text":"<p>The laws of physics exhibit temporal, spatial, and angular symmetry. That is, the laws of physics do not change dependent on the time, position, and rotation of the observer. These symmetries lead to conservation of energy, momentum, and angular momentum respectively.</p> <p>The conservation of chargee is another symmetry-based conservation law, derived from \"gauge invariance\". In this section, this is conservation law is assumed to be valid.</p> <p>Recall the continuity equation, that is, \\(\\frac{\\partial \\rho(\\mathbf{r})}{\\partial t} = - \\nabla \\cdot \\mathbf{J}(\\mathbf{r})\\). That is, the charge density at any point in space is equal to to the divergence of the current. From this, we can integrate to find \\(Q(t) = \\int_V \\rho(\\mathbf{r}, t) dV\\), and \\(\\frac{dQ}{dt} = -\\int_{\\partial V} \\mathbf{J}(\\mathbf{r}, t) \\cdot \\hat{\\mathbf{n}} dS\\). This is a local conservation law, because it does not address situations in which charge decreases in one region and increases in another without the flow of current.</p>"},{"location":"physics/electrodynamics/9-conservation-laws/#section-92-conservation-of-electomagnetic-energy","title":"Section 9.2 - Conservation of Electomagnetic Energy","text":"<p>Consider a volume \\(V\\) with surface \\(\\partial V\\), that encloses some magnetic and electric point charges. Then, for any electric charge \\(q_{ei}\\) or magnetic charge \\(q_{mj}\\), the force on each charge is</p> \\[\\begin{align}     \\mathbf{F}_i &amp;= q_{ei} (\\mathbf{E}_i + \\mathbf{v}_i \\times \\mathbf{B}_i) \\\\     \\mathbf{F}_j &amp;= q_{mi} (\\mathbf{H}_j - \\mathbf{v}_j \\times \\mathbf{D}_j) \\end{align}\\] <p>We also know that the rate at which energy changes due to changing fields is \\(\\frac{dw_i}{dt} = \\mathbf{F}_i \\cdot \\mathbf{v}_i\\) and \\(\\frac{dw_m}{dt} = \\mathbf{F}_j \\cdot \\mathbf{v}_j\\). This allows us to conclude that at any point \\(\\mathbf{r}\\) inside the volume, the rate at which the mechanical energy density changes is</p> \\[\\frac{du_{mech}}{dt} = \\sum_i \\delta(\\mathbf{r} - \\mathbf{r}_i) \\mathbf{F}_i \\cdot \\mathbf{v}_i + \\delta(\\mathbf{r} - \\mathbf{r}_j) \\mathbf{F}_j \\cdot \\mathbf{v}_j\\] <p>Since \\((\\mathbf{v}_i \\times \\mathbf{B}_i) \\cdot \\mathbf{v}_i = 0\\) and \\((\\mathbf{v}_j \\times \\mathbf{D}_j) \\cdot \\mathbf{v}_j = 0\\), and the current densities are given as \\(\\mathbf{J}_e(\\mathbf{r}) = \\sum_i \\mathbf{v}_i q_{ei}\\delta(\\mathbf{r} - \\mathbf{r}_i)\\) and \\(\\mathbf{J}_m(\\mathbf{r}) = \\sum_j \\mathbf{v}_j q_{mj}\\delta(\\mathbf{r} - \\mathbf{r}_j)\\), we can rewrite this as</p> \\[\\frac{du_{mech}}{dt} = \\mathbf{J}_e(\\mathbf{r}) \\cdot \\mathbf{E}(\\mathbf{r}) + \\mathbf{J}_m(\\mathbf{r}) \\cdot \\mathbf{H}(\\mathbf{r})\\] <p>Combine this with the Maxwell equations to remove current densities, we see that</p> \\[\\frac{du_{mech}}{dt} = (\\nabla \\times \\mathbf{H} - \\frac{\\partial \\mathbf{H}}{\\partial t}) \\cdot \\mathbf{E} + (-\\nabla \\times \\mathbf{E} - \\frac{\\partial \\mathbf{B}}{\\partial t}) \\cdot \\mathbf{H}\\] <p>With a vector identity, this simplifies to</p> \\[\\frac{du_{mech}}{dt} = -\\nabla \\times (\\mathbf{E} \\times \\mathbf{H})\\] <p>Definition. We call \\(\\mathbf{S} = \\mathbf{E} \\times \\mathbf{H}\\) the Poynting vector.</p> <p>With this vector, we can define</p> \\[\\frac{du_{mech}}{dt} = -\\nabla \\times \\mathbf{S}\\]"},{"location":"physics/electrodynamics/9-conservation-laws/#section-922-energy-density-for-linear-materials","title":"Section 9.2.2 - Energy Density for Linear Materials","text":"<p>For a simple material, that is, one in which \\(\\mathbf{D} = \\varepsilon \\mathbf{E}\\) and \\(\\mathbf{B} = \\mu \\mathbf{H}\\), we can express the rate of change of electomagnetic energy \\(\\frac{\\partial u_{em}}{\\partial t}\\) as \\(\\frac{\\partial u_{em}}{\\partial t} = \\frac{1}{2} \\frac{\\partial}{\\partial t} (\\mathbf{E} \\cdot \\mathbf{D} + \\mathbf{H} \\cdot \\mathbf{B})\\). After integration, we can see that \\(u_{em} = \\frac{1}{2}(\\varepsilon E^2 + \\mu H^2)\\).</p> <p>Definition. A material is said to be an anisotropic linear material if \\(\\mathbf{D} = \\overleftrightarrow{\\mathbf{\\varepsilon}} \\cdot \\mathbf{E}\\) and \\(\\mathbf{B} = \\overleftrightarrow{\\mathbf{\\mu}} \\cdot \\mathbf{H}\\). Then, the internal electromagnetic energy becomes</p> \\[u_{em} = \\frac{1}{2}(\\mathbf{E} \\cdot \\overleftrightarrow{\\mathbf{\\varepsilon}} \\cdot \\mathbf{E}+ \\mathbf{H} + \\overleftrightarrow{\\mathbf{\\mu}} \\cdot \\mathbf{H}) = \\frac{1}{2}\\sum_{i,j}(\\varepsilon_{ij}E_iE_j + \\mu_{ij}H_iH_j)\\] <p>If the dyadics are symmetric, the energy functions uniquely specify the energy in terms of fields. In general, the polarization or magnetization of a material may depend on its past history and on time, and as such, the energy density for such materials cannot be expressed entirely in terms of the fields.</p>"},{"location":"physics/electrodynamics/9-conservation-laws/#section-923-poynting-vector-examples","title":"Section 9.2.3 - Poynting Vector Examples","text":"<p>Consider a long coaxial cable, bridged by a constant voltage \\(V\\) on one side and a resistor \\(R\\) on the other. Then, we know that between the conductors, \\(\\mathbf{H} = \\frac{R}{2\\pi s R}\\mathbf{\\varphi}\\). Additionally, we know that</p> \\[V=\\int_a^b \\mathbf{E} \\cdot d\\mathbf{l} = \\frac{Q}{2\\pi \\ell \\varepsilon_0} \\ln(\\frac{b}{a}) \\Rightarrow \\frac{Q}{\\ell} = \\frac{2\\pi\\varepsilon_0}{\\ln(\\frac{b}{a})} V\\] <p>This then implies that \\(\\mathbf{E} = \\frac{V}{\\ln(\\frac{b}{a})s} \\hat{\\mathbf{s}}\\). We can then solve for both the energy density and Poynting vector, as well as \\(\\mathbf{v} = \\mathbf{S} / u\\), the speed at which energy moves through the cable. With the impedance for a coaxial cable \\(Z_{C0} = \\sqrt{\\frac{\\mu_0}{\\varepsilon_0}} \\frac{\\ln(\\frac{b}{a})}{2\\pi}\\), we see that</p> \\[\\mathbf{v} = \\frac{2c \\hat{\\mathbf{z}}}{\\frac{R}{Z_{C0}} + \\frac{Z_{C0}}{R}}\\] <p>Consider a long cylindrical ohmic wire of radius \\(a\\), length \\(L\\), and resistivity \\(\\rho\\) along the \\(z\\)-axis. If this wire is carrying a constant current \\(I\\), we know that inside the wire, \\(E_z = \\rho J = \\rho \\frac{I}{\\pi a^2}\\). From Ampere's Law, \\(H_\\phi = \\frac{s}{2\\pi a^2} I\\). Then, inside the wire,</p> \\[\\mathbf{S} = -s \\frac{\\rho I^2}{2 \\pi^2 a^4} \\hat{\\mathbf{s}}\\] <p>Outside the wire, we know that \\(\\mathbf{E} = \\frac{\\rho I}{\\pi a^2} \\hat{\\mathbf{z}}\\) and \\(\\mathbf{H} = \\frac{I}{2\\pi s}\\hat{\\mathbf{\\varphi}}\\), so</p> \\[\\mathbf{S} = -\\frac{\\rho I}{\\pi a^2} \\frac{I}{2\\pi s} \\hat{\\mathbf{s}}\\] <p>Notably, inside the wire, \\(\\nabla \\cdot \\mathbf{S} = \\frac{\\rho I^2}{\\pi^2 a^4}\\), but is equal to \\(0\\) outside of the wire.</p> <p>Further examples are present but omitted.</p>"},{"location":"physics/electrodynamics/9-conservation-laws/#section-93-conservation-of-momentum-and-maxwell-stress-tensor","title":"Section 9.3 - Conservation of Momentum and Maxwell Stress Tensor","text":"<p>We know that the rate of change of momentum for any given particle is simply the force acting on it. To calculate this, recall the force density:</p> \\[\\mathbf{f} = \\sum_i \\mathbf{F}_i\\delta(\\mathbf{r}-\\mathbf{r}_i) + \\sum_j \\mathbf{F}_j\\delta(\\mathbf{r}-\\mathbf{r}_j) = \\sum_i q_{ei}\\delta(\\mathbf{r}-\\mathbf{r}_i)(\\mathbf{E} + \\mathbf{v}_i \\times \\mathbf{B}) + \\sum_j q_{ej} \\delta(\\mathbf{r}-\\mathbf{r}_i) (\\mathbf{H} - \\mathbf{v}_j \\times \\mathbf{D})\\] <p>Converting to currents, we see that</p> \\[\\mathbf{f}(\\mathbf{r}) = \\rho_e(\\mathbf{r})\\mathbf{E}(\\mathbf{r}) + \\mathbf{J}_e(\\mathbf{r}) \\times \\mathbf{B}(\\mathbf{r}) + \\rho_m(\\mathbf{r}) + \\mathbf{H}(\\mathbf{r}) - \\mathbf{J}_m(\\mathbf{r}) \\times \\mathbf{D}(\\mathbf{r})\\] <p>Substituting in Maxwell's Equations, we see that</p> \\[\\mathbf{f}(\\mathbf{r}) + \\frac{\\partial}{\\partial t}(\\mathbf{D} \\times \\mathbf{B}) = \\varepsilon_0 (\\nabla \\cdot \\mathbf{E})\\mathbf{E} + (\\nabla \\times \\mathbf{E})\\times\\mathbf{D} + \\mu_0(\\nabla \\cdot \\mathbf{H})\\mathbf{H} + (\\nabla \\times \\mathbf{H})\\times\\mathbf{B}\\] <p>Now, we claim that the right-hand side is the divergence of some tensor \\(\\overleftrightarrow{\\mathbf{T}}\\), so that</p> \\[\\mathbf{f}(\\mathbf{r}) + \\frac{\\partial}{\\partial t}(\\mathbf{D} \\times \\mathbf{B}) = \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}\\] <p>This tensor is the Maxwell Stress Tensor. We claim that the divergence of this tensor is composed of both an electric and magnetic part, so that \\(\\nabla \\cdot \\overleftrightarrow{\\mathbf{T}} = \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}_e + \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}_m\\). Then, we  can state</p> \\[\\begin{align} \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}_e &amp;= \\varepsilon_0 [(\\nabla \\cdot \\mathbf{E})\\mathbf{E} + (\\nabla \\times \\mathbf{E})\\times \\mathbf{E}] \\\\ \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}_m &amp;= \\varepsilon_0 [(\\nabla \\cdot \\mathbf{H})\\mathbf{H} + (\\nabla \\times \\mathbf{H})\\times \\mathbf{H}] \\end{align}\\] <p>We know that \\(\\nabla \\cdot(\\mathbf{EE}) = (\\nabla \\cdot \\mathbf{E})\\mathbf{E} + (\\mathbf{E} \\cdot \\nabla)\\mathbf{E}\\) and \\(\\nabla \\cdot(\\overleftrightarrow{\\mathbf{I}}f) = \\nabla f\\). If we let \\(f = \\frac{1}{2}\\mathbf{E} \\cdot \\mathbf{E}\\), we see that \\(\\nabla(\\frac{1}{2}\\mathbf{E} \\cdot \\mathbf{E}) = (\\mathbf{E} \\cdot \\nabla)\\mathbf{E} + (\\nabla \\times \\mathbf{E})\\mathbf{E}\\). Then, we see that</p> \\[\\begin{align} \\overleftrightarrow{\\mathbf{T}}_e &amp;= \\varepsilon_0 \\mathbf{EE} - \\frac{\\varepsilon_0}{2} \\overleftrightarrow{\\mathbf{I}}(\\mathbf{E} \\cdot \\mathbf{E}) \\\\ \\overleftrightarrow{\\mathbf{T}}_m &amp;= \\mu_0 \\mathbf{HH} - \\frac{\\mu_0}{2} \\overleftrightarrow{\\mathbf{I}}(\\mathbf{H} \\cdot \\mathbf{H}) \\end{align}\\] <p>Knowing that \\(\\overleftrightarrow{\\mathbf{T}} = \\overleftrightarrow{\\mathbf{T}}_e + \\overleftrightarrow{\\mathbf{T}}_m\\), and that \\(u = \\frac{1}{2}(\\varepsilon_0 E^2 + \\mu_0 H^2)\\) is the energy density of the electromagnetic fields in a vacuum,</p> \\[\\overleftrightarrow{\\mathbf{T}} = \\varepsilon_0 \\mathbf{EE} + \\mu_0 \\mathbf{HH} - \\overleftrightarrow{\\mathbf{I}}u\\] <p>Additionally, we denote the time rate of change of the momentum density of the electromagnetic fields as \\(\\mathbf{g}(\\mathbf{r}) = \\mathbf{D}(\\mathbf{r}) \\times \\mathbf{B}(\\mathbf{r})\\). Thus,</p> \\[\\mathbf{f}(\\mathbf{r}) = \\frac{\\partial}{\\partial t}\\mathbf{g} = \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}\\] <p>The Divergence Theorem states that \\(\\int_V(\\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}) dV = \\int_{SofV} dS \\hat{\\mathbf{n}} \\cdot \\overleftrightarrow{\\mathbf{T}}\\). We can prove this by expanding the left-hand side over a cube. Note that as \\(\\overleftrightarrow{\\mathbf{T}}\\) is symmetric, \\(\\hat{\\mathbf{n}} \\cdot \\overleftrightarrow{\\mathbf{T}} = \\overleftrightarrow{\\mathbf{T}} \\cdot \\hat{\\mathbf{n}}\\).</p> <p>Given a static field, the momentum does not change in time. That is,</p> \\[\\frac{\\partial}{\\partial t} \\mathbf{g} = \\frac{\\partial}{\\partial t}(\\mathbf{D} \\times \\mathbf{B}) = 0\\] <p>Then, we can see that \\(\\mathbf{f}(\\mathbf{r}) = \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}}\\). We can thus integrate over the volume to find force on an object.</p> \\[\\mathbf{F} = \\int_V \\mathbf{f}(\\mathbf{r}) dV = \\int_V \\nabla \\cdot \\overleftrightarrow{\\mathbf{T}} dV = \\int_{\\partial V} dS \\hat{\\mathbf{n}} \\cdot \\overleftrightarrow{\\mathbf{T}} = \\int_{\\partial V} \\overleftrightarrow{\\mathbf{T}} \\cdot \\hat{\\mathbf{n}} dS\\]"},{"location":"physics/electrostatics/1-math/","title":"Chapter 1 - Mathematics","text":""},{"location":"physics/electrostatics/1-math/#15-dyads-and-tensors","title":"1.5 - Dyads and Tensors","text":"<p>Definition. A dyadic is a representation of two-ish vectors.</p> \\[ \\stackrel{\\leftrightarrow}{\\mathbf{D}} = \\begin{matrix}     D_{xx} \\hat{\\mathbf{x}}\\hat{\\mathbf{x}} &amp;+ D_{xy} \\hat{\\mathbf{x}}\\hat{\\mathbf{y}} &amp;+ D{xz} \\hat{\\mathbf{x}}\\hat{\\mathbf{z}} \\\\     + D_{yx} \\hat{\\mathbf{y}}\\hat{\\mathbf{x}} &amp;+ D_{yy} \\hat{\\mathbf{y}}\\hat{\\mathbf{y}} &amp;+ D{yz} \\hat{\\mathbf{y}}\\hat{\\mathbf{z}} \\\\     + D_{zx} \\hat{\\mathbf{z}}\\hat{\\mathbf{x}} &amp;+ D_{zy} \\hat{\\mathbf{z}}\\hat{\\mathbf{y}} &amp;+ D{zz} \\hat{\\mathbf{z}}\\hat{\\mathbf{z}} \\end{matrix} \\] <p>Definition. If a dyadic can be written as a composition of two vectors \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), it is called a dyad.</p> \\[ \\mathbf{AB} = \\begin{matrix}     A_x B_x \\hat{\\mathbf{x}}\\hat{\\mathbf{x}} &amp;+ A_x B_y \\hat{\\mathbf{x}}\\hat{\\mathbf{y}} &amp;+ A_x B_z \\hat{\\mathbf{x}}\\hat{\\mathbf{z}} \\\\     + A_y B_x \\hat{\\mathbf{y}}\\hat{\\mathbf{x}} &amp;+ A_y B_y \\hat{\\mathbf{y}}\\hat{\\mathbf{y}} &amp;+ A_y B_z \\hat{\\mathbf{y}}\\hat{\\mathbf{z}} \\\\     + A_z B_x \\hat{\\mathbf{z}}\\hat{\\mathbf{x}} &amp;+ A_z B_y \\hat{\\mathbf{z}}\\hat{\\mathbf{y}} &amp;+ A_z B_z \\hat{\\mathbf{z}}\\hat{\\mathbf{z}} \\end{matrix} \\] <p>The dot product of a dyad \\(\\stackrel{\\leftrightarrow}{\\mathbf{D}} = \\mathbf{AB}\\) and vector \\(\\mathbf{v}\\) can be written as follows:</p> \\[ (\\mathbf{AB}) \\cdot \\mathbf{v} = \\mathbf{A} (\\mathbf{B} \\cdot \\mathbf{v}) \\] <p>Definition. A symmetric/antisymmetric dyadic is defined the same way that a matrix is.</p> <p>Definition. The identity dyadic is \\(\\stackrel{\\leftrightarrow}{\\mathbf{I}} = \\hat{\\mathbf{x}}\\hat{\\mathbf{x}} + \\hat{\\mathbf{y}}\\hat{\\mathbf{y}} + \\hat{\\mathbf{z}}\\hat{\\mathbf{z}}\\).</p> <p>Definition. FOr a tensor, with coordinates \\(u^i\\), we have two sets of basis vectors:</p> \\[ \\mathbf{e}_i = \\pdv{\\mathbf{r}}{u^i} \\] \\[ \\mathbf{e}^i = \\nabla{u^i} \\]"},{"location":"physics/electrostatics/1-math/#19-helmholtz-theorem","title":"1.9 - Helmholtz Theorem","text":"<p>Given an arbitrary vector field \\(\\mathbf{F}(\\mathbf(r))\\), we can write said field as a composition of a curl-free component \\(\\mathbf{\\Phi}(\\mathbf{r})\\) and a divergence-free component \\(\\mathbf{A}(\\mathbf{r})\\) as follows:</p> \\[ \\mathbf{F}(\\mathbf{r}) = - \\nabla{\\mathbf{\\Phi}(\\mathbf{r})} + \\nabla \\times{\\mathbf{A}(\\mathbf{r})} \\] <p>Definition. Here, the gradient of the scalar potential is \\(\\nabla{\\mathbf{\\Phi}(\\mathbf{r})}\\) and the curl of the vector potential is \\(\\nabla \\times{\\mathbf{A}(\\mathbf{r})}\\). Thus, the scalar potential is \\(\\mathbf{\\Phi}(\\mathbf{r})\\) and the vector potential is \\(\\mathbf{A}(\\mathbf{r})\\).</p> <p>Letting said field be over bounded volume \\(V\\) with closed surface \\(\\partial V\\), and the functions \\(\\mathbf{C}(\\mathbf{r}) = \\nabla \\times{\\mathbf{F}(\\mathbf{r})}\\) and \\(\\mathbf{D}(\\mathbf{r}) = \\nabla \\cdot \\mathbf{F}(\\mathbf{r})\\) are known, we can say that</p> \\[ \\mathbf{\\Phi}(\\mathbf{r}) = \\frac{1}{4 \\pi} \\int_V \\frac{D(\\mathbf{r}')}{|{\\mathbf{r}-\\mathbf{r}'}|} d{V'} - \\frac{1}{4 \\pi} \\int_{\\partial V} \\frac{\\mathbf{F}(\\mathbf{r}') \\cdot \\mathbf{n}'}{|{\\mathbf{r}-\\mathbf{r}'}|} d{S'} \\] \\[ \\mathbf{A}(\\mathbf{r}) = \\frac{1}{4 \\pi} \\int_V \\frac{C(\\mathbf{r}')}{|{\\mathbf{r}-\\mathbf{r}'}|} d{V'} - \\frac{1}{4 \\pi} \\int_{\\partial V} \\mathbf{n}' \\times \\frac{\\mathbf{F}(\\mathbf{r}')}{|{\\mathbf{r}-\\mathbf{r}'}|} d{S'} \\] <p>Now, assume that \\(\\lim(\\frac{\\mathbf{F}(\\mathbf{r})}{\\mathbf{r}}) = 0\\) as \\(\\mathbf{r} \\rightarrow \\infty\\), with a large enough volume, we see that the second terms vanish.</p> \\[ \\mathbf{\\Phi}(\\mathbf{r}) = \\frac{1}{4 \\pi} \\int_V \\frac{D(\\mathbf{r}')}{|{\\mathbf{r}-\\mathbf{r}'}|} d{V'} \\] \\[ \\mathbf{A}(\\mathbf{r}) = \\frac{1}{4 \\pi} \\int_V \\frac{C(\\mathbf{r}')}{|{\\mathbf{r}-\\mathbf{r}'}|} d{V'} \\]"},{"location":"physics/electrostatics/2-coulomb/","title":"Chapter 2 - Coulomb's Laws, Electric and Magnetic Fields","text":""},{"location":"physics/electrostatics/2-coulomb/#section-22-parallel-treatment-of-electric-and-magnetic-fields","title":"Section 2.2 - Parallel Treatment of Electric and Magnetic Fields","text":"<p>Consider two point charges, \\(q\\) and \\(Q\\), with the latter being at the origin of the coordinate system. Let \\(q\\) be located at point \\(\\mathbf{r}\\) relative to the origin.</p> <p>Thus, according to Coulomb's Law,</p> \\[ \\begin{align}     F^e_{qQ}(\\mathbf{r}) &amp;= \\frac{q_e Q_e}{4 \\pi \\varepsilon_0} \\frac{\\hat{\\mathbf{r}}}{|\\mathbf{r}|^2} \\\\     F^m_{qQ}(\\mathbf{r}) &amp;= \\frac{q_m Q_m}{4 \\pi \\mu_0} \\frac{\\hat{\\mathbf{r}}}{|\\mathbf{r}|^2} \\end{align} \\] <p>Divide by the charge \\(q\\) to obtain the electric or magnetic field at point \\(\\mathbf{r}\\).</p> \\[ \\begin{align}     E(\\mathbf{r}) &amp;= \\frac{Q_e}{4 \\pi \\varepsilon_0} \\frac{\\hat{\\mathbf{r}}}{|\\mathbf{r}|^2} \\\\     H(\\mathbf{r}) &amp;= \\frac{Q_m}{4 \\pi \\mu_0} \\frac{\\hat{\\mathbf{r}}}{|\\mathbf{r}|^2} \\end{align} \\] <p>Now, let \\(Q\\) be at point \\(\\mathbf{r'}\\). Then, the unit vector becomes \\(\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}}|\\), and we see the following.</p> \\[ \\begin{align}     E(\\mathbf{r}) &amp;= \\frac{Q_e}{4 \\pi \\varepsilon_0} \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\\\     H(\\mathbf{r}) &amp;= \\frac{Q_m}{4 \\pi \\mu_0} \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\end{align} \\] <p>With multiple charges, we can apply the superposition principal to see the following:</p> \\[ \\begin{align}     E(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\varepsilon_0} \\sum_{i=1}^N Q_e \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\\\     H(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\mu_0} \\sum_{i=1}^N Q_m \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\end{align} \\] <p>We can convert this to an integral as \\(N\\) goes to infinity.</p> \\[\\begin{align} E(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\varepsilon_0} \\int_V \\rho_e(\\mathbf{r'}) \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} d V' \\\\ H(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\mu_0} \\int_V \\rho_m(\\mathbf{r'}) \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} d V' \\end{align}\\]"},{"location":"physics/electrostatics/2-coulomb/#section-23-divergence-and-curl-of-the-electrostatic-or-magnetostatic-field","title":"Section 2.3 - Divergence and Curl of the Electrostatic or Magnetostatic Field","text":"<p>From a lot of advanced math, we know that</p> \\[\\nabla \\cdot \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} = 4 \\pi \\delta(\\mathbf{r}-\\mathbf{r'})\\] <p>Now, apply the divergence operator over \\(\\mathbf{r}\\) to the electrostatic and magnetostatic fields.</p> \\[\\begin{align} \\nabla \\cdot E(\\mathbf{r}) &amp;= \\nabla \\cdot (\\frac{1}{4 \\pi \\varepsilon_0} \\int_V \\rho_e(\\mathbf{r'}) \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} d V') \\\\ \\nabla \\cdot H(\\mathbf{r}) &amp;= \\nabla \\cdot (\\frac{1}{4 \\pi \\mu_0} \\int_V \\rho_m(\\mathbf{r'}) \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} d V') \\end{align}\\] <p>As the divergence operator does not operate on \\(\\mathbf{r'}\\), we see that</p> \\[\\begin{align} \\nabla \\cdot E(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\varepsilon_0} \\int_V \\rho_e(\\mathbf{r'}) \\nabla \\cdot (\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3}) d V' \\\\     &amp;= \\frac{1}{4 \\pi \\varepsilon_0} 4 \\pi \\int_V \\rho_e(\\mathbf{r'}) \\delta(\\mathbf{r}-\\mathbf{r'}) d V' \\\\     &amp;= \\frac{\\rho_e(\\mathbf{r})}{\\varepsilon_0} \\\\ \\nabla \\cdot H(\\mathbf{r}) &amp;= \\frac{1}{4 \\pi \\mu_0} \\int_V \\rho_m(\\mathbf{r'}) \\nabla \\cdot (\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3}) d V' \\\\     &amp;= \\frac{1}{4 \\pi \\mu_0} 4 \\pi \\int_V \\rho_m(\\mathbf{r'}) \\delta(\\mathbf{r}-\\mathbf{r'}) d V' \\\\     &amp;= \\frac{\\rho_m(\\mathbf{r})}{\\mu_0} \\end{align}\\] <p>The curl of an electrostatic or magnetostatic is relatively simple.</p> \\[ \\begin{align}     \\nabla \\times{E(\\mathbf{r})} &amp;= \\frac{1}{4 \\pi \\varepsilon_0} \\int_V \\rho_e(\\mathbf{r'}) \\nabla \\times{(\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3})} d V' \\\\     \\nabla \\times{H(\\mathbf{r})} &amp;= \\frac{1}{4 \\pi \\mu_0} \\int_V \\rho_m(\\mathbf{r'}) \\nabla \\times{(\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3})} d V' \\\\ \\end{align} \\] <p>Additionally, we know \\(\\nabla \\times{f\\mathbf{A}} = f \\nabla \\times{\\mathbf{A}} + \\nabla{f}\\times\\mathbf{A}\\). Thus,</p> \\[ \\begin{align}     \\nabla \\times{(\\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3})} &amp;= \\frac{1}{|\\mathbf{r}-\\mathbf{r'}|^3} \\nabla \\times{(\\mathbf{r}-\\mathbf{r'})} + (\\nabla \\times{\\frac{1}{|\\mathbf{r}-\\mathbf{r'}|^3}}) \\times (\\mathbf{r}-\\mathbf{r'}) \\\\ \\end{align} \\] <p>We can verify that \\(\\nabla \\times{(\\mathbf{r}-\\mathbf{r'})} = 0\\), cancelling the first term. Additionally, \\(\\nabla \\times{\\frac{1}{|\\mathbf{r}-\\mathbf{r'}|^3}} = -3 \\frac{\\mathbf{r}-\\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^5}\\), which when crossed with \\(\\mathbf{r}-\\mathbf{r'}\\), will cancel. Thus, all terms in the curl cancel, so for a static field, the curl is zero.</p>"},{"location":"physics/electrostatics/2-coulomb/#section-24-electric-and-magnetic-flux-densities","title":"Section 2.4 - Electric and Magnetic Flux Densities","text":"<p>The electric and magnetic flux density vectors are given by \\(\\varepsilon_0 \\mathbf{E}\\) and \\(\\mu_0 \\mathbf{H}\\).</p> <p>Now, given \\(S\\) is a surface enclosing \\(Q_e\\) or \\(Q_m\\) total charge, we denote flux as following:</p> \\[ \\Phi_e = \\varepsilon_0 \\int_S \\mathbf{E} \\cdot \\hat{\\mathbf{n}} d = Q_e S \\text{ or } \\Phi_m = \\mu_0 \\int_S \\mathbf{H} \\cdot \\hat{\\mathbf{n}} d S = Q_m \\] <p>Thus, applying divergence theorem,</p> \\[ Q_e = \\Phi_e = \\varepsilon_0 \\int_S \\mathbf{E} \\cdot \\hat{\\mathbf{n}} d = \\varepsilon_0 \\int_V \\nabla \\cdot \\mathbf{E} d V \\] \\[ Q_m = \\Phi_m = \\mu_0 \\int_S \\mathbf{H} \\cdot \\hat{\\mathbf{n}} d = \\varepsilon_0 \\int_V \\nabla \\cdot \\mathbf{H} d V \\] <p>Since \\(Q_e = \\int_V \\rho_e d V\\) and \\(Q_m = \\int_V \\rho_m d V\\), we see that</p> \\[ \\begin{align}     \\int_V \\rho_e d V &amp;= \\varepsilon_0 \\int_V \\nabla \\cdot \\mathbf{E} d V \\\\     \\rho_e &amp;= \\varepsilon_0 \\int_V \\nabla \\cdot \\mathbf{E} d V \\\\     \\int_V \\rho_m d V &amp;= \\mu_0 \\int_V \\nabla \\cdot \\mathbf{H} d V \\\\     \\rho_m &amp;= \\mu_0 \\int_V \\nabla \\cdot \\mathbf{H} d V \\\\ \\end{align} \\] <p>Definition. This is known as Gauss' Law.</p> <p>With applicable symmetry, the integral factor becomes simply \\(E(r)*A\\), where \\(A\\) is the area of the surface at \\(r\\).</p>"},{"location":"physics/electrostatics/3-electro-magnetic-potentials/","title":"Chapter 3 - Electric and Magnetic Scalar Potentials","text":""},{"location":"physics/electrostatics/3-electro-magnetic-potentials/#section-31-work-and-energy-in-electrostatics-and-magnetostatics","title":"Section 3.1 - Work and Energy in Electrostatics and Magnetostatics","text":"<p>The force on charge \\(q\\) is given by \\(\\mathbf{F}(\\mathbf{r}) = q_e \\mathbf{E}(\\mathbf{r})\\) or \\(\\mathbf{F}(\\mathbf{r}) = q_m \\mathbf{H}(\\mathbf{r})\\). If this charge is moved \\(d{\\mathbf{l}} = d x \\hat{\\mathbf{x}} + d y \\hat{\\mathbf{y}} + d z \\hat{\\mathbf{z}}\\), the change in internal energy (work) this produces can be written as</p> \\[ d{U}= - \\mathbf{F} \\cdot d{\\mathbf{l}} \\] <p>Rewriting this, \\(\\mathbf{F} = -\\nabla{U}\\), with \\(U\\) as potential energy. Now, we can denote this change in internal energy in terms of \\(q\\) as follows:</p> \\[ \\mathbf{E}(\\mathbf{r}) = \\frac{1}{q_e} \\mathbf{F_e}(\\mathbf{r}) = - \\frac{1}{q_e} \\nabla{U_e(\\mathbf{r})} = -\\nabla{V_e(\\mathbf{r})} \\] <p>The units of electrostatic potential is Joule/Coulomb, also known as a Volt. Thus, the units of the electric field should be expressed in Volts/meter. Similarly,</p> \\[ \\mathbf{H}(\\mathbf{r}) = \\frac{1}{q_m} \\mathbf{F_m}(\\mathbf{r}) = - \\frac{1}{q_m} \\nabla{U_m(\\mathbf{r})} = -\\nabla{V_m(\\mathbf{r})} \\] <p>The units of magnetostatic potential is Joule/Weber, also known as an Ampere. Thus, the units of the magnetic field can be written as Amperes/meter.</p> <p>With this, we can calculate work. Moving a charge \\(q\\) from \\(A\\) to \\(B\\), we see that</p> \\[ \\delta W = \\int_A^B \\mathbf{F} \\cdot d{\\mathbf{l}} = q_e \\int_A^B \\mathbf{E} \\cdot d{\\mathbf{l}} = -q_e \\int_A^B \\nabla{\\mathbf{V}} \\cdot d{\\mathbf{l}} = -q_e \\delta V_e \\] <p>Strictly speaking, this is a potential difference. To find the absolute potential, assume a point charge \\(Q\\) at the origin, and a charge \\(q\\). We take the work as \\(q\\) moves from \\(\\mathbf{r'} = \\mathbf{\\infty}\\) to \\(\\mathbf{r'} = \\mathbf{r}\\). Thus,</p> \\[ W = -q_e \\frac{Q_e}{4 \\pi \\varepsilon_0} \\int_{\\infty}^0 \\frac{\\hat{\\mathbf{r'}}}{r'^2} \\cdot (\\hat{\\mathbf{r'}}) d{r'} = -q_e \\frac{Q_e}{4 \\pi \\varepsilon_0} [\\frac{-1}{r'}]_{\\infty}^{r'} = q_e \\frac{Q_e}{4 \\pi \\varepsilon_0} \\frac{1}{r} \\] \\[ W = -q_m \\frac{Q_m}{4 \\pi \\mu_0} \\int_{\\infty}^0 \\frac{\\hat{\\mathbf{r'}}}{r'^2} \\cdot (\\hat{\\mathbf{r'}}) d{r'} = -q_m \\frac{Q_m}{4 \\pi \\mu_0} [\\frac{-1}{r'}]_{\\infty}^{r'} = q_m \\frac{Q_m}{4 \\pi \\mu_0} \\frac{1}{r} \\] <p>Letting the potential as \\(\\mathbf{r} \\rightarrow \\infty\\) equal \\(0\\) be our reference and dividing out \\(q\\), we find that the voltage for arrangement is the following:</p> \\[ V_e(\\mathbf{r}) = \\frac{Q_e}{4 \\pi \\varepsilon_0 r} \\text{ and } V_m(\\mathbf{r}) = \\frac{Q_m}{4 \\pi \\mu_0 r} \\] <p>Now, if we let the stationary charge \\(Q\\) be located at \\(\\mathbf{r'}\\), we see that</p> \\[ V_e(\\mathbf{r}) = \\frac{Q_e}{4 \\pi \\varepsilon_0}{|\\mathbf{r}-\\mathbf{r'}|} \\text{ and } V_m(\\mathbf{r}) = \\frac{Q_m}{4 \\pi \\mu_0}{|\\mathbf{r}-\\mathbf{r'}|} \\] <p>If we allow multiple charges, this becomes</p> \\[ V_e(\\mathbf{r}) = \\frac{1}{4\\pi \\varepsilon_0} \\sum_{i=1}^N \\frac{Q_{ei}}{|\\mathbf{r}-\\mathbf{r_i}|} \\] <p>Taking this to its natural limit,</p> \\[ V_e(\\mathbf{r}) = \\frac{1}{4 \\pi \\varepsilon_0} \\int_{V'} \\frac{\\rho_e(\\mathbf{r'})}{|\\mathbf{r}-\\mathbf{r'}}| d{V'} \\] \\[ V_m(\\mathbf{r}) = \\frac{1}{4 \\pi \\mu_0} \\int_{V'} \\frac{\\rho_m(\\mathbf{r'})}{|\\mathbf{r}-\\mathbf{r'}}| d{V'} \\]"},{"location":"physics/electrostatics/3-electro-magnetic-potentials/#section-32-energy-of-a-charge-distribution","title":"Section 3.2 - Energy of a Charge Distribution","text":"<p>Given two point charges \\(Q_{e1}, Q_{e2}\\) we know the work to bring them together is</p> \\[ W_2 = W_{21} = \\frac{1}{4 \\pi \\varepsilon_0} \\frac{Q_{e1} Q_{e2}}{|\\mathbf{r_2} - \\mathbf{r_1}|} \\] <p>Superposition applies here. The energy to create \\(N\\) charges is</p> \\[ W_n = \\frac{1}{2} \\frac{4 \\pi \\varepsilon_0} \\sum_{i = 1}^{N} \\sum_{j &gt; i}^{N} \\frac{Q_{ei}Q_{ej}}{|\\mathbf{r_i}-\\mathbf{r_j}|} \\] <p>For the sake of symmetry, sum overall charges and divide by 2.</p> \\[ W_n = \\frac{1}{2} \\frac{1}{4 \\pi \\varepsilon_0} \\sum_{i = 1}^{N} \\sum_{j \\neq i}^{N} \\frac{Q_{ei}Q_{ej}}{|\\mathbf{r_i}-\\mathbf{r_j}|} \\] <p>Rearranging, we see the following:</p> \\[ W_n = \\frac{1}{2} \\sum_{i = 1}^{N}Q_{ei} \\sum_{i \\neq j}^{N} \\frac{1}{4 \\pi \\varepsilon_0} \\frac{Q_{ej}}{|\\mathbf{r_i}-\\mathbf{r_j}|} = \\frac{1}{2}\\sum_{i = 1}^{N} Q_{ei} V(\\mathbf{r_i}) \\] <p>We can rewrite this as a Riemann sum and convert to an integral.</p> \\[ W_e = \\frac{1}{2} \\int_V p_e(\\mathbf{r}) V_e(\\mathbf{r}) d V ; \\quad W_m = \\frac{1}{2} \\int_V p_m(\\mathbf{r}) V_m(\\mathbf{r}) d V \\] <p>We can also express this as</p> \\[ W_e = \\frac{1}{2} \\frac{1}{4 \\pi \\varepsilon_0} \\int_V \\int_{V'} \\frac{\\rho_e(\\mathbf{r})\\rho_e(\\mathbf{r'})}{|\\mathbf{r}-\\mathbf{r'}|} d{V'} d{V} \\] \\[ W_m = \\frac{1}{2} \\frac{1}{4 \\pi \\mu_0} \\int_V \\int_{V'} \\frac{\\rho_m(\\mathbf{r})\\rho_m(\\mathbf{r'})}{|\\mathbf{r}-\\mathbf{r'}|} d{V'} d{V} \\] <p>Note the \\(\\frac{1}{2}\\) is the same anti-double-counting factor introduced previously. If we were to determine the potential based on a different set of charges, the factor would be absent.</p> <p>We can now write an expression for energy of a charge density in terms of the field that it produces.</p> \\[ W = \\frac{\\varepsilon_0}{2} \\int_V (\\nabla \\cdot \\mathbf{E}(\\mathbf{r})) V(\\mathbf{r}) d V \\] <p>Simplifying, we see that</p> \\[ W_e = \\frac{\\varepsilon_0}{2} \\int_{V} E^2(\\mathbf{r}) d V ; \\quad W_m = \\frac{\\mu_0}{2} \\int_{V} H^2(\\mathbf{r}) d V \\]"},{"location":"physics/electrostatics/3-electro-magnetic-potentials/#section-33-the-poisson-and-laplace-equations","title":"Section 3.3 - The Poisson and Laplace Equations","text":"<p>We know that \\(\\mathbf{E}(\\mathbf{r}) = -\\nabla \\cdot V_e(\\mathbf{r})\\) and \\(\\mathbf{H}(\\mathbf{r}) = -\\nabla \\cdot V_m(\\mathbf{r})\\)</p> <p>Combined this, as well as the first of the Maxwell equations, we see that</p> \\[ \\nabla \\cdot \\mathbf{E} = -\\nabla \\cdot \\nabla V_e = - \\nabla^2{V_e} = \\frac{\\rho_e}{\\varepsilon_0} \\] \\[ \\nabla \\cdot \\mathbf{H} = -\\nabla \\cdot \\nabla V_m = - \\nabla^2{V_m} = \\frac{\\rho_m}{\\mu_0} \\] <p>The last inequality is called the Poisson Equation, or the inhomogeneous Laplace equation.</p> <p>To solve this equation, we define a Green function as follows:</p> \\[ \\nabla^2 G(\\mathbf{r}, \\mathbf{r'}) = \\delta(\\mathbf{r} - \\mathbf{r'}) \\] <p>Now, we can construct a potential function in terms of said green function that satisfies the Laplace equation.</p> \\[ V_e(\\mathbf{r}) = - \\int_V G(\\mathbf{r}, \\mathbf{r'}) \\frac{\\rho_e(\\mathbf{r'})}{\\varepsilon_0} d{V'} \\] <p>This is the specific solution. Let \\(\\psi(\\mathbf{r})\\) be a solution to the homogenous equation. We can state the following:</p> \\[ V_e(\\mathbf{r}) = \\psi(\\mathbf{r}) - \\int_V G(\\mathbf{r}, \\mathbf{r'}) \\frac{\\rho_e(\\mathbf{r'})}{\\varepsilon_0} d{V'} \\] <p>We will consider the potential of a point charge. THat is, the limit of potential is zero as distance approaches infinity.</p> <p>Recall the potential of a point charge:</p> \\[ V_e(\\mathbf{r}) = \\frac{Q_e}{\\varepsilon_0} \\frac{1}{4 \\pi |\\mathbf{r} - \\mathbf{r}|} \\] <p>We know that \\(- \\nabla^2{V(\\mathbf{r})} = \\nabla \\cdot \\mathbf{E}(\\mathbf{r})\\). Thus, recall the electric field of a point charge.</p> \\[ \\mathbf{E}(\\mathbf{r}) = -\\nabla{V(\\mathbf{r})} = \\frac{Q_e}{\\varepsilon_0} \\nabla({\\frac{-1}{4\\pi|\\mathbf{r}-\\mathbf{r'}|}}) = \\frac{Q_e}{\\varepsilon_0} \\frac{\\mathbf{r} - \\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\] <p>Taking the divergence, we find that</p> \\[ - \\nabla^2{V(\\mathbf{r})} = G(\\mathbf{r}, \\mathbf{r'}) \\frac{Q_e}{\\varepsilon_0} = \\frac{Q_e}{\\varepsilon_0} \\nabla^2({\\frac{-1}{4\\pi|\\mathbf{r}-\\mathbf{r'}|}}) =  \\frac{Q_e}{\\varepsilon_0} \\nabla \\cdot \\frac{\\mathbf{r} - \\mathbf{r'}}{|\\mathbf{r}-\\mathbf{r'}|^3} = \\frac{Q_e}{\\varepsilon_0} \\delta(\\mathbf{r} - \\mathbf{r'}) \\] <p>Thus, we see that</p> \\[ \\nabla^2 {\\frac{-1}{4\\pi}}{|\\mathbf{r}-\\mathbf{r'}|} = \\delta(\\mathbf{r} - \\mathbf{r'}) \\quad \\Rightarrow \\quad G(\\mathbf{r}, \\mathbf{r'}) = {\\frac{-1}{4\\pi}}{|\\mathbf{r}-\\mathbf{r'}|} \\] <p>Finally,</p> \\[ V_e(\\mathbf{r}) = \\int_{V'} \\frac{1}{4 \\pi |\\mathbf{r} - \\mathbf{r}|} \\frac{\\rho_e}{\\varepsilon_0} d{V'} \\] \\[ V_m(\\mathbf{r}) = \\int_{V'} \\frac{1}{4 \\pi |\\mathbf{r} - \\mathbf{r}|} \\frac{\\rho_m}{\\mu_0} d{V'} \\]"},{"location":"physics/electrostatics/3-electro-magnetic-potentials/#section-34-the-laplace-and-poisson-equations-with-boundary-conditions","title":"Section 3.4 - The Laplace and Poisson Equations with Boundary Conditions","text":"<p>Theorem. The Mean Value Theorem states that if a function satisfies the laplace equation for every point within a region, then the value of the function at the center of the applicable region is equal to the average of the function along the boundary of said region.</p> <p>This can be extended to the Method of Relaxations, in which each point in a mesh is defined by the average of its neighboring points. This is only useful in computer graphics.</p> <p>An interesting consequence of this states that there are no local minima or maxima within said region. The global maximum and minimum must be located at the boundary.</p> <p>Theorem. This leads to Earnshaw's Theorem. To make an electric trap to hold charges, more than zero forces must be applied to the charge, so that if the charge leaves its dedicated position it is forced back. Depending on the sign, at said point, potential must increase or decrease in all directions. However, this would force a local extrema. This cannot be possible.</p> <p>Theorem. The solution to a Laplace or Poisson equation is unique.</p>"},{"location":"physics/electrostatics/3-electro-magnetic-potentials/#section-35-multipole-expansion-of-the-electrostatic-or-magnetostatic-field","title":"Section 3.5 - Multipole Expansion of the Electrostatic or Magnetostatic Field","text":"<p>We want a simple way to write the Green function.</p> <p>Let us assume all charge is contained in a sphere with radius \\(R\\) centered at the origin. Then, for points \\(r\\) far from the origin, the Green function can be written as</p> \\[ \\frac{1}{4 \\pi|\\mathbf{r}-\\mathbf{r'}|} = \\frac{1}{4\\pi \\sqrt{r^2 - 2\\mathbf{r} \\cdot \\mathbf{r'} + r'^2}} = \\frac{1}{4\\pi r}(1 - 2 \\hat{\\mathbf{r}} \\cdot \\hat{\\mathbf{r'}} + \\frac{r'}{r} + \\frac{r'^2}{r^2})^{-\\frac{1}{2}} \\] <p>This inverse square root term \\((1 - 2 \\hat{\\mathbf{r}} \\cdot \\hat{\\mathbf{r'}} + \\frac{r'}{r} + \\frac{r'^2}{r^2})^{-\\frac{1}{2}}\\) can be expanded as a power series in \\(\\frac{r'}{r}\\).</p> <p>The first two terms of this power series are simple enough.</p> \\[ G(\\mathbf{r}, \\mathbf{r'}) = \\frac{1}{4 \\pi |\\mathbf{r}-\\mathbf{r'}|} \\approx \\frac{1}{4 \\pi r} ( 1 + \\frac{\\hat{\\mathbf{r}} \\cdot \\mathbf{r'}}{r}); \\quad \\text{ for}  r &gt; r' \\] <p>Applying this to the equation for voltage, we see that</p> \\[ V_e(r) = \\frac{1}{\\varepsilon_0} \\int_{V'} G(\\mathbf{r}, \\mathbf{r'}) p_e(\\mathbf{r'}) d{V'} \\approx \\frac{1}{4 \\pi \\varepsilon_0 r} \\int_{V'}  (1 + \\frac{\\hat{\\mathbf{r}} \\cdot \\mathbf{r'}}{r}) p_e(\\mathbf{r'}) d{V'} = \\frac{Q_e}{4 \\pi \\varepsilon_0 r} + \\frac{\\hat{\\mathbf{r}} \\cdot \\mathbf{p}}{4 \\pi \\varepsilon_0 r^2} \\] <p>Definition. The first and second terms of this equation are the monopole and dipole terms respectively.</p> <p>Definition. We define \\(\\mathbf{p}\\) as the electric dipole moment, and in the magnetic version, \\(\\mathbf{m}\\) as the magnetic dipole moment as follows:</p> \\[ \\mathbf{p} = \\int_{V'} \\mathbf{r'} \\rho_e(\\mathbf{r'}) d{V'} \\] <p>Notably, the moments only depend on the charge density, not the point at which the field is being examined. That is, this integral only needs to be computed once.</p> <p>To compute higher-order terms, let \\(\\varepsilon = 2\\frac{r'}{r}\\hat{\\mathbf{r}}\\cdot\\hat{\\mathbf{r'}}-(\\frac{r'}{r})^2\\). Now we can expand \\((1-\\varepsilon)^{-\\frac{1}{2}}\\).</p> \\[ (1-\\varepsilon)^{-\\frac{1}{2}} = 1 + \\frac{1}{2}\\varepsilon + \\frac{3}{8}\\varepsilon^2 + \\frac{5}{16}\\varepsilon^3 + \\ldots \\] <p>However, we want an expansion in terms of \\(t = \\frac{r'}{r}\\). To do this, we write the expansion as</p> \\[ \\frac{1}{4 \\pi |\\mathbf{r}-\\mathbf{r'}|} = \\frac{1}{4 \\pi r} \\sum_{n=0}^{\\infty} (\\frac{r'}{r}) P_n(\\hat{\\mathbf{r}} \\cdot \\hat{\\mathbf{r'}}) \\] <p>Here, \\(P_n(\\hat{\\mathbf{r}} \\cdot \\hat{\\mathbf{r'}})\\) is a polynomial. Because \\(|\\mathbf{r}-\\mathbf{r'}|\\) is symmetric, we can say that if \\(r' &gt; r\\) instead, simply switch the two. Thus the equation becomes</p> \\[ \\frac{1}{4 \\pi |\\mathbf{r}-\\mathbf{r'}|} = \\frac{1}{4 \\pi} \\sum_{n=0}^{\\infty} (\\frac{r'^n_{&lt;}}{r^{n+1}_{&gt;}}) P_n(\\hat{\\mathbf{r}} \\cdot \\hat{\\mathbf{r'}}) \\] <p>Where \\(r_&gt;\\) is the greater of \\(r, r'\\), and \\(r_&lt;\\) the lesser.</p> <p>Definition. The polynomials \\(P_n(x)\\) are Legendre Polynomials. We define them as follows:</p> \\[ (1 - 2tx + t^2)^{-\\frac{1}{2}} = \\sum_{n=0}^\\infty t^n P_n(x) \\] <p>Note that as a quirk of the function, \\(P_n(1) = 1\\) for all \\(n\\).</p> <p>We can apply these quadrupole and beyond terms to the violate or other equations, however, this becomes very messy.</p>"},{"location":"physics/electrostatics/4-conductors/","title":"Chapter 4 - Conductors and Static Electric Fields","text":""},{"location":"physics/electrostatics/4-conductors/#section-41-introduction","title":"Section 4.1 - Introduction","text":"<p>We will focus primarily on electric fields and charges. For the purposes for this section, we will assume insulators are perfect.</p>"},{"location":"physics/electrostatics/4-conductors/#section-42-electrostatic-properties-of-a-conductor","title":"Section 4.2 - Electrostatic Properties of a Conductor","text":"<p>In a metal or conductor, there are plentiful charges not bound to a particular atom and are thus free to move throughout the material.</p> <p>We note that there is no electric fiend inside a conductor, as charges internal to the material would move under the force it generates until they find a configuration that eliminates the field. This may happen, but not in electrostatics.</p> <p>Additionally, as the field is zero, it follows from Maxwell's equations that there is no charge inside a conductor. However, charge may be present at the surface. For sufficiently symmetric charges, this charge may be calculated.</p> <p>Consider any two points internal to the conductor. The voltage between said points is defined as \\(\\int_A^B \\mathbf{E} \\cdot d{\\mathbf{l}}\\). Since \\(\\mathbf{E} = 0\\) inside the conductor, the voltage difference must be zero. Thus, any two points in or on the surface (TODO: Why on the surface?) of a conductor must be at the same potential.</p> <p>The electric field at the surface of a conductor is perpendicular to its surface. Consider some displacement \\(d{\\mathbf{l}}\\). Now, \\(\\mathbf{E} \\cdot d{\\mathbf{l}} = \\mathbf{E}_s \\cdot d{\\mathbf{l}}_s + \\mathbf{E}_p \\cdot d{\\mathbf{l}}_p = d{V_s} + d{V_p}\\), in terms of parallel and perpendicular components. The parallel voltage difference is zero, so the electric field must be zero.</p> <p>Consider the surface of a conductor with surface charge density \\(\\sigma_e\\). A cylinder with one end inside and one end outside said surface, with its axis normal to said surface, will be a Gaussian \"pillbox\", which will show that with V being the volume of the pillbox, \\(\\int_V \\nabla \\cdot \\mathbf{E} d{V} = \\frac{Q_e}{\\varepsilon_0} = \\frac{A\\sigma_e}{\\varepsilon_0}\\). Thus, \\(\\sigma_e = \\varepsilon_0 E\\).</p>"},{"location":"physics/electrostatics/4-conductors/#section-43-exercises-involving-conductors-at-fixed-potentials","title":"Section 4.3 - Exercises involving conductors at fixed potentials","text":"<p>Consider a square with left and right potentials \\(V(0, y) = V(l, y) = V_1\\) and \\(V(x, 0) = V(x, l) = V_2\\). Since we are uniform in \\(z\\), we can say that \\(V(x, y) = X(x)Y(y)\\) and apply separation of variables.</p> <p>In spherical polar coordinates, we see that with azimuthal symmetry, \\(V(r, \\theta) = \\sum_{l=0}^\\infty a_l r^l P_l(cos\\theta)\\) where \\(P_l(x)\\) are Legendre polynomials.</p> <p>Theorem. 4.3.3: A Laplace equation's solution must be unique inside a volume \\(\\Omega\\) if \\(\\int_{d{\\Omega}}[\\Phi(\\mathbf{r})\\nabla{\\Phi{\\mathbf{r}}} \\cdot \\hat{\\mathbf{n}} d{S} = 0]\\). With this, consider a surface \\(d{\\Omega}\\) that surrounds conductors. The integral vanishes if a) the potential is specified on each conductor or b) the total charge on each conductor is specified.</p> <p>Now, define \\(\\Phi(\\mathbf{r})\\) as the difference between any two potential solutions to the Laplace equation at point \\(\\mathbf{r}\\). Since potential must be a constant,</p> \\[ \\int_{d{\\Omega}}[\\Phi(\\mathbf{r})\\nabla{\\Phi{\\mathbf{r}}}] \\cdot \\hat{\\mathbf{n}} d{S} = \\sum_{i=1}^N \\Phi_i \\int_{d{\\Omega_i}} \\nabla{\\Phi{\\mathbf{r}}} \\cdot \\hat{\\mathbf{n}} d{S} \\] <p>Thus, if potential is specified, \\(\\Phi_i\\) vanishes for that conductor. If the total charge is instead specified, the gradient vanishes because there is no difference in charge between any two points.</p>"},{"location":"physics/electrostatics/4-conductors/#section-44-electric-field-polarization-field-and-flux-density-in-the-presence-of-conductors","title":"Section 4.4 - Electric Field, Polarization Field, and Flux Density in the Presence of Conductors","text":"<p>Definition. A bound charge is any charge in a conductor that is bound to an atom and not free to be redistributed at the surface. We say that bound charges are the source of the polarization field \\(\\mathbf{P}\\). Additionally, we note the charge density of bound charges is \\(\\rho_{eb}\\). Thus,</p> \\[ \\nabla \\cdot \\mathbf{P} = - \\rho_{eb} \\] <p>This field is zero outside of a material, and if non-zero inside a material, will drop to zero at the surface discontinuously. If there is a component perpendicular to the surface, the discontinuity will generate curl. If there is a component parallel to the surface, it will generate divergence.</p> <p>Definition. Charges not bound are called free, with density denoted as \\(\\rho_{ef}\\). Combined with \\(\\rho_{eb}\\), they form the basis of the electric field. THat is,</p> \\[ \\varepsilon_0 \\nabla \\cdot \\mathbf{E} = \\rho_{ef} + \\rho_{eb} \\] <p>Definition. The electric flux density field \\(\\mathbf{D}\\) is defined as</p> \\[ \\mathbf{D} = \\varepsilon_0 \\mathbf{E} + \\mathbf{P} \\] <p>Both \\(\\mathbf{D}\\) and \\(\\mathbf{P}\\) have units of Coulombs/m^2. Additionally, we see that</p> \\[ \\nabla \\cdot \\mathbf{D} = \\nabla \\cdot (\\varepsilon_0 \\mathbf{E} + \\mathbf{P}) = \\nabla \\cdot \\varepsilon_0 \\mathbf{E} + \\nabla \\cdot \\mathbf{P} = (\\rho_{ef} + \\rho_{eb}) - \\rho_{eb} = \\rho_{ef} \\]"},{"location":"physics/electrostatics/4-conductors/#section-45-induced-electric-charges-their-potentials-and-fields","title":"Section 4.5 - Induced Electric Charges, their Potentials and Fields","text":"<p>This is an application chapter.</p>"},{"location":"physics/electrostatics/4-conductors/#section-46-capacitance","title":"Section 4.6 - Capacitance","text":"<p>Definition. The capacitance of an object \\(C\\) is the charge per volt, such that</p> \\[ C := \\frac{Q}{V} \\] <p>This unit, \\(\\frac{C}{V}\\), is known as a Farad. For a sphere, \\(C = 4 \\pi \\varepsilon_0 R\\). For a parallel plate capacitor, this reduces to \\(C = \\frac{epsilon_0 A}{d}\\).</p>"},{"location":"physics/electrostatics/4-conductors/#section-47-forces-on-charged-conductors-in-electric-fields","title":"Section 4.7 - Forces on Charged Conductors in Electric Fields","text":"<p>We know that \\(\\mathbf{F} = \\int \\mathbf{E}_{ext}(\\mathbf{r}) \\rho_e(\\mathbf{r}) dV\\), where \\(\\mathbf{E}_{ext}(\\mathbf{r})\\) is the external electric field and \\(\\rho_e(\\mathbf{r})\\) is the charge density of the object.</p>"},{"location":"physics/electrostatics/5-moving-charges/","title":"Chapter 5 - Electrodynamics with Moving Charges","text":""},{"location":"physics/electrostatics/5-moving-charges/#section-51-currents-in-steady-state-regime","title":"Section 5.1 - Currents in Steady-State Regime","text":"<p>We want to work in a steady-state system. Thus, we restrict ourselves to currents that do not change in time.</p> <p>With math, we see that \\(\\nabla \\cdot \\mathbf{J}(\\mathbf{r}) = -\\frac{\\partial \\rho(\\mathbf{r})}{\\partial t}\\). Since we are only considering a steady-state system, \\(\\nabla \\cdot \\mathbf{J}_e = \\nabla \\cdot \\mathbf{J}_m = 0\\).</p> <p>Definition. The conductance of a material is \\(G = \\frac{1}{R}\\), where \\(R\\) is the resistance of a material.</p> <p>For a wire of uniform cross-sectional area, we see that \\(G = \\sigma \\frac{A}{L}\\), where \\(A\\) is the cross-sectional area, \\(L\\) is the length of the wire, and \\(\\sigma\\) is the conductivity of a wire. Inverted, we see that \\(R\\) = \\(\\rho \\frac{L}{A}\\), where \\(\\rho = \\frac{1}{\\sigma}\\) is the resistivity of the wire.</p> <p>Definition. Ohm's Law can be written as \\(I = G V\\), or inverted, \\(V = IR\\). In a wire, we see that current density \\(\\mathbf{} = \\frac{I}{A} = \\sigma \\frac{V}{L} = \\sigma \\mathbf{E}\\)</p>"},{"location":"physics/electrostatics/5-moving-charges/#section-52-currents-and-curling-fields","title":"Section 5.2 - Currents and Curling Fields","text":"<p>We know that \\(\\mathbf{J}_e = \\nabla \\times{\\mathbf{H}}\\) and \\(\\mathbf{J}_m = -\\nabla \\times{\\mathbf{E}}\\). That is, current densities cause the opposing field to curl.</p> <p>For a wire with current \\(I_e\\), we see that applying Stoke's theorem to the first equation,</p> <p>$ \\int_S \\nabla \\times{\\mathbf{H}} \\cdot \\hat{\\mathbf{n}} d{S} = \\int_{\\partial S} = \\mathbf{H} \\cdot d{\\mathbf{l}}$. Apply the identity \\(\\nabla \\times{\\mathbf{H}} = \\mathbf{J}_e\\) to the left side to see that \\(\\int_S \\nabla \\times{\\mathbf{H}} \\cdot \\hat{\\mathbf{n}} d{S} = \\int_S \\mathbf{J}_e \\cdot \\hat{\\mathbf{n}} d{S} = (I_e)_S\\), or the current passing through the cross-sectional area. By the original equation, we see that \\((I_e)_S = \\mathbf{H} \\cdot d{\\mathbf{l}}\\).</p> <p>If we assume cylindrical coordinates and that \\(\\mathbf{H}(vb{r}) = H_\\varphi(s) \\hat{\\mathbf{\\varphi}}\\), then \\(\\mathbf{H} \\cdot d{\\mathbf{l}} = \\int_0^{2\\pi} H_\\varphi(S) s d{\\varphi}\\), so then \\((I_e)_S = \\int_0^{2\\pi} H_\\varphi(S) s d{\\varphi}\\). Thus, for \\(s &gt; a\\) (where \\(a\\) is the radius of the wire), \\(2\\pi s H_\\varphi = I_e\\), and for \\(s &lt; a\\), \\(2\\pi s H_\\varphi = I_e \\frac{s^2}{a^2}\\).</p> <p>By Helmholtz Theorem, we know that \\(\\mathbf{H}(\\mathbf{r}) = \\nabla \\times{\\mathbf{A}(\\mathbf{r})}\\). For a current-carrying wire, \\(\\mathbf{A}(\\mathbf{r}) = \\frac{I_e}{4\\pi} \\int_{\\text{wire}} \\frac{d{\\mathbf{l'}}}{|\\mathbf{r}-\\mathbf{r'}|}\\). Applying identities, we see the *Law of Biot and Savart$, where</p> \\[ \\mathbf{H}(\\mathbf{r}) = \\int{I_e}{4\\pi}\\int_{\\text{wire}} \\frac{-(\\mathbf{r}-\\mathbf{r'}) \\times d{\\mathbf{l'}}}{|\\mathbf{r}-\\mathbf{r'}|^3} \\] <p>Consider a current loop instead, on the \\(x-y\\) plane and current \\(I\\). Then, \\(r = z \\hat{\\mathbf{z}}\\) and \\(d{\\mathbf{l'}} = R \\hat{\\mathbf{\\varphi'}} d\\phi'\\), and the magnetic field collapses to \\(\\mathbf{H}(s = 0, z) = \\frac{I_e R^2}{2(R^2 + z^2)^{\\frac{3}{2}}} \\hat{\\mathbf{z}}\\)</p> <p>Consider some infinite bar magnet with height \\(h\\) and width \\(w\\). Then, the top and bottom surfaces will have a magnetic charge with density \\(\\mathbf{J}_m^+ = M_0 \\mathbf{b} \\delta(z - h)\\) and \\(\\mathbf{J}_m^- = -M_0 \\mathbf{v} \\delta(z)\\) respectively. By definition, \\(I_m = M_0 w v\\).</p> <p>Now, consider a loop around only the top of the conductor. Then,</p> \\[ \\int_S \\mathbf{J}_m \\cdot \\hat{\\mathbf{n}} d{S} = I_m = M_o w v \\] <p>By definition,</p> \\[ \\int_S \\mathbf{J}_m \\cdot \\hat{\\mathbf{n}} d{S} = -\\int_S (\\nabla \\times{\\mathbf{E}}) \\cdot \\hat{\\mathbf{n}} d{S} \\] <p>Applying Stokes theorem,</p> \\[ \\int_S (\\nabla \\times{\\mathbf{E}}) \\cdot \\hat{\\mathbf{n}} d{S} = M_0 w v \\]"},{"location":"physics/electrostatics/5-moving-charges/#section-53-forces-on-moving-charges-and-current","title":"Section 5.3 - Forces on Moving Charges and Current","text":"<p>Consider an electric charge moving with velocity \\(\\mathbf{v}\\) in a magnetic parallel plate capacitor with charge densities \\(\\pm \\sigma_m\\). That is, \\(\\mu_0 \\mathbf{H} = \\sigma_m \\hat{\\mathbf{z}}\\). Then, we can apply theorems to see the resulting force.</p> <p>Theorem. Lorentz Force Law states that \\(\\mathbf{F} = q_e \\mathbf{v} \\times \\mu_0 \\mathbf{H}\\) in the presence of a magnetic field. In the presence of both an electric and magnetic field, \\(\\mathbf{F} = q_e (\\mathbf{E} + \\mathbf{v} \\times \\mu_0 \\mathbf{H})\\).</p> <p>Theorem. Ampere's Force Law states that generalizing the previous theorem, we can see that</p> \\[d\\mathbf{F} = I_e d{\\mathbf{L}} \\times \\mu_0 \\mathbf{H}(\\mathbf{r})\\]"},{"location":"physics/electrostatics/5-moving-charges/#section-54-multipole-expansion-of-a-vector-potential","title":"Section 5.4 - Multipole Expansion of a Vector Potential","text":"<p>This is messy. Skipped.</p>"},{"location":"physics/electrostatics/6%20-polarization-magnetization/","title":"Chapter 6 - Polarization and Magnetization","text":"<p>TODO</p>"},{"location":"physics/electrostatics/7-time-dependent-em-fields/","title":"Chapter 7 - Time Dependent Electric and Magnetic Fields","text":"<p>TODO</p>"},{"location":"physics/mechanics/1-classical-mechanics/","title":"Chapter 1 - Classical Mechanics","text":""},{"location":"physics/mechanics/1-classical-mechanics/#section-12-space-and-time","title":"Section 1.2 - Space and Time","text":"<p>Each point \\(P \\in \\mathbb{R}^3\\) can be written as \\((x, y, z)\\). However, we will utilize the convention below:</p> \\[\\mathbf{r} = x \\hat{\\mathbf{x}} + y \\hat{\\mathbf{y}} + z \\hat{\\mathbf{z}}\\] <p>However, when working with ambiguous unit basis, it may be better to use the following:</p> \\[\\mathbf{r} = r_1 \\hat{\\mathbf{e_1}} + r_2 \\hat{\\mathbf{e_2}} + r_3 \\hat{\\mathbf{e_3}}\\] <p>Here, \\(r_1 = x, r_2 = y, r_3 = z\\) and \\(\\hat{\\mathbf{e_1}} = \\hat{\\mathbf{x_1}}, \\ldots\\). That is, \\(\\mathbf{r} = \\sum r_i \\hat{\\mathbf{e_i}}\\).</p> <p>Vectors are an \\(\\mathbb{R}\\)-module, with addition defined component-wise. Additionally, the scalar (dot) product and vector (cross) product are defined as usual.</p> <p>Regarding time, classically, time is universal.</p> <p>Definition. Reference frames are frames of motion with a defined coordinate system and origin position.</p> <p>Definition. Inertial frames are reference frames in which Newton's laws of motion hold true. An inertial frame may not be accelerating.</p>"},{"location":"physics/mechanics/1-classical-mechanics/#section-13-mass-and-force","title":"Section 1.3 - Mass and Force","text":"<p>Definition. The mass \\(m\\) of an object characterizes its translational inertia, and is measured in kilograms (kg)</p> <p>Definition. The force \\(\\mathbf{F}\\) exerted on an object is a push or pull on said object and is measured in Newtons (N). Note that force is a vector.</p>"},{"location":"physics/mechanics/1-classical-mechanics/#section-14-newtons-first-and-second-laws-inertial-frames","title":"Section 1.4 - Newton's First and Second Laws; Inertial Frames","text":"<p>Definition. A point mass or particle is a convenient fiction, in which an object with mass has no size. It may move in space but has no internal degrees of freedom. Additionally, it may not have any rotational or vibrational kinetic energy.</p> <p>Theorem. Newton's First Law. In the absence of external forces, a particle moves with constant velocity \\(\\mathbf{v}\\).</p> <p>Theorem. Newton's Second Law. Given any particle with mass \\(m\\), the net force \\(\\mathbf{F}\\) on the particle is always equal to the particle's mass times its acceleration. That is,</p> \\[\\mathbf{F} = m\\mathbf{a} = m dot{\\mathbf{r}}\\] <p>This can also be rewritten in terms of momentum. We know that momentum \\(\\mathbf{p}\\) can be written as \\(\\mathbf{p} = m\\mathbf{v} = m \\dot{\\mathbf{r}}\\). Then,</p> \\[\\mathbf{F} = m\\mathbf{a} = m \\dot{\\mathbf{p}} = m dot{\\mathbf{r}}\\] <p>If we have a constant force \\(\\mathbf{F} = F_0 \\hat{\\mathbf{x}}\\), we can write \\(dot{\\hat{\\mathbf{x}}}(t) = \\frac{F_0}{m}\\). Then,</p> \\[\\dot{\\mathbf{x}}(t) = \\int dot{\\mathbf{x}} dt = v_0 + \\frac{F_0}{m}t\\] \\[\\mathbf{x}(t) = \\int \\dot{\\mathbf{x}} dt = x_0 + v_0t + \\frac{F_0}{2m}t^2\\] <p>Definition. An inertial frame is a reference frame relative to some fixed frame if they are moving with constant velocity in regards to each other. Otherwise, the frames are non-inertial.</p>"},{"location":"physics/mechanics/1-classical-mechanics/#section-15-the-third-law-and-conservation-of-momentum","title":"Section 1.5 - The Third Law and Conservation of Momentum","text":"<p>Definition. Newton's Third Law. Every force has an equal and opposite. If \\(F_{21}\\) is the force exerted on object \\(2\\) by object \\(1\\), there exists some force with equal magnitude \\(F_{12}\\) exerted on object \\(1\\) by object \\(2\\).</p> <p>Definition. Force pairs that operate in the same line as each other (eg. gravitational attraction) are called central forces.</p> <p>Recall that the change in momentum of any particle can be defined as \\(\\dot{\\mathbf{p}}_1 = \\mathbf{F}_1 = \\mathbf{F}_{12} + \\mathbf{F}_{1}^{ext}\\). Then, \\(\\dot{\\mathbf{p}}_2 = \\mathbf{F}_{21} + \\mathbf{F}_2^{ext}\\). As \\(\\mathbf{P} = \\mathbf{p}_1 + \\mathbf{p}_2\\), we can see that</p> \\[\\dot{\\mathbf{P}} = \\mathbf{p}_1 + \\mathbf{p}_2 = \\mathbf{F}_{12} +\\mathbf{F}_{21} + \\mathbf{F}_{1}^{ext} + \\mathbf{F}_{2}^{ext} = \\mathbf{F}_{1}^{ext} + \\mathbf{F}_{2}^{ext} = \\mathbf{F}^{ext}\\] <p>From this, we can see that if \\(\\mathbf{F}^{ext} = 0\\), then \\(\\mathbf{P}\\) is a constant.</p> <p>This argument can be generalized to multi-particle systems. Consider particle \\(\\alpha\\). Then, \\(\\dot{\\mathbf{p}}_\\alpha = \\mathbf{F}_\\alpha = \\sum_{\\beta \\neq \\alpha} \\mathbf{F}_{\\alpha\\beta} + \\mathbf{F}_\\alpha^{ext}\\). We  can then see that</p> \\[\\dot{\\mathbf{P}} = \\sum_\\alpha \\mathbf{p}_\\alpha = \\sum_\\alpha \\sum_{\\beta \\neq \\alpha} \\mathbf{F}_{\\alpha\\beta} + \\sum_\\alpha \\mathbf{F}_\\alpha^{ext}\\] <p>With \\(\\sum_\\alpha \\sum_{\\beta \\neq \\alpha} \\mathbf{F}_{\\alpha\\beta} = \\sum_\\alpha \\sum_{\\beta &gt; \\alpha} \\mathbf{F}_{\\alpha\\beta}( + \\mathbf{F}_{\\beta\\alpha})\\), we can see that \\(\\dot{\\mathbf{P}} = \\sum_\\alpha \\mathbf{F}_\\alpha^{ext}\\).</p> <p>Note that Newton's Third Law breaks down as the relative objects approach the speed of light, as it presumes the forces are equal at the same time. As events that are coincident in time in one frame may not be in another, it is clear that this law cannot hold.</p>"},{"location":"physics/mechanics/1-classical-mechanics/#section-16-newtons-second-law-in-cartesian-coordinates","title":"Section 1.6 - Newton's Second Law in Cartesian Coordinates","text":"<p>This is trivial. Skipped.</p>"},{"location":"physics/mechanics/1-classical-mechanics/#section-17-two-dimensional-polar-coordinates","title":"Section 1.7 - Two-Dimensional Polar Coordinates","text":"<p>This is trivial. Skipped.</p>"},{"location":"physics/mechanics/2-projectiles-charged-particles/","title":"Chapter 2 - Projectiles and Charged Particles","text":""},{"location":"physics/mechanics/2-projectiles-charged-particles/#section-21-air-resistance","title":"Section 2.1 - Air Resistance","text":"<p>Definition. The drag, or resistive force on an object due to the atmosphere, is denoted as \\(\\mathbf{f}\\). Note that this is not the force density, but the overall force. In most cases, this force directly opposes the direction of motion. If not, the other component is known as lift, however this is mostly negligible.</p> <p>We define air resistance as \\(\\mathbf{f} = -f(v) \\hat{\\mathbf{v}}\\). We consider two types in this text: linear, where \\(f(v) = f_{lin} = bv\\), and quadratic, where \\(f(v) = f_{quad} = cv^2\\). Note that often times we consider both, and state that \\(f(v) = f_{lin} + f_{quad} = bv + cv^2\\).</p> <p>The linear term comes from viscous drag and is generally proportional to the viscosity of the medium, while quadratic drag tends to arise from the particle needing to accelerate the mass of air which it is constantly colliding against.</p> <p>In some cases, we can calculate these coefficients. With \\(D\\) as the diameter of a spherical object, and \\(\\beta\\) and \\(\\gamma\\) as properties of the medium, we can state that \\(b = \\beta D\\) and \\(c = \\gamma D^2\\). In air at STP, \\(\\beta = 1.6 \\times 10^{-4} \\text{N} \\cdot \\text{s}/\\text{m}^2\\), and \\(\\gamma = 0.25 \\text{N} \\cdot \\text{s}^2/\\text{m}^4\\).</p> <p>Oftentimes, one factor is far more impactful than the other, meaning that the smaller of the two may be neglected. To do so, compute the following ratio:</p> \\[\\frac{f_{quad}}{f_{lin}} = \\frac{cv^2}{bv} = \\frac{\\gamma D}{\\beta}v\\] <p>Note that the result is expected to be of the same order of magnitude as the Reynolds number \\(R = Dv \\mathcal{Q}/\\eta\\), where \\(\\mathcal{Q}\\) is the density of the medium and \\(\\eta\\) the viscosity.</p>"},{"location":"physics/mechanics/2-projectiles-charged-particles/#section-22-linear-air-resistance","title":"Section 2.2 - Linear Air Resistance","text":"<p>First, consider the case in which the drag force is negligible. Then, we see that with \\(\\mathbf{F}_g = \\mathbf{w} = mg\\) and \\(\\mathbf{F}_{drag} = \\mathbf{f} = -b\\mathbf{v}\\), then Newton's second law tells us that</p> \\[\\mathbf{F} = m \\dot{\\mathbf{v}} = m\\mathbf{g} - b\\mathbf{b}\\] <p>This separates into two equations:</p> \\[\\begin{align} \\dot{v}_x &amp;= -\\frac{b}{m}v_x \\\\ \\dot{v}_y &amp;= g - \\frac{b}{m}v_y \\end{align}\\] <p>These are separable equations and can be trivially solved.</p> <p>For an object on a surface in which the only motion is in the \\(x\\)-direction, only the first of the above equations applies. Then, we can define \\(k = \\frac{b}{m}\\), so that \\(\\dot{v_x} = -k v_x\\). This can be integrated to see that \\(v_x(t) = Ae^{-kt}\\). We can also define \\(\\tau = \\frac{1}{t} = \\frac{m}{b}\\), so that \\(v(t) = Ae^{-\\frac{t}{\\tau}}\\)</p> <p>Now, consider the second equation. This is still separable, however, the math is more complicated. Note that when we set \\(\\dot{v}_y = 0\\), we are at some maximum (terminal) velocity \\(v_{ter}\\). Solving, we see that \\(v_{ter} = \\frac{mg}{b}\\). Then, we can rewrite our equation as</p> \\[m\\dot{v}_y = -b(v_y - v_ter)\\] <p>This can be solved to see that \\(v(y) = v_{ter} + (v_{y0} - v_{ter})e^{-\\frac{t}{\\tau}}\\).</p>"},{"location":"physics/mechanics/2-projectiles-charged-particles/#section-23-trajectory-and-range-in-a-linear-medium","title":"Section 2.3 - Trajectory and Range in a Linear Medium","text":"<p>From the velocity functions in the previous section, we can integrate to obtain the position functions.</p> \\[\\begin{align} x(t) &amp;= v_{x0}\\tau(1-e^{-\\frac{t}{\\tau}}) \\\\ y(t) &amp;= (v_{y0} + v_{ter})\\tau(1-e^{-\\frac{t}{\\tau}})-v_{ter}t \\end{align}\\] <p>We can then solve the first equation for \\(t\\) and substitute into the second to see that</p> \\[y(t) = \\frac{v_{y_0} + v_{ter}}{v_{x0}} + v_{ter} \\tau \\ln(1 - \\frac{x}{v_{x0}\\tau})\\] <p>Note the trajectory has a vertical asymptote at \\(x = v_{x0} \\tau\\).</p> <p>We can find the horizontal range by setting \\(y(R) = 0\\). This results in an equation that contains many exponential terms, so we want to find an approximation. Truncating the Taylor series for \\(\\ln(1 - \\varepsilon)\\), we see that \\(R \\approx R_{vac}(1 - \\frac{4}{3} \\frac{v_{y0}}{v_{ter}})\\), where \\(R_{vac}\\), or the air resistance assuming no air resistance, is \\(R_{vac} = \\frac{2 v_{x0}v_{y0}}{g}\\).</p>"},{"location":"physics/mechanics/2-projectiles-charged-particles/#section-24-quadratic-air-resistance","title":"Section 2.4 - Quadratic Air Resistance","text":"<p>In the case of quadratic air resistance, we see that \\(\\mathbf{f} = -c v^2 \\hat{\\mathbf{v}}\\). Then, we can see that in the horizontal case, \\(m\\frac{dv}{v_x^2} = -c dt\\). Thus,</p> \\[v_x(t) = \\frac{v_{x0}}{1+cv_{x0}t/m} = \\frac{v_{x0}}{1+\\tau/t}\\] <p>where \\(\\tau = m/cv_{x0}\\). We can see that at \\(t = \\tau\\), \\(v = v_{x0}/2\\).</p> <p>Thus, \\(x(t) = v_{x0} \\tau \\ln(1 + t / \\tau)\\).</p> <p>For exclusively vertical motion, we first define \\(v_{ter} = \\sqrt{\\frac{mg}{c}}\\). Then, we see that \\(\\dot{v_y} = g(1 - \\frac{v^2}{v_{ter}^2})\\). Solving via separation of variables yields</p> \\[v_y(t) = v_{ter}\\tanh(\\frac{gt}{v_{ter}})\\] <p>Then, we see that</p> \\[y(t) = \\frac{v_{ter}^2}{g} \\ln(\\cosh(\\frac{gt}{v_{ter}}))\\] <p>In the case where there is both vertical and horizontal motion, the differential equation no longer has an analytic solution.</p>"},{"location":"physics/mechanics/2-projectiles-charged-particles/#section-25-motion-of-a-charge-in-a-uniform-magnetic-field","title":"Section 2.5 - Motion of a Charge in a Uniform Magnetic Field","text":""},{"location":"physics/thermal/1-energy/","title":"Chapter 1 - Energy in Thermal Physics","text":""},{"location":"physics/thermal/1-energy/#section-11-thermal-equilibrium","title":"Section 1.1 - Thermal Equilibrium","text":"<p>Definition. The theoretical definition for temperature is the quantity that is the same for two objects when in thermal equilibrium.</p> <p>Definition. The time for a system to reach thermal equilibrium is the relaxation time.</p> <p>Definition. A substance is in diffusive equilibrium when the composition molecules of each substance is in equilibrium.</p> <p>Definition. A substance is in mechanical equilibrium if there is no net torque and no net force.</p> <p>Definition. Temperature is the measure of the tendency of an object to spontaneously give up energy to its surroundings.</p> <p>Definition. Absolute zero is the temperature at which the volume of an expanding gas should go to zero given constant pressure, or if volume is constant, pressure goes to zero.</p> <p>Definition. An absolute temperature scale is any temperature scale at which \\(0\\) is absolute zero.</p> <p>Definition. The SI absolute temperature unit is the kelvin.</p>"},{"location":"physics/thermal/1-energy/#section-12-the-ideal-gas","title":"Section 1.2 - The Ideal Gas","text":"<p>Theorem. Recall the Ideal Gas Law from chemistry, in which given \\(P = \\text{pressure}\\), \\(V = \\text{volume}\\), \\(n = \\text{number of moles of a gas}\\), \\(T = \\text{temperature in an absolute scale}\\), and \\(R = \\text{the ideal gas constant}\\),</p> \\[PV = nRT\\] <p>In SI units, \\(R = 8.31 \\frac{\\text{J}}{\\text{mol} \\cdot \\text{K}}\\).</p> <p>Definition. Recall that one mole of a substance is \\(6.022 \\times 10^{23}\\) units of said substance. This constant, \\(N_A\\), is Avogadro's Number.</p> <p>Using Avogadro's Number, we can rewrite the Ideal Gas law in terms of molecules, with \\(N = \\text{number of molecules of a gas}\\) and \\(n \\cdot N_A = N\\). Thus,</p> \\[PV = NkT\\] <p>for some constant \\(k = R / N_A\\).</p> <p>Definition. This constant \\(k = R / N_A\\) is Boltzmann's constant.</p> <p>Note that if the number of moles is constant, we can rewrite this as</p> \\[\\frac{P_1 V_1}{T_1} = \\frac{P_2 V_2}{T_2}\\]"},{"location":"physics/thermal/1-energy/#microscopic-model-of-an-ideal-gas","title":"Microscopic Model of an Ideal Gas","text":"<p>Consider a piston with length \\(L\\) with a piston area of \\(A\\). Then, the average pressure \\(\\overline{P}\\) can be defined as</p> \\[\\overline{P} = \\frac{\\overline{F_{x, \\text{piston}}}}{A} = - \\frac{\\overline{F_{x, \\text{on molecule}}}}{A}\\] <p>Now, consider some arbitrary molecule of gas with velocity \\(v\\). Then, we can apply \\(F = ma\\) to see</p> \\[\\overline{P} = -\\frac{m\\overline{a}}{A} = \\frac{m\\frac{\\overline{\\Delta v_x}}{\\Delta t}}{A}\\] <p>Now, let \\(\\delta t = 2L / v_x\\), or the time it takes for half an oscillate between the piston boundary in regards to the \\(x\\)-direction. Then, \\(\\delta v_x = -2v_x\\), as we are only considering acceleration due to the piston and not the chamber wall. Then,</p> \\[\\overline{P} = \\frac{mv_x^2}{AL} = \\frac{mv_x^2}{V}\\] <p>As velocity is a distribution in an ideal gas, with \\(N\\) as the sum of all molecules, we can rewrite this equation as</p> <p>\\(\\(PV = Nm\\overline{v_x^2}\\)\\),</p> <p>where \\(N\\) is the number of molecules and \\(\\overline{v_x^2}\\) is the expected value of the square of the velocity. Now, apply the ideal gas law to see that</p> \\[kT = m\\overline{v_x^2}\\] <p>Divide by \\(2\\) to see that</p> \\[\\frac{1}{2} kT = \\frac{1}{2} m\\overline{v_x^2}\\] <p>Summing over all directions, we see that</p> \\[\\frac{1}{2} m \\overline{v^2} = \\frac{1}{2} m (\\overline{v_x^2} + \\overline{v_y^2} + \\overline{v_z^2}) = \\frac{3}{2} k T\\] <p>This is the average translational kinetic energy for an ideal gas.</p> <p>Definition. A useful unit to measure energy on this scale is the electron-volt (eV), which is the kinetic energy gained by an electron that has been accelerated through a voltage difference of one volt. Note that \\(1 \\text{eV} = 1.6 \\times 10^{-19} \\text{J}\\).</p> <p>Note that the average speed in this model can be obtained as follows:</p> \\[\\overline{v^2} = \\frac{3kT}{m}\\] <p>Then, taking the square root results in</p> \\[v_\\text{rms} \\equiv \\sqrt{\\overline{v^2}} = \\sqrt{\\frac{3kT}{m}}\\]"},{"location":"physics/thermal/1-energy/#section-13-equipartition-of-energy","title":"Section 1.3 - Equipartition of Energy","text":"<p>We are familiar with energy in the form of \\(\\frac{1}{2}ab_{x, y, z}^2\\), where \\(a\\) is some fixed property of an object.</p> <p>Theorem. Equipartition Theorem. The average energy of any quadratic degree of freedom is \\(\\frac{1}{2}kT\\).</p> <p>If an object contains \\(N\\) molecules, each with \\(f\\) degrees of freedom, the total (average) thermal energy is</p> \\[U_\\text{thermal} = N \\cdot f \\cdot \\frac{1}{2}{k}{T} \\] <p>In monoatomic molecules, each molecule has \\(3\\) degrees of freedom, corresponding to the translational position. In diatomic gasses, there are \\(2\\) additional rotational degrees of freedom.</p> <p>Additionally, there exist modes of vibration, which each contribute two degrees of freedom (positional energy and vibrational kinetic energy). At room temperature, these are negligible in gasses. In solids, each atom may vibrate in three directions (as there are 3 translational axis), but atoms may not rotate, leading to \\(6\\) total degrees of freedom.</p> <p>In liquids, we are sad.</p>"},{"location":"physics/thermal/1-energy/#section-14-heat-and-work","title":"Section 1.4 - Heat and Work","text":"<p>We are familiar with energy, temperature, and work.</p> <p>Theorem. The Law of Conservation of Energy. Energy cannot be created or destroyed, only moved.</p> <p>Theorem. In thermodynamics, energy may only enter or leave a closed system via heat and work.</p> <p>Definition. Heat is any spontaneous flow of energy between two objects due to a difference in temperature.</p> <p>Definition. Work is any other flow of energy in or out of a system.</p> <p>With \\(U\\) being the total energy of a system, we can write</p> \\[\\Delta U = Q + W\\] <p>That is, the change in total energy of a system is equal to the heat being added to the system and work done on the system.</p> <p>Note that with heat engines, we often see \\(Q - W\\), where \\(W\\) instead represents the work done by the system.</p> <p>Theorem. The First Law of Thermodynamics. \\(\\Delta U = Q + W\\), along with the Law of Conservation of Energy. In  other words, you can't win the game.</p> <p>Definition. The SI unit of energy is the Joule, where \\(1J = 1 \\text{kg} \\cdot \\text{m}^2 / \\text{s}^2\\).</p> <p>Definition. The imperial unit of energy is the calorie, or the amount of energy to heat one gram of water by \\(1 \\degree \\text{C}\\). The exact conversion factor is defined as \\(1 \\text{J} = 4.184 \\text{cal}\\)</p> <p>Definition. Conduction is the transfer of heat by molecular contact, in which fast moving molecules bump into slow moving molecules and transfer energy.</p> <p>Definition. Convection is the transfer of heat by the bulk motion of a liquid or gas.</p> <p>Definition. Radiation is the transfer of heat via electromagnetic waves.</p>"},{"location":"physics/thermal/1-energy/#section-15-compression-work","title":"Section 1.5 - Compression Work","text":"<p>From classical mechanics, we know that \\(W = \\vec{F} \\cdot d\\vec{r}\\).</p> <p>Consider a piston with a compressible gas. In this case, with \\(\\Delta x\\) positive as the piston moves inwards, we can state that \\(W = F \\Delta x\\). Now, we want the gas to always maintain internal equilibrium. For this to be true, the piston must be moving relatively slowly. Note that any volume change that happens in this way is said to be quasistatic.</p> <p>We know that the force exerted by the piston is equal to the pressure times the area. Thus, \\(W = P A \\Delta  x\\). But \\(A\\Delta x\\) is just volume (in this case, negative, as volume is decreasing). So, \\(W = -P \\Delta V\\).</p> <p>However, this assumes constant pressure. For a non-constant pressure, \\(P(V)\\), we know that \\(W = \\int F dx = - \\int P(V) dV\\).</p> <p>Definition. In isothermal compression, we see that \\(\\delta T = 0\\). Then, \\(T\\) is a constant, so \\(nRT\\) is constant meaning \\(PV\\) is constant. Then, as \\(P(V) = (P_0V_0)/(V)\\), we can see that \\(W = \\int_{V_1}^{V_2} P(V) dV = nRT \\ln(V_i/V_f) = PV \\ln(P_f/P_i)\\)</p> <p>Definition. The line formed by isothermal compression on a \\(PV\\)-diagram is called an isotherm.</p> <p>Definition. In adiabatic compression, we assume that \\(Q = 0\\). Then, we see that \\(PV^\\gamma\\) is constant, with \\(\\gamma\\) being the adiabatic constant. Note that as \\(U = \\frac{f}{2}NkT = W\\), we can see that \\(V_2 T_2^{f/2} = V_1 T_1^{f/2}\\), and $gamma = (f+2)(f)$. Additionally, we see that \\(W\\) = \\(\\frac{P_2 V_2 - P_1 V_1}{1-\\gamma}\\)</p>"},{"location":"physics/thermal/1-energy/#section-16-heat-capacity","title":"Section 1.6 - Heat Capacity","text":"<p>Definition. The heat capacity \\(C = Q / \\Delta T\\) of an object is the energy required to raise its temperature by one degree.</p> <p>Definition. The specific heat capacity \\(c = C / m = C / (m \\Delta T)\\) is the energy needed to raise a substance by one degree per unit mass.</p> <p>In a system, we can note that</p> \\[C = \\frac{Q}{\\Delta T} = \\frac{\\Delta U - W}{\\Delta T}\\] <p>Consider the case in which volume is constant. Under these circumstances, we can calculate the heat capacity at constant volume, and as volume does not change, \\(W = 0\\), so</p> \\[C_V = (\\frac{\\Delta U}{\\Delta T})_V = (\\frac{\\partial U}{\\partial T})_V\\] <p>In the case where pressure is constant instead, we see that the heat capacity at constant pressure is defined as</p> \\[C_P = (\\frac{\\Delta U}{\\Delta T})_V = (\\frac{\\Delta  U - (- P \\Delta V)}{\\Delta T})_P = (\\frac{\\partial U}{\\partial T})_P + P (\\frac{\\partial V}{\\partial T})_P\\] <p>Knowing that \\(U = \\frac{1}{2}NfkT\\), we can see that \\(C_V = \\frac{NfK}{2}\\).</p> <p>Theorem. The Rule of Dulong and Pitt states that in solids, \\(f = 6\\), so the heat capacity per mole is \\(3R\\). In reality, all degrees of freedom freeze out as \\(T\\) approaches \\(0\\), so \\(C\\) approaches \\(0\\).</p> <p>For an ideal gas, at constant pressure,</p> \\[(\\frac{\\partial V}{\\partial T})_P = \\frac{\\partial}{\\partial T} (\\frac{NkT}{P}) = \\frac{Nk}{P}\\] <p>So, \\(C_P = C_V + Nk = C_V + nR\\).</p> <p>There are times when heat can be added without increasing the temperature at all, such as during a phase transformation. Then,</p> <p>Definition. The latent heat \\(L\\) of an object is the energy required to melt or boil a substance completely. We can also define specific latent heat \\(l\\) as</p> \\[l = \\frac{L}{m} = \\frac{Q}{m}\\] <p>Note that during this, we assume the pressure is constant and no other work is done aside from constant-pressure volume change. Additionally, the latent heat for freezing and boiling does not have to be (and almost never is) equal.</p> <p>Definition. We define enthalpy, \\(H\\), as the total energy needed to create any given system out of nothing in a set environment, and is defined as</p> \\[H = U + PV\\] <p>This can also be interpreted as the maximum possible energy extracted from annihilating the system, consisting of the system's internal energy \\(U\\) and the work \\(PV\\) done by the atmosphere to fill its absence.</p> <p>In a system, if the pressure is held constant, we see that \\(\\Delta H = \\Delta U + P \\Delta V\\). Thus, enthalpy can only increase due to expansion or internal energy changes. From the First Law of Thermodynamics, \\(\\Delta H = Q + W_{other}\\) if pressure is constant. Notably, the change in enthalpy per degree of temperature at a constant pressure is the same as the heat capacity at constant pressure \\(C_P\\).</p> <p>Definition. The Enthalpy of Formation is the energy needed to create a compound or undergo a phase transition from base constituents in their most stable states.</p>"},{"location":"physics/thermal/1-energy/#section-17-rates-of-processes","title":"Section 1.7 - Rates of Processes","text":"<p>Skipped.</p>"},{"location":"physics/thermal/2-second-law/","title":"Chapter 2 - The Second Law","text":""},{"location":"physics/thermal/2-second-law/#section-21-two-state-systems","title":"Section 2.1 - Two-State Systems","text":"<p>Definition. Given a system defined by a test statistic \\(XS\\) and positive integer \\(N\\), an ordered tuple with length \\(N\\) and elements in the range of \\(X\\) is known as a microstate. An unordered tuple with the same length \\(N\\) and elements in the range of \\(X\\) is known as a macrostate.</p> <p>Definition. The multiplicity of a macrostate is the number of possible microstates that, when when written as an unordered tuple, produce said macrostate. In this work, we will define \\(\\Omega(Macrostate) = Multiplicity\\).</p> <p>Note that if the test statistic \\(X\\) is a uniform and discrete test statistic, the probability of generating a given macrostate \\(m\\) can be written as \\(P(m) = \\frac{\\Omega(M)}{\\sum_M \\Omega M}\\).</p> <p>Recall. From Statistics, \\(C(n, k) = \\binom{n}{k}\\), or \\(n\\) choose \\(k\\), is the number of unordered pairs of length \\(k\\) that can be generated from a list of \\(n\\) distinct elements.</p> <p>Definition. A paramagnet is a material whose molecular magnetic moments do not align unless in the presence of an external magnetic field.</p> <p>Definition. A ferromagnet is a material whose molecular magnetic moments will be aligned in the presence of an external magnetic field and retain their alignment in its absence.</p> <p>Definition. The individual magnetic particles in a material are referred to as dipoles, as each contains a unique magnetic vector.</p> <p>Definition. In a two-state paramagnet, when exposed to a magnetic field, each dipole may only be parallel or antiparallel to the applied field. We denote \\(N = N_\\uparrow + N_\\downarrow\\) to represent the number of dipoles pointing up or down.</p> <p>Assuming the external magnetic field points up, we note that an up-dipole contains less energy than a down-dipole. The total energy of a system is determined by \\(N_\\uparrow\\) and \\(N_\\downarrow\\), so the macrostate of this system can be used to determine the total energy.</p>"},{"location":"physics/thermal/2-second-law/#section-22-the-einstein-model-of-a-solid","title":"Section 2.2 - The Einstein Model of a Solid","text":"<p>Consider a collection of microscopic systems that can each store any discrete amount of quantized energy. If each system is a harmonic oscillator, we know from Quantum Mechanics that the potential energy is \\(\\frac{1}{2}k_s x^2\\), where \\(k_s\\) is the spring constant. Then, the size of energy units is \\(hf\\), where \\(h\\) is Planck's constant (\\(h = 6.63 \\times 10^{-34} \\text{J} \\cdot \\text{s}\\)) and \\(f\\) is the natural frequency of the oscillator (\\(f = \\frac{1}{2\\pi} \\sqrt{k_s / m}\\)).</p> <p>Definition. For a three-dimensional solid, each particle can oscillate in three dimensions. Thus, if there are \\(N\\) oscillators, there are \\(N/3\\) particles. A solid modeled as such is known as an Einstein solid.</p> <p>Consider a system in which \\(N = 3\\). Then, \\(\\Omega(0) = 1\\), \\(\\Omega(1) = 3\\), \\(\\Omega(2) = 6\\), \\(\\Omega(3) = 10\\), and so on. We can extend this to see that for an Einstein solid with \\(N\\) oscillators, the multiplicity of the total energy \\(q\\) is</p> \\[\\Omega(N, q) = \\binom{q+N-1}{q} = \\frac{(q+N-1)!}{q!(N-1)!}\\]"},{"location":"physics/thermal/2-second-law/#section-23-interacting-systems","title":"Section 2.3 - Interacting Systems","text":"<p>Consider a system containing two solids, \\(A\\) and \\(B\\), that can share energy back and forth.</p> <p>Definition. Two solids are weakly coupled when the rate of energy transfer between the two solids is substantially less than the rate of energy transfer within the solids. That is, the total energy of each solid \\(U_A\\) and \\(U_B\\) only change slowly. Note that \\(U = U_A + U_B\\) is fixed.</p> <p>Consider a small system, in which \\(N_A = N_B = 3\\), with a total energy of \\(q_{total} = q_A + q_B = 6\\) (Note that the actual value of energy is \\(U = qhf\\)). There are seven possible macrostates of the system, each defined by \\(q_A \\in {0, 1, \\ldots, 6}\\) (as \\(q_B = 6 - q_A\\)). We can find the multiplicity of the overall macrostate by multiplying the multiplicity of \\(q_A\\) in solid \\(A\\) with the multiplicity of \\(q_B\\) in solid \\(B\\).</p> <p>Theorem. The fundamental assumption of statistical mechanics states that in an isolated system in thermal equilibrium, all microstates are equally probably. Note that this does not imply that macrostates are equally probably.</p> <p>Theorem. The second law of thermodynamics states that the spontaneous flow of energy stops when a system is at the macrostate with the greatest multiplicity.</p>"},{"location":"physics/thermal/2-second-law/#section-24-large-systems","title":"Section 2.4 - Large Systems","text":"<p>Definition. When dealing with large and small numbers, it is important to note that a small number may be added to a large number without significantly changing it.</p> <p>We can also define very large numbers, of which large or small numbers may be added or multiplied by each other and remain unchanged.</p> <p>Theorem. Stirling's Approximation. For some large \\(N \\in \\mathbb{N}\\), we can estimate \\(N! \\approx N^N e^{-N} \\sqrt{2\\pi N}\\). This comes from \\(N! \\approx N^N\\), with the additional correction terms \\(e^{-N}\\) and \\(\\sqrt{2\\pi N}\\). If we care about \\(\\ln(N!)\\), we can omit the last term to see \\(\\ln (N!) \\approx N \\ln N - N\\).</p> <p>We can use this to simplify \\(\\Omega(N, q) = \\binom{q + N - 1}{q} = \\frac{(q + N - 1)!}{q!(N-1)!} \\approx \\frac{(q+N)!}{q!N!}\\). Take the logarithm to see that \\(\\ln \\Omega = \\ln(\\frac{(q+N)!}{q!N!}) = \\ln((q+N)!) - \\ln(q!) - \\ln(N!)\\). We can now apply the simplification to see that \\(\\Omega \\approx (q + N)\\ln(q+N) - (q - N) - q\\ln q + q - N \\ln N + N = (q+N)\\ln(q+N) - q\\ln q - N\\ln N\\).</p> <p>We can factor \\(\\ln (q+N)\\) to see that \\(\\ln(q+N) = \\ln q + \\ln(1 + \\frac{N}{q})\\), and if \\(N \\gg q\\), we can use the Taylor series of \\(\\ln(x)\\) at \\(x_0 = 1\\) to see that \\(\\ln(q+N) \\approx \\ln q + \\frac{N}{q}\\) Thus, \\(\\ln \\Omega \\approx N \\frac{q}{N} + N + \\frac{N^2}{q}\\).</p> <p>Note that \\(N^2/q\\) becomes negligible. This, we can exponentiate to see that \\(\\Omega \\approx e^{N\\ln(q/N)}e^N = (\\frac{eq}{N})^N\\).</p> <p>Now, for a system of two large Einstein solids, we wish to know the width of the peak in the multiplicity function. We know that with \\(q = q_{total} = q_A + q_B\\),</p> \\[\\Omega = \\Omega(q_A) \\Omega(q_B) = (\\frac{eq_A}{N})^N (\\frac{eq_B}{N})^N = (\\frac{e}{N})^{2N}(q_A q_B)^N\\] <p>The highest peak will be at \\(q = 2 q_A\\), where \\(\\Omega_max = (\\frac{e}{N})^{2N} (\\frac{q}{2})^{2N}\\). If we instead let \\(q_A = \\frac{q}{2} + x\\) and \\(q_B = \\frac{q}{2} - x\\), we will see that \\(\\Omega = (\\frac{e}{N})^{2N}((\\frac{q}{2})^2 - x^2)^N\\). By taking the logarithm of the second factor and then applying simplifications, we can reduce this to \\(\\Omega = \\Omega_{max} e{-N (2x/q)^2}\\). This function should be familiar, as it is a Gaussian.</p> <p>Note that the multiplicity falls to \\(1/e\\) of its maximum value when \\(N(\\frac{2x}{q})^2 = 1\\), or when \\(x = \\frac{q}{2\\sqrt{N}}\\). This means that the approximate width of the peak is \\(q/\\sqrt{N}\\)</p> <p>Definition. The thermodynamic limit is when a system becomes infinitely large, so that measurable fluctuations away from the most likely microstate never occur.</p>"},{"location":"recipes/bread/","title":"Breads","text":""},{"location":"recipes/bread/#pumpkin-bread","title":"Pumpkin Bread","text":"<ul> <li>Preheat oven to \\(350 \\degree\\) F.</li> <li>Combine \\(1 \\frac{2}{3}\\) cups flour, \\(1 \\frac{1}{2}\\) cups sugar, 1 tsp. baking soda, 1 tsp cinnamon, \\(\\frac{3}{4}\\) tsp. salt, \\(\\frac{1}{2}\\) tsp. baking powder, \\(\\frac{1}{2}\\) tsp. nutmeg, \\(\\frac{1}{4}\\) tsp cloves.</li> <li>In a separate bowl, combine 2 eggs, 1 can of pumpkin, \\(\\frac{1}{2}\\) cup canola oil, and \\(\\frac{1}{2}\\) cups water.</li> <li>Combine. Mix in \\(\\frac{1}{2}\\) cups of walnuts.</li> <li>Add to a greased 9x5 pan. Bake at \\(350 \\degree\\) F for 65-80 minutes.</li> </ul>"},{"location":"recipes/cookies/","title":"Cookies","text":""},{"location":"recipes/cookies/#chocolate-chip-cookies","title":"Chocolate Chip Cookies","text":"<p>Original: Link</p> <ul> <li>Preheat oven to \\(350 \\degree\\) F.</li> <li>In a small bowl, combine \\(1 \\frac{1}{2}\\) cups flour and \\(\\frac{1}{4}\\) tsp. salt</li> <li>In a medium bowl, mix together \\(\\frac{1}{2}\\) cup butter, \\(\\frac{1}{2}\\) cup sugar, \\(\\frac{1}{2}\\) cup brown sugar.</li> <li>To the wet ingredients, add 1 egg and 1 tsp. vanilla.</li> <li>To the wet ingredients, add a combination of 1 tsp. hot water and \\(\\frac{1}{2}\\) tsp. baking soda.</li> <li>Mix the wet and dry ingredients. Stir in 1 cup chocolate chips and optionally \\(\\frac{1}{2}\\) cup walnuts.</li> <li>Bake for 10m at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/cookies/#peanut-butter-cookies","title":"Peanut Butter Cookies","text":"<ul> <li>Preheat oven to \\(350 \\degree\\) F.</li> <li>Mix \\(\\frac{1}{2}\\) cup butter, \\(\\frac{1}{2}\\) cup peanut butter, \\(\\frac{1}{2}\\) cup sugar, \\(\\frac{1}{2}\\)  cup brown sugar.</li> <li>Whisk in 1 egg.</li> <li>In a separate bowl, prepare \\(1 \\frac{1}{4}\\) cup sugar, \\(\\frac{3}{4}\\) tsp. baking soda, \\(\\frac{1}{2}\\) tsp. baking powder, and \\(\\frac{1}{4}\\) tsp. salt.</li> <li>Combine. Bake for 10 minutes at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/cookies/#lemon-cookies","title":"Lemon Cookies","text":"<ul> <li>Preheat oven to \\(350 \\degree\\) F.</li> <li>Mix 2 cups flour, \\(\\frac{1}{2}\\) baking soda, \\(\\frac{1}{2}\\) tsp. salt.</li> <li>In a separate bowl, mix \\(\\frac{1}{2}\\) cup butter, 1 cup sugar</li> <li>Whisk 1 egg, 1 tsp. vanilla into wet ingredients.</li> <li>Combine. Mix in a lemon worth of zest and juice.</li> <li>Bake for 10m at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/cookies/#glaze-optional","title":"Glaze (Optional)","text":"<ul> <li>Combine 2 cups of powdered sugar, 2 tbsp. lemon zest, and \\(\\frac{1}{3}\\) cup of lemon juice.</li> </ul>"},{"location":"recipes/cookies/#snickerdoodle-cookies","title":"Snickerdoodle Cookies","text":"<ul> <li>Preheat oven to \\(400 \\degree\\) F.</li> <li>Blend together \\(\\frac{3}{4}\\) cup sugar, \\(\\frac{1}{4}\\) cup butter (softened), \\(\\frac{1}{4}\\) cup shortening.</li> <li>Add 1 egg, 1 tsp. vanilla</li> <li>In a separate bowl, combine \\(1 \\frac{1}{4}\\) cups flour, 1 tsp. cream of tartar, \\(\\frac{1}{2}\\) tsp. baking soda, and \\(\\frac{1}{4}\\) tsp. salt</li> <li>Combine</li> <li>Coat in a mix of 1 tbsp. sugar : 1 tsp. cinnamon</li> <li>Bake for 10 minutes at \\(400 \\degree\\) F.</li> </ul>"},{"location":"recipes/cupcakes/","title":"Cupcakes","text":""},{"location":"recipes/cupcakes/#lemon-cupcakes","title":"Lemon Cupcakes","text":"<ul> <li>Preheat oven to \\(350 \\degree\\) F</li> <li>Combine \\(1 \\frac{1}{4}\\) cups flour, \\(\\frac{3}{4}\\) tsp. baking powder, \\(\\frac{1}{4}\\) tsp. baking soda.</li> <li>In a separate bowl, combine \\(\\frac{1}{4}\\) cup butter, \\(\\frac{3}{4}\\) cup sugar, \\(\\frac{1}{4}\\) cup vegetable oil, \\(\\frac{1}{4}\\) tsp. vanilla</li> <li>Add 2 eggs.</li> <li>Combine with half of the dry mixture. Add 6 tbsp. milk, 1 lemon of zest and juice. Stir. Add the rest of the dry ingredients.</li> <li>Bake for 15-18 minutes at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/cupcakes/#frosting","title":"Frosting","text":"<ul> <li>Beat 1 cup butter and 4 cups of powdered sugar. Add \\(\\frac{1}{2}\\) tsp. vanilla, 4-5 tbsp. lemon juice, 1 tsp. zest, and salt to taste.</li> </ul>"},{"location":"recipes/meals/","title":"Meals","text":""},{"location":"recipes/meals/#rice-porridge","title":"Rice Porridge","text":"<ul> <li>Boil 2 cups of chicken broth. Add onion and garlic powder.</li> <li>Add 1 cup of rice. Boil till soft.</li> <li>Mix ground beef with \\(\\frac{1}{2}\\) cups of chicken broth. Add to rice, boil for approx. 5 minutes.</li> <li>Add salt, pepper, fish sauce.</li> </ul>"},{"location":"recipes/meals/#banh-bao","title":"Banh Bao","text":"<p>Source: link.</p> <ul> <li> <p>For the filling, combine \\(\\frac{3}{4}\\) lb. ground pork, \\(3\\) tbsp. wood ear mushrooms, \\(\\frac{1}{4}\\) cup minced yellow onions, \\(2\\) tsp. fish sauce, \\(2\\) tsp. oyster sauce, \\(1\\) tsp sugar, \\(\\frac{1}{2}\\) tsp. salt, \\(\\frac{1}{2}\\) tsp. pepper, 2 sliced Chinese sausages, and \\(4\\) boiled eggs, cut into quarters.</p> </li> <li> <p>For the dough, add \\(2 \\frac{1}{2}\\) cup flour and \\(2\\) tsp baking powder to a bowl</p> </li> <li>Heat \\(\\frac{3}{4}\\) cup whole milk to \\(\\approx 100 \\deg \\F\\), add instant yeast. Set aside for \\(\\approx 10\\) minutes or until foams.</li> <li>Add \\(1\\) tbsp vegetable oil and \\(\\frac{1}{2}\\) cup sugar</li> <li>Combine wet and dry ingredients</li> <li>Knead on floured surface for \\(\\approx 10\\) minutes.</li> <li> <p>Transfer to an oiled bowl, cover, and wait for approx. 1 hour</p> </li> <li> <p>Bring water to a simmer, add \\(1\\) tsp. rice wine vinegar. Steam for \\(\\approx 15-17\\) minutes.</p> </li> </ul>"},{"location":"recipes/pies/","title":"Pies","text":""},{"location":"recipes/pies/#pie-crust-1","title":"Pie Crust 1","text":"<ul> <li>Whisk \\(1 \\frac{1}{4}\\) cups of flour with \\(\\frac{1}{4}\\) tsp. salt</li> <li>Cut in \\(\\frac{1}{2}\\) cups of cubed butter (chilled), \\(\\frac{1}{4}\\) cups cold water.</li> <li>Refrigerate</li> </ul>"},{"location":"recipes/pies/#pie-crust-2","title":"Pie Crust 2","text":"<ul> <li>Mix \\(\\frac{1}{3}\\) cup flour, \\(\\frac{1}{3}\\) tsp. salt.</li> <li>Cut in \\(\\frac{1}{2}\\) cups of shortening, 3 tbsp. cold water.</li> <li>Refrigerate</li> </ul>"},{"location":"recipes/pies/#pumpkin-pie-1","title":"Pumpkin Pie 1","text":"<ul> <li>Preheat oven to \\(425 \\degree\\) F.</li> <li>Whisk together 1 can pumpkin, 1 can sweetened-condensed milk, and two eggs.</li> <li>Add 1 tsp. cinnamon, \\(\\frac{1}{2}\\) tsp. ginger, \\(\\frac{1}{2}\\) tsp. nutmeg, \\(\\frac{1}{2}\\) tsp. salt.</li> <li>Add to pie crust.</li> <li>Bake for 15 minutes at \\(245 \\degree\\) F, then for 35-40 minutes at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/pies/#pumpkin-pie-2","title":"Pumpkin Pie 2","text":"<p>From: Link</p> <ul> <li>Fits with Pie Crust 2</li> <li>Preheat oven to \\(425 \\degree\\) F.</li> <li>Whisk together 2 can pumpkin, 2 cans evaporated milk, two eggs, and \\(\\frac{3}{4}\\) cups brown sugar.</li> <li>Add \\(\\frac{1}{2}\\) tsp. cinnamon, \\(\\frac{1}{2}\\) tsp. ginger, \\(\\frac{1}{2}\\) tsp. nutmeg, \\(\\frac{1}{2}\\) tsp. salt.</li> <li>Add to pie crust.</li> <li>Bake for 15 minutes at \\(245 \\degree\\) F, then for 35-40 minutes at \\(350 \\degree\\) F.</li> </ul>"},{"location":"recipes/pies/#apple-hand-pie","title":"Apple Hand Pie","text":"<p>From: Link</p>"},{"location":"recipes/pies/#filling","title":"Filling","text":"<ul> <li>Cut 2 apples into slices.</li> <li>Mix \\(\\frac{1}{4}\\) cups sugar, 2 tbsp. brown sugar, \\(1 \\frac{1}{4}\\) tsp. cinnamon, and \\(\\frac{1}{4}\\) tsp. salt together with 1 tsp. water.</li> <li>Brown 2 tbsp. butter on mild heat.</li> <li>Mix in apples, add sugar mixture.</li> <li>Wait until apples are softened (approx. 5 minutes).</li> </ul>"},{"location":"recipes/pies/#hand-pies","title":"Hand Pies","text":"<ul> <li>Preheat oven to \\(400 \\degree\\) F.</li> <li>Split pie crust into 4. Place filling in crust, fold.</li> <li>Sprinkle with \\(\\frac{1}{4}\\) tsp. white sugar.</li> <li>Whisk 2 tsp. milk, 1 egg. Brush pastries.</li> <li>Bake at \\(400 \\degree\\) F. for 25-30 minutes.</li> </ul>"},{"location":"recipes/snacks/","title":"Snacks","text":""},{"location":"recipes/snacks/#seasoned-chex-mix","title":"Seasoned Chex Mix","text":"<ul> <li>Preheat oven to \\(250 \\degree F\\).</li> <li>Combine 9-10 cups Chex (approx. 1 box).</li> <li>Melt 8 tbsp. butter. COmbine with 2 tbsp. worcestershire sauce, 2 tbsp. seasoned salt, 1 tsp. garlic power, and 1 tsp. onion powder.</li> <li>Pour half of mixture into mixed chex, stir, add other half, repeat.</li> <li>Bake at \\(250 \\degree F\\) for approx. 45-60 minutes using 2-3 oven trays, stirring every 15 minutes.</li> </ul>"},{"location":"recipes/snacks/#buckeyes","title":"Buckeyes","text":"<ul> <li>Mix \\(1 \\frac{1}{2}\\) cup peanut butter with 1 cup butter (softened), \\(\\frac{1}{2}\\) tsp. vanilla, and 4 cups of powdered sugar.</li> <li>Refridgerate.</li> <li>Melt 4 cups of chocolate chips. Roll peanut butter mixture into balls, coat in chocolate.</li> </ul>"},{"location":"recipes/snacks/#chocolate-fudge","title":"Chocolate Fudge","text":"<ul> <li>Melt 1 bag of chocolate chips on low. Stir in 1 can of sweetened condensed milk. Pour into buttered or oiled tray.</li> </ul>"},{"location":"recipes/snacks/#peanut-butter-fudge","title":"Peanut Butter Fudge","text":"<ul> <li>Melt \\(\\frac{1}{2}\\) cup of butter on medium heat. Stir in a 16oz bag of brown sugar, \\(\\frac{1}{2}\\) cup of milk.</li> <li>Remove from heat. Stir in \\(\\frac{3}{4}\\) cups of peanut butter and 1 tsp bvnilla.</li> <li>Add to \\(3 \\frac{1}{2}\\) cups of powdered sugar</li> <li>Pour into buttered or oiled tray.</li> </ul>"}]}